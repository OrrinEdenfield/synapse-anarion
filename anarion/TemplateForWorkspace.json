{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "anarion"
		},
		"anarion-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'anarion-WorkspaceDefaultSqlServer'"
		},
		"brandybuck_primula_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'brandybuck_primula'"
		},
		"DownloadDotMicrosoftDotCom_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://download.microsoft.com"
		},
		"MicrosoftDotCom_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://www.microsoft.com"
		},
		"anarion-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://gondor2.dfs.core.windows.net"
		},
		"biketrips_http_source_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://s3.amazonaws.com/tripdata/"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/GetJSONfromHTTP')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "GetDownloadPage",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "BinarySource",
								"storeSettings": {
									"type": "HttpReadSettings",
									"requestMethod": "GET"
								},
								"formatSettings": {
									"type": "BinaryReadSettings"
								}
							},
							"sink": {
								"type": "BinarySink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "AzureIPRangeLink",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "AzureIPRangeLinkSink",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					},
					{
						"name": "ParseDownloadPage",
						"type": "ExecuteDataFlow",
						"dependsOn": [
							{
								"activity": "GetDownloadPage",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Azure_IP_Range_ParseHTML",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"relativeURL": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "None",
							"cacheSinks": {
								"firstRowOnly": true
							}
						}
					},
					{
						"name": "GetJsonFile",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "ParseDownloadPage",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "BinarySource",
								"storeSettings": {
									"type": "HttpReadSettings",
									"requestMethod": "GET"
								},
								"formatSettings": {
									"type": "BinaryReadSettings"
								}
							},
							"sink": {
								"type": "BinarySink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "AzureIPRangeJSONFile",
								"type": "DatasetReference",
								"parameters": {
									"paramURL": {
										"value": "@string(activity('ParseDownloadPage').output.runStatus.output.relativeURL.value[0].url3)",
										"type": "Expression"
									}
								}
							}
						],
						"outputs": [
							{
								"referenceName": "Azure_IP_Range_JSON_Sink",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "Examples"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/AzureIPRangeLink')]",
				"[concat(variables('workspaceId'), '/datasets/AzureIPRangeLinkSink')]",
				"[concat(variables('workspaceId'), '/dataflows/Azure_IP_Range_ParseHTML')]",
				"[concat(variables('workspaceId'), '/datasets/AzureIPRangeJSONFile')]",
				"[concat(variables('workspaceId'), '/datasets/Azure_IP_Range_JSON_Sink')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Load-to-SQL-Dedicated')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Load_US_Pop_by_Zip_SQL_Dedicated",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Load_US_Pop_by_Zip_Parquet",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"source2": {},
									"sink1": {},
									"sink2": {}
								}
							},
							"staging": {
								"linkedService": {
									"referenceName": "anarion-WorkspaceDefaultStorage",
									"type": "LinkedServiceReference"
								},
								"folderPath": "calembel/staging"
							},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "None",
							"cacheSinks": {
								"firstRowOnly": true
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "Examples"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/dataflows/Load_US_Pop_by_Zip_Parquet')]",
				"[concat(variables('workspaceId'), '/linkedServices/anarion-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Prep-Monthly-BikeTrips')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Get compressed file from web",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "BinarySource",
								"storeSettings": {
									"type": "HttpReadSettings",
									"requestMethod": "GET"
								},
								"formatSettings": {
									"type": "BinaryReadSettings"
								}
							},
							"sink": {
								"type": "BinarySink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "biketrips_binaryfile_source",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "biketrips_binaryfile_sink",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					},
					{
						"name": "Unzip and organize incoming",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "Get compressed file from web",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "BinarySource",
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": false,
									"deleteFilesAfterCompletion": false
								},
								"formatSettings": {
									"type": "BinaryReadSettings",
									"compressionProperties": {
										"type": "ZipDeflateReadSettings",
										"preserveZipFileNameAsFolder": false
									}
								}
							},
							"sink": {
								"type": "BinarySink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "biketrips_csv_source_zipped",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "biketrips_csv_sink",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					},
					{
						"name": "Delete MACOSX dir",
						"type": "Delete",
						"dependsOn": [
							{
								"activity": "Unzip and organize incoming",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "biketrips_csv_sink_dirMACOSX",
								"type": "DatasetReference",
								"parameters": {}
							},
							"enableLogging": false,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "Copy ZIP file to archive",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "Unzip and organize incoming",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "BinarySource",
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": true,
									"deleteFilesAfterCompletion": true
								},
								"formatSettings": {
									"type": "BinaryReadSettings"
								}
							},
							"sink": {
								"type": "BinarySink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "biketrips_binaryfile_sink",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "biketrips_zip_archive",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					},
					{
						"name": "Delete incoming dir",
						"type": "Delete",
						"dependsOn": [
							{
								"activity": "Copy ZIP file to archive",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "biketrips_binaryfile_sink",
								"type": "DatasetReference",
								"parameters": {}
							},
							"enableLogging": false,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "Examples"
				},
				"annotations": [],
				"lastPublishTime": "2022-08-22T12:53:11Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/biketrips_binaryfile_source')]",
				"[concat(variables('workspaceId'), '/datasets/biketrips_binaryfile_sink')]",
				"[concat(variables('workspaceId'), '/datasets/biketrips_csv_source_zipped')]",
				"[concat(variables('workspaceId'), '/datasets/biketrips_csv_sink')]",
				"[concat(variables('workspaceId'), '/datasets/biketrips_csv_sink_dirMACOSX')]",
				"[concat(variables('workspaceId'), '/datasets/biketrips_zip_archive')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SynapseLink2SQLDB-Generate')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Scale to S3-DTU100",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[dbo].[spScaleDB_S3]"
						},
						"linkedServiceName": {
							"referenceName": "brandybuck_primula",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "Scale to Basic",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "Scale to S3-DTU100",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[dbo].[spScaleDB_Basic]"
						},
						"linkedServiceName": {
							"referenceName": "brandybuck_primula",
							"type": "LinkedServiceReference"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "Examples"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/brandybuck_primula')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AzureIPRangeJSONFile')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "DownloadDotMicrosoftDotCom",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"paramURL": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "HttpServerLocation",
						"relativeUrl": {
							"value": "@dataset().paramURL",
							"type": "Expression"
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/DownloadDotMicrosoftDotCom')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AzureIPRangeLink')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "MicrosoftDotCom",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "HttpServerLocation",
						"relativeUrl": "en-us/download/confirmation.aspx?id=56519"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/MicrosoftDotCom')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AzureIPRangeLinkSink')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "anarion-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "linkresponse.html",
						"folderPath": "01-raw/azure-ip-range",
						"fileSystem": "calembel"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/anarion-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Azure_IP_Range_JSON_Sink')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "anarion-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "iprange.json",
						"folderPath": "02-curated/azure-ip-range-json",
						"fileSystem": "calembel"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/anarion-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Azure_IP_Source_TXT_linkresponse')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "anarion-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "linkresponse.html",
						"folderPath": "01-raw/azure-ip-range",
						"fileSystem": "calembel"
					},
					"columnDelimiter": "",
					"rowDelimiter": "",
					"escapeChar": "\\",
					"quoteChar": "\""
				},
				"schema": [
					{
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/anarion-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Csv_US_Zip_codes')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "anarion-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "us_postal_codes.csv",
						"folderPath": "01-raw/us-zip-codes",
						"fileSystem": "calembel"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "Zip Code",
						"type": "String"
					},
					{
						"name": "Place Name",
						"type": "String"
					},
					{
						"name": "State",
						"type": "String"
					},
					{
						"name": "State Abbreviation",
						"type": "String"
					},
					{
						"name": "County",
						"type": "String"
					},
					{
						"name": "Latitude",
						"type": "String"
					},
					{
						"name": "Longitude",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/anarion-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Parquet_US_Pop_By_Zip')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "anarion-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "01-raw/US-Population-by-postal-code/parquet",
						"fileSystem": "calembel"
					},
					"compressionCodec": "snappy"
				},
				"schema": [
					{
						"name": "decennialTime",
						"type": "UTF8"
					},
					{
						"name": "zipCode",
						"type": "UTF8"
					},
					{
						"name": "population",
						"type": "INT32"
					},
					{
						"name": "race",
						"type": "UTF8"
					},
					{
						"name": "sex",
						"type": "UTF8"
					},
					{
						"name": "minAge",
						"type": "INT32"
					},
					{
						"name": "maxAge",
						"type": "INT32"
					},
					{
						"name": "year",
						"type": "INT32"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/anarion-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/US_Pop_By_Zip_SQL_Sink')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "anarion-WorkspaceDefaultSqlServer",
					"type": "LinkedServiceReference",
					"parameters": {
						"DBName": "SynapseSQLDedicated"
					}
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [],
				"typeProperties": {
					"schema": "dbo",
					"table": "US_Pop_by_Zip"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/anarion-WorkspaceDefaultSqlServer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/US_Zip_SQL_Sink')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "anarion-WorkspaceDefaultSqlServer",
					"type": "LinkedServiceReference",
					"parameters": {
						"DBName": "SynapseSQLDedicated"
					}
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [],
				"typeProperties": {
					"schema": "dbo",
					"table": "US_Zip"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/anarion-WorkspaceDefaultSqlServer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/biketrips_binaryfile_sink')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "anarion-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "01-raw/biketrips/incoming",
						"fileSystem": "calembel"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/anarion-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/biketrips_binaryfile_source')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "biketrips_http_source",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "HttpServerLocation",
						"relativeUrl": {
							"value": "@concat(formatDatetime(getPastTime(1,'Month'),'yyyy'),formatDatetime(getPastTime(1,'Month'),'MM'),'-citbike-tripdata.csv.zip')",
							"type": "Expression"
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/biketrips_http_source')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/biketrips_csv_sink')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "anarion-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "01-raw/biketrips/2022",
						"fileSystem": "calembel"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/anarion-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/biketrips_csv_sink_dirMACOSX')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "anarion-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "01-raw/biketrips/2022/__MACOSX",
						"fileSystem": "calembel"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/anarion-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/biketrips_csv_source_zipped')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "anarion-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "01-raw/biketrips/incoming",
						"fileSystem": "calembel"
					},
					"compression": {
						"type": "ZipDeflate",
						"level": "Optimal"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/anarion-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/biketrips_zip_archive')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "anarion-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "04-archive/biketrips",
						"fileSystem": "calembel"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/anarion-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DownloadDotMicrosoftDotCom')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "HttpServer",
				"typeProperties": {
					"url": "[parameters('DownloadDotMicrosoftDotCom_properties_typeProperties_url')]",
					"enableServerCertificateValidation": true,
					"authenticationType": "Anonymous"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/MicrosoftDotCom')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "HttpServer",
				"typeProperties": {
					"url": "[parameters('MicrosoftDotCom_properties_typeProperties_url')]",
					"enableServerCertificateValidation": true,
					"authenticationType": "Anonymous"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PowerBIWorkspace')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "PowerBIWorkspace",
				"typeProperties": {
					"workspaceID": "29d1e616-f424-482d-a0e3-3f9158f647b3",
					"tenantID": "72f988bf-86f1-41af-91ab-2d7cd011db47"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/anarion-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('anarion-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/anarion-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('anarion-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/biketrips_http_source')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "HttpServer",
				"typeProperties": {
					"url": "[parameters('biketrips_http_source_properties_typeProperties_url')]",
					"enableServerCertificateValidation": true,
					"authenticationType": "Anonymous"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/brandybuck_primula')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureSqlDatabase",
				"typeProperties": {
					"connectionString": "[parameters('brandybuck_primula_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Monthly-Get-Biketrips')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"runtimeState": "Started",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "Prep-Monthly-BikeTrips",
							"type": "PipelineReference"
						},
						"parameters": {}
					}
				],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Month",
						"interval": 1,
						"startTime": "2022-09-16T06:00:00Z",
						"endTime": "2023-01-20T00:00:00Z",
						"timeZone": "UTC",
						"schedule": {
							"minutes": [
								0
							],
							"hours": [
								6
							],
							"monthDays": [
								16
							]
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/Prep-Monthly-BikeTrips')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/OnPremSHIR')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "SelfHosted",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Azure_IP_Range_ParseHTML')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Examples"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Azure_IP_Source_TXT_linkresponse",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"name": "relativeURL"
						}
					],
					"transformations": [
						{
							"name": "DerivedColumn1"
						},
						{
							"name": "Flatten1"
						},
						{
							"name": "SurrogateKey1"
						},
						{
							"name": "Filter1"
						},
						{
							"name": "DerivedColumn2"
						},
						{
							"name": "SurrogateKey2"
						},
						{
							"name": "Filter2"
						},
						{
							"name": "Flatten2"
						},
						{
							"name": "DerivedColumn3"
						},
						{
							"name": "Select1"
						}
					],
					"script": "source(output(\n\t\t{_col0_} as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> source1\nsource1 derive(url = regexSplit({_col0_},'download.microsoft.com')) ~> DerivedColumn1\nDerivedColumn1 foldDown(unroll(url, url),\n\tmapColumn(\n\t\t{_col0_},\n\t\turl\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Flatten1\nFlatten1 keyGenerate(output(rownbr as long),\n\tstartAt: 1L,\n\tstepValue: 1L) ~> SurrogateKey1\nSurrogateKey1 filter(rownbr == 2) ~> Filter1\nFilter1 derive(url2 = regexSplit(url,'.json\"')) ~> DerivedColumn2\nFlatten2 keyGenerate(output(rownbr2 as long),\n\tstartAt: 1L,\n\tstepValue: 1L) ~> SurrogateKey2\nSurrogateKey2 filter(rownbr2 == 1) ~> Filter2\nDerivedColumn2 foldDown(unroll(url2, url2),\n\tmapColumn(\n\t\t{_col0_},\n\t\turl,\n\t\trownbr,\n\t\turl2\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Flatten2\nFilter2 derive(url3 = concat(ltrim(url2,'/'),'.json')) ~> DerivedColumn3\nDerivedColumn3 select(mapColumn(\n\t\turl3\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> Select1\nSelect1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tpartitionFileNames:['jsonlink.txt'],\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tstore: 'cache',\n\tformat: 'inline',\n\toutput: true,\n\tsaveOrder: 1,\n\tpartitionBy('hash', 1)) ~> relativeURL"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/Azure_IP_Source_TXT_linkresponse')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Load_US_Pop_by_Zip_Parquet')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Parquet_US_Pop_By_Zip",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "Csv_US_Zip_codes",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "US_Pop_By_Zip_SQL_Sink",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "US_Zip_SQL_Sink",
								"type": "DatasetReference"
							},
							"name": "sink2"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          decennialTime as string,",
						"          zipCode as string,",
						"          population as integer,",
						"          race as string,",
						"          sex as string,",
						"          minAge as integer,",
						"          maxAge as integer,",
						"          year as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     format: 'parquet') ~> source1",
						"source(output(",
						"          ZipCode as string,",
						"          PlaceName as string,",
						"          State as string,",
						"          StateAbbreviation as string,",
						"          County as string,",
						"          Latitude as string,",
						"          Longitude as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     staged: true,",
						"     allowCopyCommand: true,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> sink1",
						"source2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     staged: true,",
						"     allowCopyCommand: true,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> sink2"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/Parquet_US_Pop_By_Zip')]",
				"[concat(variables('workspaceId'), '/datasets/Csv_US_Zip_codes')]",
				"[concat(variables('workspaceId'), '/datasets/US_Pop_By_Zip_SQL_Sink')]",
				"[concat(variables('workspaceId'), '/datasets/US_Zip_SQL_Sink')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Add-AAD-User')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Examples-SQL-Dedicated"
				},
				"content": {
					"query": "-- Add login from AAD:\n--CREATE USER [ored@microsoft.com] FROM EXTERNAL PROVIDER;\nCREATE USER [Orrin.Edenfield_microsoft.com#EXT#@fdpo.onmicrosoft.com] FROM EXTERNAL PROVIDER;\n\n-- Give permissions:\nEXEC sp_addrolemember 'db_datareader', 'Orrin.Edenfield_microsoft.com#EXT#@fdpo.onmicrosoft.com';\nEXEC sp_addrolemember 'db_datawriter', 'Orrin.Edenfield_microsoft.com#EXT#@fdpo.onmicrosoft.com';\nEXEC sp_addrolemember 'db_ddladmin', 'Orrin.Edenfield_microsoft.com#EXT#@fdpo.onmicrosoft.com';\nEXEC sp_addrolemember 'db_owner', 'Orrin.Edenfield_microsoft.com#EXT#@fdpo.onmicrosoft.com';",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SynapseSQLDedicated",
						"poolName": "SynapseSQLDedicated"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Add-Purview-Managed-Identity')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Examples/Purview"
				},
				"content": {
					"query": "-- Add MSI for my Purview account\nCREATE USER [palantir] FROM EXTERNAL PROVIDER\nGO\n\n-- Add permisions to the user in the database\nEXEC sp_addrolemember 'db_owner', [palantir]\nGO",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/COPYscriptByHand')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Misc"
				},
				"content": {
					"query": "-- Create the destination table with varchar data types\n/*\nDROP TABLE dbo.biketripstest;\nGO\n*/\nCREATE TABLE dbo.biketripstest\n\t(\n\t [tripduration] varchar(250),\n\t [starttime] varchar(250),\n\t [stoptime] varchar(250),\n\t [start station id] varchar(250),\n\t [start station name] varchar(250),\n\t [start station latitude] varchar(250),\n\t [start station longitude] varchar(250),\n\t [end station id] varchar(250),\n\t [end station name] varchar(250),\n\t [end station latitude] varchar(250),\n\t [end station longitude] varchar(250),\n\t [bikeid] varchar(250),\n\t [usertype] varchar(250),\n\t [birth year] varchar(250),\n\t [gender] varchar(250)\n\t)\nWITH\n\t(\n\tDISTRIBUTION = ROUND_ROBIN,\n\t CLUSTERED COLUMNSTORE INDEX\n\t -- HEAP\n\t)\nGO\n\n-- Table with real data types\nDROP TABLE dbo.biketripstesttypes;\nGO\nCREATE TABLE dbo.biketripstesttypes\n\t(\n\t [tripduration] bigint,\n\t [starttime] datetime2(0),\n\t [stoptime] datetime2(0),\n\t [start station id] bigint,\n\t [start station name] nvarchar(54),\n\t [start station latitude] float,\n\t [start station longitude] float,\n\t [end station id] bigint,\n\t [end station name] nvarchar(54),\n\t [end station latitude] float,\n\t [end station longitude] float,\n\t [bikeid] bigint,\n\t [usertype] nvarchar(30),\n\t [birth year] bigint,\n\t [gender] bigint\n\t)\nWITH\n\t(\n\tDISTRIBUTION = ROUND_ROBIN,\n\t CLUSTERED COLUMNSTORE INDEX\n\t -- HEAP\n\t)\nGO\n\n\n-- ::::::  Begin COPY INTO work\n\n/* -- FROM just 1 file, to test \nFROM 'https://minastirith.dfs.core.windows.net/datalake2020/01-fresh/biketrips/2020/202001-citibike-tripdata.csv'\n*/\n\n/* -- FROM 2020 year directory \nFROM 'https://minastirith.dfs.core.windows.net/datalake2020/01-fresh/biketrips/2020/'\n*/\n\n\n-- Run COPY into\nCOPY INTO dbo.biketripstest \nFROM 'https://minastirith.dfs.core.windows.net/datalake2020/01-fresh/biketrips/2020/'\nWITH (\n   FIELDTERMINATOR=',',\n   FIRSTROW=2,\n   ROWTERMINATOR='0x0A'\n);\n\n\n\n-- COPY into dbo.biketripstesttypes\nCOPY INTO dbo.biketripstesttypes\nFROM 'https://minastirith.dfs.core.windows.net/datalake2020/01-fresh/biketrips/2020/'\n--FROM 'https://minastirith.dfs.core.windows.net/datalake2020/01-fresh/biketrips/2020/202001-citibike-tripdata.csv'\nWITH (\n   FIELDTERMINATOR=',',\n   FIRSTROW=2,\n   ROWTERMINATOR='0x0A'\n);",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/External-Tables-00-PublicData')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Examples-SQL-Serverless"
				},
				"content": {
					"query": "/* Note: this script is filtered on a specific month. You can modify the location to read the entire dataset. */\nIF NOT EXISTS (SELECT * FROM sys.external_file_formats WHERE name = 'SynapseParquetFormat')\n\tCREATE EXTERNAL FILE FORMAT [SynapseParquetFormat]\n\tWITH ( FORMAT_TYPE = PARQUET)\nGO\n\nIF NOT EXISTS (SELECT * FROM sys.external_data_sources WHERE name = 'nyctlc_azureopendatastorage_blob_core_windows_net')\n\tCREATE EXTERNAL DATA SOURCE [nyctlc_azureopendatastorage_blob_core_windows_net]\n\tWITH (\n\t\tLOCATION = 'wasbs://nyctlc@azureopendatastorage.blob.core.windows.net',\n\t\tTYPE     = HADOOP\n\t)\nGO\n\nCREATE EXTERNAL TABLE nyc_tlc_yellow_trip_ext (\n\t[vendorID] varchar(8000),\n\t[tpepPickupDateTime] datetime2(7),\n\t[tpepDropoffDateTime] datetime2(7),\n\t[passengerCount] int,\n\t[tripDistance] float,\n\t[puLocationId] varchar(8000),\n\t[doLocationId] varchar(8000),\n\t[startLon] float,\n\t[startLat] float,\n\t[endLon] float,\n\t[endLat] float,\n\t[rateCodeId] int,\n\t[storeAndFwdFlag] varchar(8000),\n\t[paymentType] varchar(8000),\n\t[fareAmount] float,\n\t[extra] float,\n\t[mtaTax] float,\n\t[improvementSurcharge] varchar(8000),\n\t[tipAmount] float,\n\t[tollsAmount] float,\n\t[totalAmount] float\n\t)\n\tWITH (\n    LOCATION = 'yellow/puYear=2014/puMonth=3/',\n    -- LOCATION = 'yellow'\n\tDATA_SOURCE = [nyctlc_azureopendatastorage_blob_core_windows_net],\n\tFILE_FORMAT = [SynapseParquetFormat],\n\tREJECT_TYPE = VALUE,\n\tREJECT_VALUE = 0\n\t)\nGO\n\nSELECT TOP 100 * FROM nyc_tlc_yellow_trip_ext\nGO\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/External-Tables-01-My-Datalake')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Examples-SQL-Serverless"
				},
				"content": {
					"query": "-- Example external tables/resources\n/*\nYou can use external tables to:\n  - Query Azure Blob Storage and Azure Data Lake Gen2 with Transact-SQL statements.\n  - Store query results to files in Azure Blob Storage or Azure Data Lake Storage using CETAS\n  - Import data from Azure Blob Storage and Azure Data Lake Storage and store it in a dedicated SQL pool (only Hadoop tables in dedicated pool).\n    - On secont thought, use COPY INTO for this.\n*/\n\n\n-- Credential\ncreate database scoped credential msi_cred\nwith identity = 'Managed Service Identity';\n\n\n-- External data source\ndrop external data source datalake_source;\ngo\ncreate external data source datalake_source\nwith(\n    location = 'abfss://datalake@minastirith.dfs.core.windows.net'\n    ,credential = msi_cred\n    ,type = HADOOP\n);\n\n-- External file format\ncreate external file format parquet_snappy\nwith(\n     format_type = PARQUET\n    ,data_compression = 'org.apache.hadoop.io.compress.SnappyCodec'\n);\n\ncreate external file format delimitedtext_csv\nwith(\n     format_type = delimitedtext\n    ,format_options(\n        field_terminator = ','\n    )\n);\n\ncreate external file format delimitedtext_csv_skiprow1\nwith(\n     format_type = delimitedtext\n    ,format_options(\n         field_terminator = ','\n        ,first_row = 2\n    )\n);\n\n\ncreate schema ext;\n\n-- External table\ndrop external table ext.biketrips2020;\ngo\ncreate external table ext.biketrips2020\n(\n     [tripduration] [varchar](250)  NULL\n\t,[starttime] [varchar](250)  NULL\n\t,[stoptime] [varchar](250)  NULL\n\t,[start station id] [varchar](250)  NULL\n\t,[start station name] [varchar](250)  NULL\n\t,[start station latitude] [varchar](250)  NULL\n\t,[start station longitude] [varchar](250)  NULL\n\t,[end station id] [varchar](250)  NULL\n\t,[end station name] [varchar](250)  NULL\n\t,[end station latitude] [varchar](250)  NULL\n\t,[end station longitude] [varchar](250)  NULL\n\t,[bikeid] [varchar](250)  NULL\n\t,[usertype] [varchar](250)  NULL\n\t,[birth year] [varchar](250)  NULL\n\t,[gender] [varchar](250)  NULL\n)\nWITH\n(\n    LOCATION='/01-fresh/biketrips/2020/' ,\n    DATA_SOURCE = datalake_source ,\n    FILE_FORMAT = delimitedtext_csv_skiprow1\n);\n\n-- Query data\nselect top 10 * from ext.biketrips2020;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Read-Delta-Lake')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Examples-SQL-Serverless"
				},
				"content": {
					"query": "use serverlessDB;\n\n-- openrowset example\n-- The URI in the OPENROWSET function must reference the root Delta Lake folder that contains a subfolder called _delta_log\nselect top 10 *\nfrom openrowset(\n    bulk 'https://minastirith.blob.core.windows.net/datalake/03-serve/biketrips-deltalake/',\n    format = 'delta') as rows\n\n-- Calculate some aggregate columns\nselect YEAR(StartTime) as [Year], MONTH(StartTime) as [Month], count(*) as [RecordCount]\nfrom openrowset(\n    bulk 'https://minastirith.blob.core.windows.net/datalake/03-serve/biketrips-deltalake/',\n    format = 'delta') as rows\ngroup by YEAR(StartTime), MONTH(StartTime)\n\n\n-- Create external data source\ncreate external data source DeltaLakeStorageBikeTrips\nwith ( location = 'https://minastirith.blob.core.windows.net/datalake/03-serve/biketrips-deltalake/' );\n\n-- openrowset with external data source\nselect top 10 *\nfrom openrowset(\n        bulk '/',\n        data_source = 'DeltaLakeStorageBikeTrips',\n        format = 'delta'\n    ) as rows\n\n-- best practice to specify a schema\nselect top 10 *\nfrom openrowset(\n        bulk '/',\n        data_source = 'DeltaLakeStorageBikeTrips',\n        format = 'delta'\n    )\n    with (  TripDuration varchar(75)\n           ,StartTime varchar(75)\n           ,StopTime varchar(75)\n           ,StartStationId varchar(75)\n           ,StartStationName varchar(75)\n           ,StartStationLatitude varchar(75)\n           ,StartStationLongitude varchar(75)\n           ,EndStationId varchar(75)\n           ,EndStationName varchar(75)\n           ,EndStationLatitude varchar(75)\n           ,EndStationLongitude varchar(75)\n           ,BikeId varchar(75)\n           ,UserType varchar(75)\n           ,BirthYear varchar(75)\n           ,Gender varchar(75)\n           ) as rows",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL-Dedicated-DDM-Example-01')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Examples-SQL-Dedicated"
				},
				"content": {
					"query": "/*\nDynamic data masking example for Azure Synapse SQL Dedicated\n*/\n\n-- in ddmtesting2 database\n\n-- create schema\ncreate schema ddm;\n\n\n/*\ndrop table dbo.securedata;\n*/\n\n-- create table\ncreate table ddm.securedata(\n     [MemberID]         int not null\n    ,[FirstName]        varchar(100) not null\n    ,[LastName]         varchar(100) not null\n    ,[PostalAddress]    varchar(100) not null\n    ,[CreditCard]       decimal(16,0) not null\n)\nwith\n(\n\t distribution = round_robin\n    ,clustered columnstore index\n);\n\n\n-- insert some data\ninsert into ddm.securedata values (1234,'Francisque','Thandeka','100 High Street',1111222233334444);\ninsert into ddm.securedata values (1235,'Vanda','Maeleachlainn','101 High Street',2222333344445555);\ninsert into ddm.securedata values (1236,'Josefina','Visnja','102 High Street',3333444455556666);\ninsert into ddm.securedata values (1237,'Andrés','Winfrith','103 High Street',4444555566667777);\ninsert into ddm.securedata values (1239,'Josephus','Panos','105 High Street',6666777788889999);\n\n-- View data in table\nselect * from ddm.securedata;\n-- All data visible to everyone who has access to the table.\n/*\nMemberID    FirstName   LastName        PostalAddress       CreditCard\n1234\t    Francisque\tThandeka\t    100 High Street\t    1111222233334444\n1237\t    Andrés\t    Winfrith\t    103 High Street\t    4444555566667777\n1236\t    Josefina\tVisnja\t        102 High Street\t    3333444455556666\n1239\t    Josephus\tPanos\t        105 High Street\t    6666777788889999\n1235\t    Vanda\t    Maeleachlainn\t101 High Street\t    2222333344445555\n*/\n\n\n-- Create user accounts\ncreate user User1 without login;\ncreate user User2 without login;\ncreate user User3 without login;\n\n-- Give users access to run select against the objects in schema ddm\ngrant select on schema::ddm to User1\ngrant select on schema::ddm to User2\ngrant select on schema::ddm to User3\n\n\n-- add masking to the table\nalter table ddm.securedata alter column PostalAddress add masked with (function = 'default()');\nalter table ddm.securedata alter column CreditCard add masked with (function = 'random(1, 100)');\n\n-- remove masking from the table - only run this for testing, don't remove masking when running test expecting to see masked data\n/*\nalter table dbo.securedata alter column PostalAddress drop masked;\nalter table dbo.securedata alter column CreditCard drop masked;\n*/\n\n-- Check the data:\nselect * from ddm.securedata;\n-- Data is not masked for me (ored@microsoft.com, AAD Admin)\n\n\n-- What User1 would see\nexecute as user = 'User1';  \nselect * from ddm.securedata;\nrevert;\n-- both columns are masked\n\n-- What User2 would see\nexecute as user = 'User2';  \nselect * from ddm.securedata;\nrevert;\n-- both columns are masked\n\n-- What User3 would see\nexecute as user = 'User3';  \nselect * from ddm.securedata;\nrevert;\n-- both columns are masked\n\n/*\n-- Customer has requirement that \n\tUser1 be able to see [PostalAddress]\n\tUser2 be able to see [CreditCard]\n\tUser3 be able to see [PostalAddress] & [CreditCard]\n*/\n-- Allow User3 to see the masked data, User3 can now see [PostalAddress] & [CreditCard] unmasked\ngrant unmask on ddm.securedata(PostalAddress) to User1;\ngrant unmask on ddm.securedata(CreditCard) to User2;\ngrant unmask to User3;\n\n\n-- What User1 would see\nexecute as user = 'User1';  \nselect * from ddm.securedata;\nrevert;\n-- both columns are masked (not as expected)\n-- Expected: PostalAddress to be unmasked\n\n-- What User2 would see\nexecute as user = 'User2';  \nselect * from ddm.securedata;\nrevert;\n-- both columns are masked (not as expected)\n-- Expected: CreditCard to be unmasked\n\n-- What User3 would see\nexecute as user = 'User3';  \nselect * from ddm.securedata;\nrevert;\n-- both columns are unmasked (as expected)",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQLserverlessByHand-1')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Examples-SQL-Serverless"
				},
				"content": {
					"query": "--=====================================================================\n--====== DELIMITED DATA ===============================================\n--=====================================================================\n\n-- Full path to one file\nSELECT top 10 *\nfrom OPENROWSET(\n    bulk 'https://minastirith.dfs.core.windows.net/datalake2020/01-fresh/biketrips/2020/202012-citibike-tripdata.csv',\n    format = 'csv',\n    parser_version = '2.0',\n    FIRSTROW = 2\n) as rows\n\n-- Use header row for column names\nSELECT top 10 *\nfrom OPENROWSET(\n    bulk 'https://minastirith.dfs.core.windows.net/datalake2020/01-fresh/biketrips/2020/202012-citibike-tripdata.csv',\n    format = 'csv',\n    parser_version = '2.0',\n    header_row = true\n) as rows\n\n\n-- Using a data source\ncreate external data source biketrips\nwith (location='https://minastirith.dfs.core.windows.net/datalake2020/01-fresh/biketrips/');\n\nselect top 10 *\nfrom OPENROWSET(\n     bulk '2020/202012-citibike-tripdata.csv'\n    ,data_source = 'biketrips'\n    ,format = 'csv'\n    ,parser_version='2.0'\n    --,FIRSTROW=2\n) as rows;\n\n-- Explicitly specify a schema\nselect top 10 *\nfrom OPENROWSET(\n    bulk '2020/202012-citibike-tripdata.csv',\n    data_source = 'biketrips',\n    format='csv',\n    parser_version='2.0',\n    FIRSTROW=2\n) with(\n     tripduration varchar(50)\n    ,starttime varchar(50)\n    ,stoptime varchar(50)\n    ,start_station_id varchar(50)\n) as rows\n\n-- Find collation of the database:\nSELECT CONVERT (varchar, SERVERPROPERTY('collation')) AS 'Server Collation';\n\n\n-- Below uses data that can be queried by running this setup script:\n-- https://github.com/Azure-Samples/Synapse/blob/main/SQL/Samples/LdwSample/SampleDB.sql\n\n-- Read Windows-style new line files \nSELECT *\nFROM OPENROWSET(\n        BULK 'csv/population/population.csv',\n        DATA_SOURCE = 'SqlOnDemandDemo',\n        FORMAT = 'CSV', PARSER_VERSION = '2.0',\n        FIELDTERMINATOR =',',\n        ROWTERMINATOR = '\\n'\n    )\nWITH (\n    [country_code] VARCHAR (5) COLLATE Latin1_General_BIN2,\n    [country_name] VARCHAR (100) COLLATE Latin1_General_BIN2,\n    [year] smallint,\n    [population] bigint\n) AS [r]\nWHERE\n    country_name = 'Luxembourg'\n    AND year = 2017;\n\n-- Read UNIX-style new line files\nSELECT * \nFROM OPENROWSET( \n    BULK 'csv/population-unix/population.csv', \n    DATA_SOURCE = 'SqlOnDemandDemo', \n    FORMAT = 'CSV', PARSER_VERSION = '2.0', \n    FIELDTERMINATOR =',', \n    ROWTERMINATOR = '0x0a' ) \nWITH ( \n    [country_code] VARCHAR (5) COLLATE Latin1_General_BIN2, \n    [country_name] VARCHAR (100) COLLATE Latin1_General_BIN2, \n    [year] smallint, [population] bigint \n) AS [r] \nWHERE \n    country_name = 'Luxembourg' \n    AND year = 2017;\n\n-- Work with custom quote character\n-- This query would return the same results if you omitted the FIELDQUOTE parameter since the default value for FIELDQUOTE is a double-quote.\nSELECT * \nFROM OPENROWSET( \n    BULK 'csv/population-unix-hdr-quoted/population.csv', \n    DATA_SOURCE = 'SqlOnDemandDemo', \n    FORMAT = 'CSV', PARSER_VERSION = '2.0', \n    FIELDTERMINATOR =',', \n    ROWTERMINATOR = '0x0a',\n    FIRSTROW = 2,\n    FIELDQUOTE = ' ” '\n) \nWITH ( \n    [country_code] VARCHAR (5) COLLATE Latin1_General_BIN2, \n    [country_name] VARCHAR (100) COLLATE Latin1_General_BIN2, \n    [year] smallint, [population] bigint \n) AS [r] \nWHERE \n    country_name = 'Luxembourg' \n    AND year = 2017;\n\n\n-- Work with escape characters\n-- This query would fail if ESCAPECHAR is not specified since the comma in \"Slov,enia\" would be treated as field delimiter instead of part of the country/region name. \"Slov,enia\" would be treated as two columns. Therefore, the row would have one column more than the other rows, and one column more than you defined in the WITH clause.\nSELECT * \nFROM OPENROWSET( \n    BULK 'csv/population-unix-hdr-escape/population.csv', \n    DATA_SOURCE = 'SqlOnDemandDemo', \n    FORMAT = 'CSV', PARSER_VERSION = '2.0', \n    FIELDTERMINATOR =',', \n    ROWTERMINATOR = '0x0a',\n    FIRSTROW = 2,\n    ESCAPECHAR = ' \\\\ '\n) \nWITH ( \n    [country_code] VARCHAR (5) COLLATE Latin1_General_BIN2, \n    [country_name] VARCHAR (100) COLLATE Latin1_General_BIN2, \n    [year] smallint, \n    [population] bigint \n) AS [r] \nWHERE \n    country_name = 'Slovenia';\n\n\n-- Work with escape quoting characters\nSELECT * \nFROM OPENROWSET( \n    BULK 'csv/population-unix-hdr-escape-quoted/population.csv', \n    DATA_SOURCE = 'SqlOnDemandDemo', \n    FORMAT = 'CSV', PARSER_VERSION = '2.0', \n    FIELDTERMINATOR =',', \n    ROWTERMINATOR = '0x0a',\n    FIRSTROW = 2\n) \nWITH ( \n    [country_code] VARCHAR (5) COLLATE Latin1_General_BIN2, \n    [country_name] VARCHAR (100) COLLATE Latin1_General_BIN2, \n    [year] smallint, \n    [population] bigint \n) AS [r] \nWHERE \n    country_name = 'Slovenia';\n\n\n-- Work with tab-delimited files\nSELECT * \nFROM OPENROWSET( \n    BULK 'csv/population-unix-hdr-tsv/population.csv', \n    DATA_SOURCE = 'SqlOnDemandDemo', \n    FORMAT = 'CSV', PARSER_VERSION = '2.0', \n    FIELDTERMINATOR ='\\t', \n    ROWTERMINATOR = '0x0a',\n    FIRSTROW = 2\n) \nWITH ( \n    [country_code] VARCHAR (5) COLLATE Latin1_General_BIN2, \n    [country_name] VARCHAR (100) COLLATE Latin1_General_BIN2, \n    [year] smallint, \n    [population] bigint \n) AS [r] \nWHERE \n    country_name = 'Slovenia'\n    AND year = 2017\n\n\n-- Return a subset of columns from a file\n-- Look at the WITH clause in the query below and note that there is \"2\" (without quotes) at the end of row where you define the [country_name] column. It means that the [country_name] column is the second column in the file. The query will ignore all columns in the file except the second one.\nSELECT \n    COUNT(DISTINCT country_name) AS countries \nFROM OPENROWSET(\n    BULK 'csv/population/population.csv', \n    DATA_SOURCE = 'SqlOnDemandDemo', \n    FORMAT = 'CSV', PARSER_VERSION = '2.0', \n    FIELDTERMINATOR =',', \n    ROWTERMINATOR = '\\n' ) \nWITH ( \n    --[country_code] VARCHAR (5), \n    [country_name] VARCHAR (100) 2 \n    --[year] smallint, \n    --[population] bigint \n) AS [r]\n\n\n--=====================================================================\n--====== PARQUET DATA =================================================\n--=====================================================================\n\n-- Parquet works much the same as CSV except you change the FORMAT value\nSELECT top 10 *\nfrom OPENROWSET(\n     bulk 'https://minastirith.dfs.core.windows.net/datalake2020/02-curated/biketrips/onefile/biketrips.parquet/part-00000-a763e5c2-062d-4f7b-8347-71f788fb0ab1-c000.snappy.parquet'\n    ,FORMAT='parquet'\n) as rows\n\n-- Again, queries below this use the setup script data\n-- https://github.com/Azure-Samples/Synapse/blob/master/SQL/Samples/LdwSample/SampleDB.sql\n\n-- Query specific column of parquet files\nSELECT \n    YEAR(tpepPickupDateTime), \n    passengerCount, \n    COUNT(*) AS cnt \nFROM \n    OPENROWSET( \n        BULK 'puYear=2018/puMonth=*/*.snappy.parquet', \n        DATA_SOURCE = 'YellowTaxi', \n        FORMAT='PARQUET' \n    ) WITH ( \n        tpepPickupDateTime DATETIME2, \n        passengerCount INT \n    ) AS nyc \nGROUP BY \n    passengerCount, \n    YEAR(tpepPickupDateTime) \nORDER BY \n    YEAR(tpepPickupDateTime), \n    passengerCount;\n\n-- Query partitioned data\n-- The serverless SQL pool query is compatible with Hive/Hadoop partitioning scheme.\nSELECT \n    YEAR(tpepPickupDateTime), \n    passengerCount, \n    COUNT(*) AS cnt \nFROM \n    OPENROWSET(\n        BULK 'puYear=*/puMonth=*/*.snappy.parquet', \n        DATA_SOURCE = 'YellowTaxi', \n        FORMAT='PARQUET' ) nyc \nWHERE \n    nyc.filepath(1) = 2017 \n    AND nyc.filepath(2) IN (1, 2, 3) \n    AND tpepPickupDateTime BETWEEN CAST('1/1/2017' AS datetime) AND CAST('3/31/2017' AS datetime)\nGROUP BY \n    passengerCount, \n    YEAR(tpepPickupDateTime) \nORDER BY \n    YEAR(tpepPickupDateTime), \n    passengerCount;\n\n-- Data type mapping\n-- https://docs.microsoft.com/en-us/learn/modules/query-data-lake-using-azure-synapse-serverless-sql-pools/3-query-parquet-file#data-type-mapping\n\n\n--=====================================================================\n--====== JSDON DATA ===================================================\n--=====================================================================\n\n-- Pandemic Data Lake data used below is publically accessible\n\n-- Read JSONL files\nselect top 10 * \nfrom \n    openrowset( \n        bulk 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.jsonl', \n        format = 'csv', \n        fieldterminator ='0x0b', \n        fieldquote = '0x0b' \n    ) with (doc nvarchar(max)) as rows\n\n-- Read JSON files\nselect top 10 * \nfrom \n    openrowset( \n        bulk 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.json', \n        format = 'csv', \n        fieldterminator ='0x0b', \n        fieldquote = '0x0b', \n        rowterminator = '0x0b' --> You need to override rowterminator to read classic JSON \n    ) with (doc nvarchar(max)) as rows\n\n-- Parse the JSON files using JSON_VALUE\nselect \n    JSON_VALUE(doc, '$.date_rep') AS date_reported, \n    JSON_VALUE(doc, '$.countries_and_territories') AS country, \n    JSON_VALUE(doc, '$.cases') as cases, \n    doc \nfrom \n    openrowset( \n        bulk 'latest/ecdc_cases.jsonl', \n        data_source = 'covid', \n        format = 'csv', \n        fieldterminator ='0x0b', \n        fieldquote = '0x0b' \n    ) with (doc nvarchar(max)) as rows \norder by JSON_VALUE(doc, '$.geo_id') desc\n\n-- Parse the JSON files using OPENJSON\nselect * \nfrom \n    openrowset( \n        bulk 'latest/ecdc_cases.jsonl', \n        data_source = 'covid', \n        format = 'csv', \n        fieldterminator ='0x0b', \n        fieldquote = '0x0b' \n    ) with (doc nvarchar(max)) as rows \n    cross apply openjson (doc) \n        with ( date_rep datetime2, \n                   cases int, \n                   fatal int '$.deaths', \n                   country varchar(100) '$.countries_and_territories') \nwhere country = 'Serbia' \norder by country, date_rep desc;\n\n\n--=====================================================================\n--====== MULTIPLE FILES ===============================================\n--=====================================================================\n\n-- Again, queries below this use the setup script data\n-- https://github.com/Azure-Samples/Synapse/blob/master/SQL/Samples/LdwSample/SampleDB.sql\n\n-- Read all files in folder\n-- All files accessed with the single OPENROWSET must have the same structure (i.e., number of columns and their data types).\nSELECT \n    YEAR(pickup_datetime) AS [year], \n    SUM(passenger_count) AS passengers_total, \n    COUNT(*) AS [rides_total] \nFROM \n    OPENROWSET( \n        BULK 'csv/taxi/*.csv',                 -- LOOK HERE\n        DATA_SOURCE = 'sqlondemanddemo', \n        FORMAT = 'CSV', \n        PARSER_VERSION = '2.0', \n        FIRSTROW = 2 \n    ) WITH ( \n        pickup_datetime DATETIME2 2, \n        passenger_count INT 4 \n    ) AS nyc \nGROUP BY \n    YEAR(pickup_datetime) \nORDER BY \n    YEAR(pickup_datetime);\n\n\n-- Read subset of files in folder\nSELECT \n    payment_type,\n    SUM(fare_amount) AS fare_total\nFROM \n    OPENROWSET( \n        BULK 'csv/taxi/yellow_tripdata_2017-*.csv', \n        DATA_SOURCE = 'sqlondemanddemo', \n        FORMAT = 'CSV', \n        PARSER_VERSION = '2.0', \n        FIRSTROW = 2 \n    ) WITH ( \n        payment_type INT 10, \n        fare_amount FLOAT 11 \n    ) AS nyc \nGROUP BY \n    payment_type \nORDER BY \n    payment_type;\n\n-- Read all files from a specific folder\nSELECT \n    YEAR(pickup_datetime) as [year], \n    SUM(passenger_count) AS passengers_total, \n    COUNT(*) AS [rides_total] \nFROM OPENROWSET( \n    BULK 'csv/taxi/', \n    DATA_SOURCE = 'sqlondemanddemo', \n    FORMAT = 'CSV', \n    PARSER_VERSION = '2.0', \n    FIRSTROW = 2 \n) WITH ( \n    vendor_id VARCHAR(100) COLLATE Latin1_General_BIN2, \n    pickup_datetime DATETIME2, \n    dropoff_datetime DATETIME2, \n    passenger_count INT, \n    trip_distance FLOAT, \n    rate_code INT, \n    store_and_fwd_flag VARCHAR(100) COLLATE Latin1_General_BIN2, \n    pickup_location_id INT, \n    dropoff_location_id INT, \n    payment_type INT, \n    fare_amount FLOAT, \n    extra FLOAT, \n    mta_tax FLOAT, \n    tip_amount FLOAT, \n    tolls_amount FLOAT, \n    improvement_surcharge FLOAT, \n    total_amount FLOAT \n) AS nyc \nGROUP BY \n    YEAR(pickup_datetime) \nORDER BY \n    YEAR(pickup_datetime);\n\n\n-- Read all files from multiple folders\nSELECT\n    YEAR(pickup_datetime) as [year],\n    SUM(passenger_count) AS passengers_total,\n    COUNT(*) AS [rides_total]\nFROM OPENROWSET(\n        BULK 'csv/t*i/', \n        DATA_SOURCE = 'sqlondemanddemo',\n        FORMAT = 'CSV', PARSER_VERSION = '2.0',\n        FIRSTROW = 2\n    )\n    WITH (\n        vendor_id VARCHAR(100) COLLATE Latin1_General_BIN2, \n        pickup_datetime DATETIME2, \n        dropoff_datetime DATETIME2,\n        passenger_count INT,\n        trip_distance FLOAT,\n        rate_code INT,\n        store_and_fwd_flag VARCHAR(100) COLLATE Latin1_General_BIN2,\n        pickup_location_id INT,\n        dropoff_location_id INT,\n        payment_type INT,\n        fare_amount FLOAT,\n        extra FLOAT,\n        mta_tax FLOAT,\n        tip_amount FLOAT,\n        tolls_amount FLOAT,\n        improvement_surcharge FLOAT,\n        total_amount FLOAT\n    ) AS nyc\nGROUP BY\n    YEAR(pickup_datetime)\nORDER BY\n    YEAR(pickup_datetime);\n\n-- Use multiple wildcards\nSELECT\n    YEAR(pickup_datetime) as [year],\n    SUM(passenger_count) AS passengers_total,\n    COUNT(*) AS [rides_total]\nFROM OPENROWSET(\n        BULK 'csv/t*i/yellow_tripdata_2017-*.csv',\n        DATA_SOURCE = 'sqlondemanddemo',\n        FORMAT = 'CSV', PARSER_VERSION = '2.0',\n        FIRSTROW = 2\n    )\n    WITH (\n        vendor_id VARCHAR(100) COLLATE Latin1_General_BIN2, \n        pickup_datetime DATETIME2, \n        dropoff_datetime DATETIME2,\n        passenger_count INT,\n        trip_distance FLOAT,\n        rate_code INT,\n        store_and_fwd_flag VARCHAR(100) COLLATE Latin1_General_BIN2,\n        pickup_location_id INT,\n        dropoff_location_id INT,\n        payment_type INT,\n        fare_amount FLOAT,\n        extra FLOAT,\n        mta_tax FLOAT,\n        tip_amount FLOAT,\n        tolls_amount FLOAT,\n        improvement_surcharge FLOAT,\n        total_amount FLOAT\n    ) AS nyc\nGROUP BY\n    YEAR(pickup_datetime)\nORDER BY\n    YEAR(pickup_datetime);\n\n\n\n\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQLserverlessByHand-2')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Examples-SQL-Serverless"
				},
				"content": {
					"query": "-- Creating SQL Serverless databases\nCREATE DATABASE newdbname;\n\n\n-- Creating credentials in Azure Synapse serverless SQL pools\n-- AAD\nCREATE DATABASE SCOPED CREDENTIAL [sqlondemand] \nWITH IDENTITY='User Identity'\n\n-- Managed Identity for this Synapse workspace\nCREATE DATABASE SCOPED CREDENTIAL [sqlondemand] \nWITH IDENTITY='Managed Identity'\n\n-- SAS token\nCREATE DATABASE SCOPED CREDENTIAL [sqlondemand] \nWITH IDENTITY='SHARED ACCESS SIGNATURE',   \nSECRET = 'sv=2018-03-28&ss=bf&srt=sco&sp=rl&st=2019-10-14T12%3A10%3A25Z&se=2061-12-31T12%3A10%3A00Z&sig=KlSU2ullCscyTS0An0nozEpo4tO5JAgGBvw%2FJX2lguw%3D'\n\n\n-- External data sources\nCREATE EXTERNAL DATA SOURCE YellowTaxi \nWITH ( LOCATION = 'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/')\n\nCREATE EXTERNAL DATA SOURCE SqlOnDemandDemo WITH ( \n    LOCATION = 'https://sqlondemandstorage.blob.core.windows.net', \n    CREDENTIAL = sqlondemand \n);\n\n-- External tables\n-- 3 objects needed\n--    External data source\n--    External file format\n--    External table\n\n-- Below uses the setup script\n-- https://github.com/Azure-Samples/Synapse/blob/master/SQL/Samples/LdwSample/SampleDB.sql\n\n-- Database scoped credential\nCREATE DATABASE SCOPED CREDENTIAL [sqlondemand] \nWITH IDENTITY='SHARED ACCESS SIGNATURE',   \nSECRET = 'sv=2018-03-28&ss=bf&srt=sco&sp=rl&st=2019-10-14T12%3A10%3A25Z&se=2061-12-31T12%3A10%3A00Z&sig=KlSU2ullCscyTS0An0nozEpo4tO5JAgGBvw%2FJX2lguw%3D'\n\n-- External data source\nCREATE EXTERNAL DATA SOURCE SqlOnDemandDemo WITH ( \n    LOCATION = 'https://sqlondemandstorage.blob.core.windows.net', \n    CREDENTIAL = sqlondemand \n); \nGO \nCREATE EXTERNAL DATA SOURCE YellowTaxi \nWITH ( LOCATION = 'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/')\nGO\n\n-- External file format\nCREATE EXTERNAL FILE FORMAT QuotedCsvWithHeaderFormat \nWITH (   \n    FORMAT_TYPE = DELIMITEDTEXT, \n    FORMAT_OPTIONS ( FIELD_TERMINATOR = ',', STRING_DELIMITER = '\"', FIRST_ROW = 2   ) \n); \nGO \nCREATE EXTERNAL FILE FORMAT ParquetFormat WITH (  FORMAT_TYPE = PARQUET );\nGO\n\n-- Create the external table (on the secured data)\nUSE [mydbname]; \nGO \nCREATE EXTERNAL TABLE populationExternalTable \n( \n    [country_code] VARCHAR (5) COLLATE Latin1_General_BIN2, \n    [country_name] VARCHAR (100) COLLATE Latin1_General_BIN2, \n    [year] smallint, \n    [population] bigint \n) \nWITH ( \n    LOCATION = 'csv/population/population.csv', \n    DATA_SOURCE = sqlondemanddemo, \n    FILE_FORMAT = QuotedCSVWithHeaderFormat \n);\n\n\n-- Create the external table (on the public data)\nCREATE EXTERNAL TABLE Taxi ( \n    vendor_id VARCHAR(100) COLLATE Latin1_General_BIN2,  \n    pickup_datetime DATETIME2,  \n    dropoff_datetime DATETIME2, \n    passenger_count INT, \n    trip_distance FLOAT, \n    fare_amount FLOAT, \n    tip_amount FLOAT, \n    tolls_amount FLOAT, \n    total_amount FLOAT \n) WITH ( \n        LOCATION = 'puYear=*/puMonth=*/*.parquet', \n        DATA_SOURCE = YellowTaxi, \n        FILE_FORMAT = ParquetFormat \n);\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Serverless-Biketrips-01')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Examples-SQL-Serverless/biketrips"
				},
				"content": {
					"query": "-- Read multiple files with same schema\n-- This is auto-generated code\nSELECT\n    TOP 100 *\nFROM\n    OPENROWSET(\n        BULK (\n            'https://gondor2.dfs.core.windows.net/calembel/01-raw/biketrips/2022/202201-citibike-tripdata.csv',\n\t\t\t'https://gondor2.dfs.core.windows.net/calembel/01-raw/biketrips/2022/202202-citibike-tripdata.csv',\n\t\t\t'https://gondor2.dfs.core.windows.net/calembel/01-raw/biketrips/2022/202203-citibike-tripdata.csv',\n\t\t\t'https://gondor2.dfs.core.windows.net/calembel/01-raw/biketrips/2022/202204-citibike-tripdata.csv',\n\t\t\t'https://gondor2.dfs.core.windows.net/calembel/01-raw/biketrips/2022/202205-citibike-tripdata.csv',\n\t\t\t'https://gondor2.dfs.core.windows.net/calembel/01-raw/biketrips/2022/202206-citbike-tripdata.csv',\n\t\t\t'https://gondor2.dfs.core.windows.net/calembel/01-raw/biketrips/2022/202207-citbike-tripdata.csv'\n        ),\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0'\n    ) AS [result]\n\n\n-- Create Synapse SQL Serverless database\ncreate database biketrips collate Latin1_General_100_BIN2_UTF8;\n\n-- Use the new database\nuse biketrips;\n\n-- Create master key for encryption, only do this once.\n-- Using:!r@PMK5cfCWn%f#qJjmJ\ncreate master key encryption by password='INSERT HERE';\n\n-- Create scoped credential\ncreate database scoped credential WorkspaceIdentity with identity = 'Managed Identity';\ngo\n\n-- Create external data source\nIF NOT EXISTS (SELECT * FROM sys.external_data_sources WHERE name = 'calembel_gondor2_dfs_core_windows_net') \n\tCREATE EXTERNAL DATA SOURCE [calembel_gondor2_dfs_core_windows_net] \n\tWITH (\n\t\tLOCATION = 'abfss://calembel@gondor2.dfs.core.windows.net' \n\t)\nGO\n\n-- Create external file formats\nIF NOT EXISTS (SELECT * FROM sys.external_file_formats WHERE name = 'SynapseDelimitedTextFormat') \n\tCREATE EXTERNAL FILE FORMAT [SynapseDelimitedTextFormat] \n\tWITH ( FORMAT_TYPE = DELIMITEDTEXT ,\n\t       FORMAT_OPTIONS (\n\t\t\t FIELD_TERMINATOR = ',',\n\t\t\t USE_TYPE_DEFAULT = FALSE\n\t\t\t))\nGO\n\n-- Do this format too\ncreate external file format ParquetExternalFormat with (format_type=PARQUET);\ngo\n\n\n\n-- Explore some data\nselect top 10  *\nfrom openrowset(\n    bulk '2022/', \n    data_source = 'biketrips_raw_source', \n    format='CSV',\n    PARSER_VERSION = '2.0'\n    ) as a\n\n\n\n-- Create a table\nCREATE EXTERNAL TABLE biketrips202207 (\n\t[ride_id] nvarchar(4000),\n\t[rideable_type] nvarchar(4000),\n\t[started_at] datetime2(0),\n\t[ended_at] datetime2(0),\n\t[start_station_name] nvarchar(4000),\n\t[start_station_id] float,\n\t[end_station_name] nvarchar(4000),\n\t[end_station_id] float,\n\t[start_lat] float,\n\t[start_lng] float,\n\t[end_lat] float,\n\t[end_lng] float,\n\t[member_casual] nvarchar(4000)\n\t)\n\tWITH (\n\tLOCATION = '01-raw/biketrips/2022/202207-citbike-tripdata.csv',\n\tDATA_SOURCE = [calembel_gondor2_dfs_core_windows_net],\n\tFILE_FORMAT = [SynapseDelimitedTextFormat]\n\t)\nGO\n\n-- Query new external table\nSELECT TOP 10 * FROM dbo.biketrips202207;\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "biketrips",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SynapseLink-CosmosDB-01')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Examples-SQL-Serverless"
				},
				"content": {
					"query": "/*  \n-- Create the credential that is used to access\nCREATE CREDENTIAL [howtoanalytics-cosmosdb]\nWITH IDENTITY = 'SHARED ACCESS SIGNATURE', SECRET = '2EBVHRxK6KLS7ZCyrWHrY4k5CEmqyL25CGM18AFIwGCgHibwoVfhKCuLAU0fLvE5ChueH3gTGXSGw14I36y3gw=='\n*/\n\n\n\nSELECT TOP 100 *\nFROM OPENROWSET(​PROVIDER = 'CosmosDB', CONNECTION = 'Account=howtoanalytics;Database=biketrips',\n    OBJECT = 'data2021', SERVER_CREDENTIAL = 'howtoanalytics-cosmosdb' ) AS [data2021];\n\n-- Create database\n--create database sqlserverless;\n\n-- To copy the data into the data lake, we need to use CETAS & to use that we need to create an external data source & format\nCREATE EXTERNAL DATA SOURCE [datalake] WITH (LOCATION = 'https://minastirith.dfs.core.windows.net/datalake2020');\nCREATE EXTERNAL FILE FORMAT [parquet] WITH (FORMAT_TYPE = PARQUET, DATA_COMPRESSION = 'org.apache.hadoop.io.compress.SnappyCodec'); \nCREATE EXTERNAL FILE FORMAT [delimitedtext] WITH (FORMAT_TYPE = DELIMITEDTEXT);\n\nCREATE EXTERNAL FILE FORMAT csvtext WITH (FORMAT_TYPE = DELIMITEDTEXT, FORMAT_OPTIONS (FIELD_TERMINATOR = ','));\n\n\n-- 01-fresh/synapselink-cosmosdb/\n\n-- Drop external tables\ndrop EXTERNAL TABLE biketrips2021_parquet;\ndrop EXTERNAL TABLE biketrips2021_delimited;\n\n-- Create External table to copy data into Data Lake from Cosmos DB:\nCREATE EXTERNAL TABLE biketrips2021_parquet\nWITH (\n    LOCATION = '01-fresh/synapselink-cosmosdb/parquet',\n    DATA_SOURCE = datalake,  \n    FILE_FORMAT = parquet\n)  \nAS\nSELECT *\nFROM OPENROWSET(​PROVIDER = 'CosmosDB', CONNECTION = 'Account=howtoanalytics;Database=biketrips',\n                OBJECT = 'data2021', SERVER_CREDENTIAL = 'howtoanalytics-cosmosdb' ) AS [data2021];\nGO\n-- 00:00:16\n\nCREATE EXTERNAL TABLE biketrips2021_delimited\nWITH (\n    LOCATION = '01-fresh/synapselink-cosmosdb/delimitedtext',\n    DATA_SOURCE = datalake,  \n    FILE_FORMAT = csvtext\n)  \nAS\nSELECT *\nFROM OPENROWSET(​PROVIDER = 'CosmosDB', CONNECTION = 'Account=howtoanalytics;Database=biketrips',\n                OBJECT = 'data2021', SERVER_CREDENTIAL = 'howtoanalytics-cosmosdb' ) AS [data2021];\nGO\n-- 00:00:14\n\n-- you can query the newly created external table\nSELECT count(*) FROM biketrips2021_parquet\n-- 3,224,034\n\nSELECT count(*) FROM biketrips2021_delimited\n-- 3,224,034",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/US-Zip-Code-01')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT TOP (100) [decennialTime]\n,[zipCode]\n,[population]\n,[race]\n,[sex]\n,[minAge]\n,[maxAge]\n,[year]\n FROM [dbo].[US_Pop_by_Zip]\n\n select \n FROM [dbo].[US_Pop_by_Zip]\n\n\n\n \n select top 10 *\n from dbo.US_Zip",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SynapseSQLDedicated",
						"poolName": "SynapseSQLDedicated"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/buildings-iot-data-analytics')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Examples-SQL-Dedicated/operational-analytics"
				},
				"content": {
					"query": "-- Create external table\ndrop external table ext.buildings_sensors;\ngo\ncreate external table ext.buildings_sensors\n(\n     ISO8601 varchar(20)\n    ,deviceid varchar(20)\n    ,avg_temperature float\n    ,avg_humidity float\n)\nWITH\n(\n    LOCATION='03-serve/iot-data/buildings-by-hour/',\n    DATA_SOURCE = datalake2020_source,\n    FILE_FORMAT = parquet_snappy\n);\n\n-- Test the external table\nselect top 10 * from ext.buildings_sensors\nselect count(*) from ext.buildings_sensors\n-- 91\nselect *\nfrom ext.buildings_sensors order by ISO8601 desc, deviceid asc\n\n\nCREATE SCHEMA staging;\n\n-- CTAS for staging table\ndrop table staging.buildings;\ngo\ncreate table staging.buildings\nwith\n(\n    DISTRIBUTION = ROUND_ROBIN\n    ,HEAP\n)\nas \nselect * from ext.buildings_sensors;\n\nselect * from staging.buildings\n\n-- Put new records in staging\nselect * from staging.buildings\norder by ISO8601 desc, deviceid asc\n\nselect * from ext.buildings_sensors\norder by ISO8601 desc, deviceid asc\n\n-- one time\ntruncate table staging.buildings;\ninsert into staging.buildings\nselect\n     e.ISO8601\n    ,e.deviceid\n    ,e.avg_temperature\n    ,e.avg_humidity\nfrom ext.buildings_sensors as e\n--left join staging.buildings as s \nleft join dw.buildings as s\non \n     e.ISO8601 = s.ISO8601\n--    and e.deviceid = s.deviceid\n--    and e.avg_temperature = s.avg_temperature\n--    and e.avg_humidity = e.avg_humidity\nwhere s.ISO8601 is null\n--order by e.ISO8601 asc, e.deviceid desc\n-- asc  2021-09-28-00\n-- desc 2021-09-30-23\n\n-- asc  2021-09-26-00\n-- desc 2021-09-27-23\n\nselect count(*) from staging.buildings\n\n\n-- Create heap table\nCREATE TABLE staging.buildings\n(\n     ISO8601 varchar(20)\n    ,deviceid varchar(20)\n    ,avg_temperature float\n    ,avg_humidity float\n)\nWITH (HEAP);\n\ninsert into staging.buildings\nselect * from ext.buildings_sensors\n\n\n\n-- DW table\nDROP TABLE dw.buildings;\nGO\nCREATE TABLE dw.buildings\n(\n     ISO8601 varchar(20)\n    ,deviceid varchar(20)\n    ,avg_temperature float\n    ,avg_humidity float\n)\nWITH (DISTRIBUTION = HASH(deviceid),CLUSTERED COLUMNSTORE INDEX);\n\n-- Insert new records to the data warehouse table\ninsert into dw.buildings \nselect * from staging.buildings;\n\nselect * from dw.buildings \n\n-- Create the sproc\ndrop PROCEDURE dw_insert;\nCREATE PROCEDURE dw_insert AS\nBEGIN\n    -- Truncate the staging table. Staging table will only hold new records to be inserted\n    truncate table staging.buildings;\n\n    -- Insert only new records into the staging table\n    insert into staging.buildings\n    select\n         e.ISO8601\n        ,e.deviceid\n        ,e.avg_temperature\n        ,e.avg_humidity\n    from ext.buildings_sensors as e\n    left join dw.buildings as s\n    on \n        e.ISO8601 = s.ISO8601\n    --    and e.deviceid = s.deviceid\n    --    and e.avg_temperature = s.avg_temperature\n    --    and e.avg_humidity = e.avg_humidity\n    where s.ISO8601 is null\n\n    -- Insert new records into the DW table\n    insert into dw.buildings select * from staging.buildings;\nEND\n\nselect count(*) from dw.buildings\n--91\n\nexec dw_insert;\nselect count(*) from dw.buildings;\n--182\n\n\nSELECT count(*)\nFROM [ext].[buildings_sensors]\n-- 91\n-- 115\n-- 151\n-- 199\n\nselect * from ext.buildings_sensors\norder by ISO8601 desc\n\nselect count(*) from dw.buildings;\n-- 91\n-- 182\n\nselect * from dw.buildings\norder by ISO8601 desc\n\nSELECT top 10 \n    year(cast(left(ISO8601,10) as date)) as [year], month(cast(left(ISO8601,10) as date)) as [month], day(cast(left(ISO8601,10) as date)) as [day]\n    ,count(*) as occurs\nfrom dw.buildings\ngroup by year(cast(left(ISO8601,10) as date)), month(cast(left(ISO8601,10) as date)), day(cast(left(ISO8601,10) as date))\n\nselect count(*)\nfrom dw.buildings\nwhere day(cast(left(ISO8601,10) as date)) = 26\norder by ISO8601 desc\n-- 26   144 deleted\n-- 27   129 deleted\n\n\nselect count(*)\nfrom [ext].[buildings_sensors]\nwhere day(cast(left(ISO8601,10) as date)) = 26\norder by ISO8601 desc\n\n\nselect *\nfrom dw.buildings\nwhere day(cast(left(ISO8601,10) as date)) = 26\norder by ISO8601 desc",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/buildings-iot-data-dw')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Examples-SQL-Dedicated/operational-analytics"
				},
				"content": {
					"query": "---------------------------------------------------------------------------------------------------\n-- External table (Parqet data on data lake)\nselect count(*)\nfrom ext.buildings_sensors\n-- 199\n\n-- Staging table (heap, round-robin table in SQL Dedicated)\nselect count(*)\nfrom staging.buildings\n-- 199\n\n-- DW table (CCI, hash distribution in SQL Dedicated)\nselect count(*)\nfrom dw.buildings\n-- 199\n\n\n-- Query the external table\nselect top 20 * from ext.buildings_sensors order by ISO8601 desc;\n\n-- DW record count by date:\nSELECT \n    year(cast(left(ISO8601,10) as date)) as [year], month(cast(left(ISO8601,10) as date)) as [month], day(cast(left(ISO8601,10) as date)) as [day]\n    ,count(*) as occurs\nfrom dw.buildings\ngroup by year(cast(left(ISO8601,10) as date)), month(cast(left(ISO8601,10) as date)), day(cast(left(ISO8601,10) as date))\norder by year(cast(left(ISO8601,10) as date)), month(cast(left(ISO8601,10) as date)), day(cast(left(ISO8601,10) as date)) desc\n\n\n-- Turn off ResultSet Cache\nSET RESULT_SET_CACHING OFF;\n\nSELECT \n    year(cast(left(ISO8601,10) as date)) as [year], month(cast(left(ISO8601,10) as date)) as [month], day(cast(left(ISO8601,10) as date)) as [day]\n    ,count(*) as occurs\nfrom dw.buildings\ngroup by year(cast(left(ISO8601,10) as date)), month(cast(left(ISO8601,10) as date)), day(cast(left(ISO8601,10) as date))\norder by year(cast(left(ISO8601,10) as date)), month(cast(left(ISO8601,10) as date)), day(cast(left(ISO8601,10) as date)) desc",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/demo-script')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Misc"
				},
				"content": {
					"query": "-- This is auto-generated code\nSELECT\n    TOP 100 *\nFROM\n    OPENROWSET(\n        BULK 'https://minastirith.dfs.core.windows.net/datalake2020/01-fresh/biketrips/2020/202001-citibike-tripdata.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION='2.0',\n        header_row=true\n    ) AS [result]\n\nSELECT COUNT(*) as TotalRecords\nFROM\n    OPENROWSET(\n        BULK 'https://minastirith.dfs.core.windows.net/datalake2020/01-fresh/biketrips/2020/202001-citibike-tripdata.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION='2.0',\n        header_row=true\n    ) AS [result]\n-- 1,240,596\n\n\nSELECT \n     YEAR(starttime) as [year]\n    ,MONTH(starttime) as [month]\n    ,COUNT(*) as TotalRecords\nFROM\n    OPENROWSET(\n        BULK 'https://minastirith.dfs.core.windows.net/datalake2020/01-fresh/biketrips/2020/202001-citibike-tripdata.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION='2.0',\n        header_row=true\n    ) AS [result]\ngroup by \n     YEAR(starttime)\n    ,MONTH(starttime)\n\nSELECT COUNT(*) as TotalRecords\nFROM\n    OPENROWSET(\n        BULK 'https://minastirith.dfs.core.windows.net/datalake2020/01-fresh/biketrips/2020/',\n        FORMAT = 'CSV',\n        PARSER_VERSION='2.0',\n        header_row=true\n    ) AS [result]\n-- 1,240,596\n-- 19,506,857\n\n\nSELECT \n     YEAR(starttime) as [year]\n    ,MONTH(starttime) as [month]\n    ,COUNT(*) as TotalRecords\nFROM\n    OPENROWSET(\n        BULK 'https://minastirith.dfs.core.windows.net/datalake2020/01-fresh/biketrips/2020/',\n        FORMAT = 'CSV',\n        PARSER_VERSION='2.0',\n        header_row=true\n    ) AS [result]\ngroup by \n     YEAR(starttime)\n    ,MONTH(starttime)\norder by \n     YEAR(starttime)\n    ,MONTH(starttime)\n\n\n\n-- PARQUET data\n-- Note that for YEAR() we have to do YEAR(CAST(starttime as date))\n\n-- in master\ncreate database newserverless;\n\nuse newserverless;\n\n\ncreate view dbo.biketrips2020 as \nSELECT \n     YEAR(starttime) as [year]\n    ,MONTH(starttime) as [month]\n    ,COUNT(*) as TotalRecords\nFROM\n    OPENROWSET(\n        BULK 'https://minastirith.dfs.core.windows.net/datalake2020/01-fresh/biketrips/2020/',\n        FORMAT = 'CSV',\n        PARSER_VERSION='2.0',\n        header_row=true\n    ) AS [result]\ngroup by \n     YEAR(starttime)\n    ,MONTH(starttime)",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/edw_create_tables')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Misc/TPC-DS"
				},
				"content": {
					"query": "-- misc\nSET ANSI_NULLS ON\nGO\n\nSET QUOTED_IDENTIFIER ON\nGO\n\n-- call_center\nCREATE TABLE [call_center]\n(\n\t[cc_call_center_sk] [int] NOT NULL,\n\t[cc_call_center_id] [char](16) NOT NULL,\n\t[cc_rec_start_date] [date] NULL,\n\t[cc_rec_end_date] [date] NULL,\n\t[cc_closed_date_sk] [int] NULL,\n\t[cc_open_date_sk] [int] NULL,\n\t[cc_name] [varchar](50) NULL,\n\t[cc_class] [varchar](50) NULL,\n\t[cc_employees] [int] NULL,\n\t[cc_sq_ft] [int] NULL,\n\t[cc_hours] [char](20) NULL,\n\t[cc_manager] [varchar](40) NULL,\n\t[cc_mkt_id] [int] NULL,\n\t[cc_mkt_class] [char](50) NULL,\n\t[cc_mkt_desc] [varchar](100) NULL,\n\t[cc_market_manager] [varchar](40) NULL,\n\t[cc_division] [int] NULL,\n\t[cc_division_name] [varchar](50) NULL,\n\t[cc_company] [int] NULL,\n\t[cc_company_name] [char](50) NULL,\n\t[cc_street_number] [char](10) NULL,\n\t[cc_street_name] [varchar](60) NULL,\n\t[cc_street_type] [char](15) NULL,\n\t[cc_suite_number] [char](10) NULL,\n\t[cc_city] [varchar](60) NULL,\n\t[cc_county] [varchar](30) NULL,\n\t[cc_state] [char](2) NULL,\n\t[cc_zip] [char](10) NULL,\n\t[cc_country] [varchar](20) NULL,\n\t[cc_gmt_offset] [decimal](5, 2) NULL,\n\t[cc_tax_percentage] [decimal](5, 2) NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n-- catalog_page\nCREATE TABLE [catalog_page]\n(\n\t[cp_catalog_page_sk] [int] NOT NULL,\n\t[cp_catalog_page_id] [char](16) NOT NULL,\n\t[cp_start_date_sk] [int] NULL,\n\t[cp_end_date_sk] [int] NULL,\n\t[cp_department] [varchar](50) NULL,\n\t[cp_catalog_number] [int] NULL,\n\t[cp_catalog_page_number] [int] NULL,\n\t[cp_description] [varchar](100) NULL,\n\t[cp_type] [varchar](100) NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n-- catalog_returns\nCREATE TABLE [catalog_returns]\n(\n\t[cr_returned_date_sk] [int] NULL,\n\t[cr_returned_time_sk] [int] NULL,\n\t[cr_item_sk] [int] NOT NULL,\n\t[cr_refunded_customer_sk] [int] NULL,\n\t[cr_refunded_cdemo_sk] [int] NULL,\n\t[cr_refunded_hdemo_sk] [int] NULL,\n\t[cr_refunded_addr_sk] [int] NULL,\n\t[cr_returning_customer_sk] [int] NULL,\n\t[cr_returning_cdemo_sk] [int] NULL,\n\t[cr_returning_hdemo_sk] [int] NULL,\n\t[cr_returning_addr_sk] [int] NULL,\n\t[cr_call_center_sk] [int] NULL,\n\t[cr_catalog_page_sk] [int] NULL,\n\t[cr_ship_mode_sk] [int] NULL,\n\t[cr_warehouse_sk] [int] NULL,\n\t[cr_reason_sk] [int] NULL,\n\t[cr_order_number] [int] NOT NULL,\n\t[cr_return_quantity] [int] NULL,\n\t[cr_return_amount] [decimal](7, 2) NULL,\n\t[cr_return_tax] [decimal](7, 2) NULL,\n\t[cr_return_amt_inc_tax] [decimal](7, 2) NULL,\n\t[cr_fee] [decimal](7, 2) NULL,\n\t[cr_return_ship_cost] [decimal](7, 2) NULL,\n\t[cr_refunded_cash] [decimal](7, 2) NULL,\n\t[cr_reversed_charge] [decimal](7, 2) NULL,\n\t[cr_store_credit] [decimal](7, 2) NULL,\n\t[cr_net_loss] [decimal](7, 2) NULL\n)\nWITH\n(\n\tDISTRIBUTION = HASH ( [cr_item_sk] ),\n\tCLUSTERED COLUMNSTORE INDEX ORDER ([cr_returned_date_sk], [cr_item_sk])\n)\nGO\n\n\n-- catalog_sales\nCREATE TABLE [catalog_sales]\n(\n\t[cs_sold_date_sk] [int] NULL,\n\t[cs_sold_time_sk] [int] NULL,\n\t[cs_ship_date_sk] [int] NULL,\n\t[cs_bill_customer_sk] [int] NULL,\n\t[cs_bill_cdemo_sk] [int] NULL,\n\t[cs_bill_hdemo_sk] [int] NULL,\n\t[cs_bill_addr_sk] [int] NULL,\n\t[cs_ship_customer_sk] [int] NULL,\n\t[cs_ship_cdemo_sk] [int] NULL,\n\t[cs_ship_hdemo_sk] [int] NULL,\n\t[cs_ship_addr_sk] [int] NULL,\n\t[cs_call_center_sk] [int] NULL,\n\t[cs_catalog_page_sk] [int] NULL,\n\t[cs_ship_mode_sk] [int] NULL,\n\t[cs_warehouse_sk] [int] NULL,\n\t[cs_item_sk] [int] NOT NULL,\n\t[cs_promo_sk] [int] NULL,\n\t[cs_order_number] [int] NOT NULL,\n\t[cs_quantity] [int] NULL,\n\t[cs_wholesale_cost] [decimal](7, 2) NULL,\n\t[cs_list_price] [decimal](7, 2) NULL,\n\t[cs_sales_price] [decimal](7, 2) NULL,\n\t[cs_ext_discount_amt] [decimal](7, 2) NULL,\n\t[cs_ext_sales_price] [decimal](7, 2) NULL,\n\t[cs_ext_wholesale_cost] [decimal](7, 2) NULL,\n\t[cs_ext_list_price] [decimal](7, 2) NULL,\n\t[cs_ext_tax] [decimal](7, 2) NULL,\n\t[cs_coupon_amt] [decimal](7, 2) NULL,\n\t[cs_ext_ship_cost] [decimal](7, 2) NULL,\n\t[cs_net_paid] [decimal](7, 2) NULL,\n\t[cs_net_paid_inc_tax] [decimal](7, 2) NULL,\n\t[cs_net_paid_inc_ship] [decimal](7, 2) NULL,\n\t[cs_net_paid_inc_ship_tax] [decimal](7, 2) NULL,\n\t[cs_net_profit] [decimal](7, 2) NULL\n)\nWITH\n(\n\tDISTRIBUTION = HASH ( [cs_item_sk] ),\n\tCLUSTERED COLUMNSTORE INDEX ORDER(cs_sold_date_sk, cs_item_sk)\n)\nGO\n\n-- customer_address\nCREATE TABLE [customer_address]\n(\n\t[ca_address_sk] [int] NOT NULL,\n\t[ca_address_id] [char](16) NOT NULL,\n\t[ca_street_number] [char](10) NULL,\n\t[ca_street_name] [varchar](60) NULL,\n\t[ca_street_type] [char](15) NULL,\n\t[ca_suite_number] [char](10) NULL,\n\t[ca_city] [varchar](60) NULL,\n\t[ca_county] [varchar](30) NULL,\n\t[ca_state] [char](2) NULL,\n\t[ca_zip] [char](10) NULL,\n\t[ca_country] [varchar](20) NULL,\n\t[ca_gmt_offset] [decimal](5, 2) NULL,\n\t[ca_location_type] [char](20) NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n\n-- customer_demographics\nCREATE TABLE [customer_demographics]\n(\n\t[cd_demo_sk] [int] NOT NULL,\n\t[cd_gender] [char](1) NULL,\n\t[cd_marital_status] [char](1) NULL,\n\t[cd_education_status] [char](20) NULL,\n\t[cd_purchase_estimate] [int] NULL,\n\t[cd_credit_rating] [char](10) NULL,\n\t[cd_dep_count] [int] NULL,\n\t[cd_dep_employed_count] [int] NULL,\n\t[cd_dep_college_count] [int] NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n\n-- customer\nCREATE TABLE [customer]\n(\n\t[c_customer_sk] [int] NOT NULL,\n\t[c_customer_id] [char](16) NOT NULL,\n\t[c_current_cdemo_sk] [int] NULL,\n\t[c_current_hdemo_sk] [int] NULL,\n\t[c_current_addr_sk] [int] NULL,\n\t[c_first_shipto_date_sk] [int] NULL,\n\t[c_first_sales_date_sk] [int] NULL,\n\t[c_salutation] [char](10) NULL,\n\t[c_first_name] [char](20) NULL,\n\t[c_last_name] [char](30) NULL,\n\t[c_preferred_cust_flag] [char](1) NULL,\n\t[c_birth_day] [int] NULL,\n\t[c_birth_month] [int] NULL,\n\t[c_birth_year] [int] NULL,\n\t[c_birth_country] [varchar](20) NULL,\n\t[c_login] [char](13) NULL,\n\t[c_email_address] [char](50) NULL,\n\t[c_last_review_date] [char](10) NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n\n-- date_dim\nCREATE TABLE [date_dim]\n(\n\t[d_date_sk] [int] NOT NULL,\n\t[d_date_id] [char](16) NOT NULL,\n\t[d_date] [date] NULL,\n\t[d_month_seq] [int] NULL,\n\t[d_week_seq] [int] NULL,\n\t[d_quarter_seq] [int] NULL,\n\t[d_year] [int] NULL,\n\t[d_dow] [int] NULL,\n\t[d_moy] [int] NULL,\n\t[d_dom] [int] NULL,\n\t[d_qoy] [int] NULL,\n\t[d_fy_year] [int] NULL,\n\t[d_fy_quarter_seq] [int] NULL,\n\t[d_fy_week_seq] [int] NULL,\n\t[d_day_name] [char](9) NULL,\n\t[d_quarter_name] [char](6) NULL,\n\t[d_holiday] [char](1) NULL,\n\t[d_weekend] [char](1) NULL,\n\t[d_following_holiday] [char](1) NULL,\n\t[d_first_dom] [int] NULL,\n\t[d_last_dom] [int] NULL,\n\t[d_same_day_ly] [int] NULL,\n\t[d_same_day_lq] [int] NULL,\n\t[d_current_day] [char](1) NULL,\n\t[d_current_week] [char](1) NULL,\n\t[d_current_month] [char](1) NULL,\n\t[d_current_quarter] [char](1) NULL,\n\t[d_current_year] [char](1) NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n\n-- household_demographics\nCREATE TABLE [household_demographics]\n(\n\t[hd_demo_sk] [int] NOT NULL,\n\t[hd_income_band_sk] [int] NULL,\n\t[hd_buy_potential] [char](15) NULL,\n\t[hd_dep_count] [int] NULL,\n\t[hd_vehicle_count] [int] NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n\n-- income_band\nCREATE TABLE [income_band]\n(\n\t[ib_income_band_sk] [int] NOT NULL,\n\t[ib_lower_bound] [int] NULL,\n\t[ib_upper_bound] [int] NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n\n-- inventory\nCREATE TABLE [inventory]\n(\n\t[inv_date_sk] [int] NOT NULL,\n\t[inv_item_sk] [int] NOT NULL,\n\t[inv_warehouse_sk] [int] NOT NULL,\n\t[inv_quantity_on_hand] [int] NULL\n)\nWITH\n(\n\tDISTRIBUTION = HASH(inv_date_sk),\n\tCLUSTERED COLUMNSTORE INDEX \n)\nGO\n\n\n-- item\nCREATE TABLE [item]\n(\n\t[i_item_sk] [int] NOT NULL,\n\t[i_item_id] [char](16) NOT NULL,\n\t[i_rec_start_date] [date] NULL,\n\t[i_rec_end_date] [date] NULL,\n\t[i_item_desc] [varchar](200) NULL,\n\t[i_current_price] [decimal](7, 2) NULL,\n\t[i_wholesale_cost] [decimal](7, 2) NULL,\n\t[i_brand_id] [int] NULL,\n\t[i_brand] [char](50) NULL,\n\t[i_class_id] [int] NULL,\n\t[i_class] [char](50) NULL,\n\t[i_category_id] [int] NULL,\n\t[i_category] [char](50) NULL,\n\t[i_manufact_id] [int] NULL,\n\t[i_manufact] [char](50) NULL,\n\t[i_size] [char](20) NULL,\n\t[i_formulation] [char](20) NULL,\n\t[i_color] [char](20) NULL,\n\t[i_units] [char](10) NULL,\n\t[i_container] [char](10) NULL,\n\t[i_manager_id] [int] NULL,\n\t[i_product_name] [char](50) NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n\n-- promotion\nCREATE TABLE [promotion]\n(\n\t[p_promo_sk] [int] NOT NULL,\n\t[p_promo_id] [char](16) NOT NULL,\n\t[p_start_date_sk] [int] NULL,\n\t[p_end_date_sk] [int] NULL,\n\t[p_item_sk] [int] NULL,\n\t[p_cost] [decimal](15, 2) NULL,\n\t[p_response_target] [int] NULL,\n\t[p_promo_name] [char](50) NULL,\n\t[p_channel_dmail] [char](1) NULL,\n\t[p_channel_email] [char](1) NULL,\n\t[p_channel_catalog] [char](1) NULL,\n\t[p_channel_tv] [char](1) NULL,\n\t[p_channel_radio] [char](1) NULL,\n\t[p_channel_press] [char](1) NULL,\n\t[p_channel_event] [char](1) NULL,\n\t[p_channel_demo] [char](1) NULL,\n\t[p_channel_details] [varchar](100) NULL,\n\t[p_purpose] [char](15) NULL,\n\t[p_discount_active] [char](1) NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n\n-- reason\nCREATE TABLE [reason]\n(\n\t[r_reason_sk] [int] NOT NULL,\n\t[r_reason_id] [char](16) NOT NULL,\n\t[r_reason_desc] [char](100) NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n\n-- ship_mode\nCREATE TABLE [ship_mode]\n(\n\t[sm_ship_mode_sk] [int] NOT NULL,\n\t[sm_ship_mode_id] [char](16) NOT NULL,\n\t[sm_type] [char](30) NULL,\n\t[sm_code] [char](10) NULL,\n\t[sm_carrier] [char](20) NULL,\n\t[sm_contract] [char](20) NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n\n-- store_returns\nCREATE TABLE [store_returns]\n(\n\t[sr_returned_date_sk] [int] NULL,\n\t[sr_return_time_sk] [int] NULL,\n\t[sr_item_sk] [int] NOT NULL,\n\t[sr_customer_sk] [int] NULL,\n\t[sr_cdemo_sk] [int] NULL,\n\t[sr_hdemo_sk] [int] NULL,\n\t[sr_addr_sk] [int] NULL,\n\t[sr_store_sk] [int] NULL,\n\t[sr_reason_sk] [int] NULL,\n\t[sr_ticket_number] [bigint] NOT NULL,\n\t[sr_return_quantity] [int] NULL,\n\t[sr_return_amt] [decimal](7, 2) NULL,\n\t[sr_return_tax] [decimal](7, 2) NULL,\n\t[sr_return_amt_inc_tax] [decimal](7, 2) NULL,\n\t[sr_fee] [decimal](7, 2) NULL,\n\t[sr_return_ship_cost] [decimal](7, 2) NULL,\n\t[sr_refunded_cash] [decimal](7, 2) NULL,\n\t[sr_reversed_charge] [decimal](7, 2) NULL,\n\t[sr_store_credit] [decimal](7, 2) NULL,\n\t[sr_net_loss] [decimal](7, 2) NULL\n)\nWITH\n(\n\tDISTRIBUTION = HASH ( [sr_item_sk] ),\n\tCLUSTERED COLUMNSTORE INDEX ORDER([sr_returned_date_sk], [sr_item_sk])\n)\nGO\n\n\n-- store_sales\nCREATE TABLE [store_sales]\n(\n\t[ss_sold_date_sk] [int] NULL,\n\t[ss_sold_time_sk] [int] NULL,\n\t[ss_item_sk] [int] NOT NULL,\n\t[ss_customer_sk] [int] NULL,\n\t[ss_cdemo_sk] [int] NULL,\n\t[ss_hdemo_sk] [int] NULL,\n\t[ss_addr_sk] [int] NULL,\n\t[ss_store_sk] [int] NULL,\n\t[ss_promo_sk] [int] NULL,\n\t[ss_ticket_number] [int] NOT NULL,\n\t[ss_quantity] [int] NULL,\n\t[ss_wholesale_cost] [decimal](7, 2) NULL,\n\t[ss_list_price] [decimal](7, 2) NULL,\n\t[ss_sales_price] [decimal](7, 2) NULL,\n\t[ss_ext_discount_amt] [decimal](7, 2) NULL,\n\t[ss_ext_sales_price] [decimal](7, 2) NULL,\n\t[ss_ext_wholesale_cost] [decimal](7, 2) NULL,\n\t[ss_ext_list_price] [decimal](7, 2) NULL,\n\t[ss_ext_tax] [decimal](7, 2) NULL,\n\t[ss_coupon_amt] [decimal](7, 2) NULL,\n\t[ss_net_paid] [decimal](7, 2) NULL,\n\t[ss_net_paid_inc_tax] [decimal](7, 2) NULL,\n\t[ss_net_profit] [decimal](7, 2) NULL\n)\nWITH\n(\n\tDISTRIBUTION = HASH ( [ss_item_sk] ),\n\tCLUSTERED COLUMNSTORE INDEX ORDER([ss_sold_date_sk], [ss_item_sk])\n)\nGO\n\n\n-- store\nCREATE TABLE [store]\n(\n\t[s_store_sk] [int] NOT NULL,\n\t[s_store_id] [char](16) NOT NULL,\n\t[s_rec_start_date] [date] NULL,\n\t[s_rec_end_date] [date] NULL,\n\t[s_closed_date_sk] [int] NULL,\n\t[s_store_name] [varchar](50) NULL,\n\t[s_number_employees] [int] NULL,\n\t[s_floor_space] [int] NULL,\n\t[s_hours] [char](20) NULL,\n\t[s_manager] [varchar](40) NULL,\n\t[s_market_id] [int] NULL,\n\t[s_geography_class] [varchar](100) NULL,\n\t[s_market_desc] [varchar](100) NULL,\n\t[s_market_manager] [varchar](40) NULL,\n\t[s_division_id] [int] NULL,\n\t[s_division_name] [varchar](50) NULL,\n\t[s_company_id] [int] NULL,\n\t[s_company_name] [varchar](50) NULL,\n\t[s_street_number] [varchar](10) NULL,\n\t[s_street_name] [varchar](60) NULL,\n\t[s_street_type] [char](15) NULL,\n\t[s_suite_number] [char](10) NULL,\n\t[s_city] [varchar](60) NULL,\n\t[s_county] [varchar](30) NULL,\n\t[s_state] [char](2) NULL,\n\t[s_zip] [char](10) NULL,\n\t[s_country] [varchar](20) NULL,\n\t[s_gmt_offset] [decimal](5, 2) NULL,\n\t[s_tax_precentage] [decimal](5, 2) NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n\n-- time_dim\nCREATE TABLE [time_dim]\n(\n\t[t_time_sk] [int] NOT NULL,\n\t[t_time_id] [char](16) NOT NULL,\n\t[t_time] [int] NULL,\n\t[t_hour] [int] NULL,\n\t[t_minute] [int] NULL,\n\t[t_second] [int] NULL,\n\t[t_am_pm] [char](2) NULL,\n\t[t_shift] [char](20) NULL,\n\t[t_sub_shift] [char](20) NULL,\n\t[t_meal_time] [char](20) NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n\n-- warehouse\nCREATE TABLE [warehouse]\n(\n\t[w_warehouse_sk] [int] NOT NULL,\n\t[w_warehouse_id] [char](16) NOT NULL,\n\t[w_warehouse_name] [varchar](20) NULL,\n\t[w_warehouse_sq_ft] [int] NULL,\n\t[w_street_number] [char](10) NULL,\n\t[w_street_name] [varchar](60) NULL,\n\t[w_street_type] [char](15) NULL,\n\t[w_suite_number] [char](10) NULL,\n\t[w_city] [varchar](60) NULL,\n\t[w_county] [varchar](30) NULL,\n\t[w_state] [char](2) NULL,\n\t[w_zip] [char](10) NULL,\n\t[w_country] [varchar](20) NULL,\n\t[w_gmt_offset] [decimal](5, 2) NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n\n-- web_page\nCREATE TABLE [web_page]\n(\n\t[wp_web_page_sk] [int] NOT NULL,\n\t[wp_web_page_id] [char](16) NOT NULL,\n\t[wp_rec_start_date] [date] NULL,\n\t[wp_rec_end_date] [date] NULL,\n\t[wp_creation_date_sk] [int] NULL,\n\t[wp_access_date_sk] [int] NULL,\n\t[wp_autogen_flag] [char](1) NULL,\n\t[wp_customer_sk] [int] NULL,\n\t[wp_url] [varchar](100) NULL,\n\t[wp_type] [char](50) NULL,\n\t[wp_char_count] [int] NULL,\n\t[wp_link_count] [int] NULL,\n\t[wp_image_count] [int] NULL,\n\t[wp_max_ad_count] [int] NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n\n-- web_returns\nCREATE TABLE [web_returns]\n(\n\t[wr_returned_date_sk] [int] NULL,\n\t[wr_returned_time_sk] [int] NULL,\n\t[wr_item_sk] [int] NOT NULL,\n\t[wr_refunded_customer_sk] [int] NULL,\n\t[wr_refunded_cdemo_sk] [int] NULL,\n\t[wr_refunded_hdemo_sk] [int] NULL,\n\t[wr_refunded_addr_sk] [int] NULL,\n\t[wr_returning_customer_sk] [int] NULL,\n\t[wr_returning_cdemo_sk] [int] NULL,\n\t[wr_returning_hdemo_sk] [int] NULL,\n\t[wr_returning_addr_sk] [int] NULL,\n\t[wr_web_page_sk] [int] NULL,\n\t[wr_reason_sk] [int] NULL,\n\t[wr_order_number] [int] NOT NULL,\n\t[wr_return_quantity] [int] NULL,\n\t[wr_return_amt] [decimal](7, 2) NULL,\n\t[wr_return_tax] [decimal](7, 2) NULL,\n\t[wr_return_amt_inc_tax] [decimal](7, 2) NULL,\n\t[wr_fee] [decimal](7, 2) NULL,\n\t[wr_return_ship_cost] [decimal](7, 2) NULL,\n\t[wr_refunded_cash] [decimal](7, 2) NULL,\n\t[wr_reversed_charge] [decimal](7, 2) NULL,\n\t[wr_account_credit] [decimal](7, 2) NULL,\n\t[wr_net_loss] [decimal](7, 2) NULL\n)\nWITH\n(\n\tDISTRIBUTION = HASH ( [wr_item_sk] ),\n\tCLUSTERED COLUMNSTORE INDEX ORDER(wr_returned_date_sk, wr_item_sk)\n)\nGO\n\n\n-- web_sales\nCREATE TABLE [web_sales]\n(\n\t[ws_sold_date_sk] [int] NULL,\n\t[ws_sold_time_sk] [int] NULL,\n\t[ws_ship_date_sk] [int] NULL,\n\t[ws_item_sk] [int] NOT NULL,\n\t[ws_bill_customer_sk] [int] NULL,\n\t[ws_bill_cdemo_sk] [int] NULL,\n\t[ws_bill_hdemo_sk] [int] NULL,\n\t[ws_bill_addr_sk] [int] NULL,\n\t[ws_ship_customer_sk] [int] NULL,\n\t[ws_ship_cdemo_sk] [int] NULL,\n\t[ws_ship_hdemo_sk] [int] NULL,\n\t[ws_ship_addr_sk] [int] NULL,\n\t[ws_web_page_sk] [int] NULL,\n\t[ws_web_site_sk] [int] NULL,\n\t[ws_ship_mode_sk] [int] NULL,\n\t[ws_warehouse_sk] [int] NULL,\n\t[ws_promo_sk] [int] NULL,\n\t[ws_order_number] [int] NOT NULL,\n\t[ws_quantity] [int] NULL,\n\t[ws_wholesale_cost] [decimal](7, 2) NULL,\n\t[ws_list_price] [decimal](7, 2) NULL,\n\t[ws_sales_price] [decimal](7, 2) NULL,\n\t[ws_ext_discount_amt] [decimal](7, 2) NULL,\n\t[ws_ext_sales_price] [decimal](7, 2) NULL,\n\t[ws_ext_wholesale_cost] [decimal](7, 2) NULL,\n\t[ws_ext_list_price] [decimal](7, 2) NULL,\n\t[ws_ext_tax] [decimal](7, 2) NULL,\n\t[ws_coupon_amt] [decimal](7, 2) NULL,\n\t[ws_ext_ship_cost] [decimal](7, 2) NULL,\n\t[ws_net_paid] [decimal](7, 2) NULL,\n\t[ws_net_paid_inc_tax] [decimal](7, 2) NULL,\n\t[ws_net_paid_inc_ship] [decimal](7, 2) NULL,\n\t[ws_net_paid_inc_ship_tax] [decimal](7, 2) NULL,\n\t[ws_net_profit] [decimal](7, 2) NULL\n)\nWITH\n(\n\tDISTRIBUTION = HASH ( [ws_item_sk] ),\n\tCLUSTERED COLUMNSTORE INDEX ORDER(ws_sold_date_sk, ws_item_sk)\n)\nGO\n\n\n-- web_site\nCREATE TABLE [web_site]\n(\n\t[web_site_sk] [int] NOT NULL,\n\t[web_site_id] [char](16) NOT NULL,\n\t[web_rec_start_date] [date] NULL,\n\t[web_rec_end_date] [date] NULL,\n\t[web_name] [varchar](50) NULL,\n\t[web_open_date_sk] [int] NULL,\n\t[web_close_date_sk] [int] NULL,\n\t[web_class] [varchar](50) NULL,\n\t[web_manager] [varchar](40) NULL,\n\t[web_mkt_id] [int] NULL,\n\t[web_mkt_class] [varchar](50) NULL,\n\t[web_mkt_desc] [varchar](100) NULL,\n\t[web_market_manager] [varchar](40) NULL,\n\t[web_company_id] [int] NULL,\n\t[web_company_name] [char](50) NULL,\n\t[web_street_number] [char](10) NULL,\n\t[web_street_name] [varchar](60) NULL,\n\t[web_street_type] [char](15) NULL,\n\t[web_suite_number] [char](10) NULL,\n\t[web_city] [varchar](60) NULL,\n\t[web_county] [varchar](30) NULL,\n\t[web_state] [char](2) NULL,\n\t[web_zip] [char](10) NULL,\n\t[web_country] [varchar](20) NULL,\n\t[web_gmt_offset] [decimal](5, 2) NULL,\n\t[web_tax_percentage] [decimal](5, 2) NULL\n)\nWITH\n(\n\tDISTRIBUTION = REPLICATE,\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/examples-setup-script')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Misc"
				},
				"content": {
					"query": "if db_name() = 'master'\n    throw 50001, 'This script cannot be executed in master database. Create new database and run the script there.', 1;\n\nif SERVERPROPERTY('EngineEdition') <> 11\n    throw 50001, 'This script must be executed on Azure Synapse - SQL serverless endpoint.', 1;\n\n------------------------------------------------------------------------------------------\n--      Part 1 - Cleanup script\n--      This part removes objects from sample database\n------------------------------------------------------------------------------------------\nDROP VIEW IF EXISTS parquet.YellowTaxi\nGO\nDROP VIEW IF EXISTS json.Books\nGO\nDROP VIEW IF EXISTS csv.YellowTaxi\nGO\nIF (EXISTS(SELECT * FROM sys.external_tables WHERE name = 'Population')) BEGIN\n    DROP EXTERNAL TABLE csv.Population\nEND\nIF (EXISTS(SELECT * FROM sys.external_file_formats WHERE name = 'QuotedCsvWithHeader')) BEGIN\n    DROP EXTERNAL FILE FORMAT QuotedCsvWithHeader\nEND\nGO\nIF (EXISTS(SELECT * FROM sys.external_file_formats WHERE name = 'QuotedCsvWithoutHeader')) BEGIN\n    DROP EXTERNAL FILE FORMAT QuotedCsvWithoutHeader\nEND\nGO\nIF (EXISTS(SELECT * FROM sys.external_file_formats WHERE name = 'NativeParquet')) BEGIN\n    DROP EXTERNAL FILE FORMAT NativeParquet\nEND\nGO\nDROP SCHEMA IF EXISTS parquet;\nGO\nDROP SCHEMA IF EXISTS csv;\nGO\nDROP SCHEMA IF EXISTS json;\nGO\n\nIF (EXISTS(SELECT * FROM sys.external_data_sources WHERE name = 'SqlOnDemandDemo')) BEGIN\n    DROP EXTERNAL DATA SOURCE SqlOnDemandDemo\nEND\n\nIF (EXISTS(SELECT * FROM sys.external_data_sources WHERE name = 'AzureOpenData')) BEGIN\n    DROP EXTERNAL DATA SOURCE AzureOpenData\nEND\n\nIF (EXISTS(SELECT * FROM sys.external_data_sources WHERE name = 'YellowTaxi')) BEGIN\n    DROP EXTERNAL DATA SOURCE YellowTaxi\nEND\n\nIF (EXISTS(SELECT * FROM sys.external_data_sources WHERE name = 'GreenTaxi')) BEGIN\n    DROP EXTERNAL DATA SOURCE GreenTaxi\nEND\n\nIF NOT EXISTS (SELECT * FROM sys.symmetric_keys) BEGIN\n    declare @pasword nvarchar(400) = CAST(newid() as VARCHAR(400));\n    EXEC('CREATE MASTER KEY ENCRYPTION BY PASSWORD = ''' + @pasword + '''')\nEND\n\nIF EXISTS\n   (SELECT * FROM sys.credentials\n   WHERE name = 'https://sqlondemandstorage.blob.core.windows.net')\n   DROP CREDENTIAL [https://sqlondemandstorage.blob.core.windows.net]\nGO\n\nIF EXISTS\n   (SELECT * FROM sys.database_scoped_credentials\n   WHERE name = 'sqlondemand')\n   DROP DATABASE SCOPED CREDENTIAL [sqlondemand]\nGO\n\nIF EXISTS\n   (SELECT * FROM sys.database_scoped_credentials\n   WHERE name = 'WorkspaceIdentity')\n   DROP DATABASE SCOPED CREDENTIAL [WorkspaceIdentity]\nGO\n\n\n------------------------------------------------------------------------------------------\n--      Part 2 - initialization script\n--      This part creates required objects in sample database\n------------------------------------------------------------------------------------------\n\n-- create database-scoped credential for the containers in demo storage account\n-- this credential will be used in OPENROWSET function with data source that uses relative file URL\nCREATE DATABASE SCOPED CREDENTIAL [sqlondemand]\nWITH IDENTITY='SHARED ACCESS SIGNATURE',  \nSECRET = 'sv=2018-03-28&ss=bf&srt=sco&sp=rl&st=2019-10-14T12%3A10%3A25Z&se=2061-12-31T12%3A10%3A00Z&sig=KlSU2ullCscyTS0An0nozEpo4tO5JAgGBvw%2FJX2lguw%3D'\nGO\n-- Create credential that will allow user to impersonate using Managed Identity assigned to workspace\nCREATE DATABASE SCOPED CREDENTIAL WorkspaceIdentity WITH IDENTITY = 'Managed Identity'\nGO\n\n-- SQL logins only:\n-- create server-scoped credential for the containers in demo storage account\n-- SQL logins will use this credential in OPENROWSET function without data source that uses absolute file URL\nCREATE CREDENTIAL [https://sqlondemandstorage.blob.core.windows.net]\nWITH IDENTITY='SHARED ACCESS SIGNATURE',  \nSECRET = 'sv=2018-03-28&ss=bf&srt=sco&sp=rl&st=2019-10-14T12%3A10%3A25Z&se=2061-12-31T12%3A10%3A00Z&sig=KlSU2ullCscyTS0An0nozEpo4tO5JAgGBvw%2FJX2lguw%3D'\nGO\n\nCREATE SCHEMA parquet;\nGO\nCREATE SCHEMA csv;\nGO\nCREATE SCHEMA json;\nGO\n\n-- Create external data source secured using credential\nCREATE EXTERNAL DATA SOURCE SqlOnDemandDemo WITH (\n    LOCATION = 'https://sqlondemandstorage.blob.core.windows.net',\n    CREDENTIAL = sqlondemand\n);\nGO\n-- Create publicly available external data sources\nCREATE EXTERNAL DATA SOURCE AzureOpenData\nWITH ( LOCATION = 'https://azureopendatastorage.blob.core.windows.net/')\nGO\nCREATE EXTERNAL DATA SOURCE YellowTaxi\nWITH ( LOCATION = 'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/')\nGO\nCREATE EXTERNAL DATA SOURCE GreenTaxi\nWITH ( LOCATION = 'https://azureopendatastorage.blob.core.windows.net/nyctlc/green/')\nGO\n\nCREATE EXTERNAL FILE FORMAT QuotedCsvWithHeader\nWITH (  \n    FORMAT_TYPE = DELIMITEDTEXT,\n    FORMAT_OPTIONS (\n        FIELD_TERMINATOR = ',',\n        STRING_DELIMITER = '\"',\n        FIRST_ROW = 2\n    )\n);\nGO\nCREATE EXTERNAL FILE FORMAT QuotedCsvWithoutHeader\nWITH (  \n    FORMAT_TYPE = DELIMITEDTEXT,\n    FORMAT_OPTIONS (\n        FIELD_TERMINATOR = ',',\n        STRING_DELIMITER = '\"',\n        FIRST_ROW = 1\n    )\n);\nGO\nCREATE EXTERNAL FILE FORMAT NativeParquet\nWITH (  \n    FORMAT_TYPE = PARQUET\n);\nGO\n\nCREATE EXTERNAL TABLE csv.population\n(\n    [country_code] VARCHAR (5) COLLATE Latin1_General_BIN2,\n    [country_name] VARCHAR (100) COLLATE Latin1_General_BIN2,\n    [year] smallint,\n    [population] bigint\n)\nWITH (\n    LOCATION = 'csv/population/population.csv',\n    DATA_SOURCE = SqlOnDemandDemo,\n    FILE_FORMAT = QuotedCsvWithHeader\n);\nGO\n\nCREATE VIEW parquet.YellowTaxi\nAS SELECT *, nyc.filepath(1) AS [year], nyc.filepath(2) AS [month]\nFROM\n    OPENROWSET(\n        BULK 'parquet/taxi/year=*/month=*/*.parquet',\n        DATA_SOURCE = 'SqlOnDemandDemo',\n        FORMAT='PARQUET'\n    ) AS nyc\nGO\n\nCREATE VIEW csv.YellowTaxi\nAS\nSELECT  *, nyc.filepath(1) AS [year], nyc.filepath(2) AS [month]\nFROM OPENROWSET(\n        BULK 'csv/taxi/yellow_tripdata_*-*.csv',\n        DATA_SOURCE = 'SqlOnDemandDemo',\n        FORMAT = 'CSV', \n        FIRSTROW = 2\n    )\n    WITH (\n          vendor_id VARCHAR(100) COLLATE Latin1_General_BIN2, \n          pickup_datetime DATETIME2, \n          dropoff_datetime DATETIME2,\n          passenger_count INT,\n          trip_distance FLOAT,\n          rate_code INT,\n          store_and_fwd_flag VARCHAR(100) COLLATE Latin1_General_BIN2,\n          pickup_location_id INT,\n          dropoff_location_id INT,\n          payment_type INT,\n          fare_amount FLOAT,\n          extra FLOAT,\n          mta_tax FLOAT,\n          tip_amount FLOAT,\n          tolls_amount FLOAT,\n          improvement_surcharge FLOAT,\n          total_amount FLOAT\n    ) AS nyc\nGO\n\nCREATE VIEW json.Books\nAS SELECT *\nFROM\n    OPENROWSET(\n        BULK 'json/books/*.json',\n        DATA_SOURCE = 'SqlOnDemandDemo',\n        FORMAT='CSV',\n        FIELDTERMINATOR ='0x0b',\n        FIELDQUOTE = '0x0b',\n        ROWTERMINATOR = '0x0b'\n    )\n    WITH (\n        content varchar(8000)\n    ) AS books;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/json-skils-list')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Misc"
				},
				"content": {
					"query": "SELECT TOP 1\n     JSON_VALUE (jsonContent, '$.skills[0].skillId') AS skillId\n    ,JSON_VALUE (jsonContent, '$.skills[0].area') AS area\n    ,JSON_VALUE (jsonContent, '$.skills[0].solutionArea') AS solutionArea\n    ,JSON_VALUE (jsonContent, '$.skills[0].category') AS category\n    ,JSON_VALUE (jsonContent, '$.skills[0].practice') AS practice\n    ,JSON_VALUE (jsonContent, '$.skills[0].buildingBlock') AS buildingBlocka\n    ,JSON_VALUE (jsonContent, '$.skills[0].name') AS name\n    ,jsonContent\nFROM OPENROWSET(BULK 'https://minastirith.dfs.core.windows.net/datalake/01-fresh/skills-json/skills.json',FORMAT = 'CSV',FIELDQUOTE = '0x0b',FIELDTERMINATOR ='0x0b',ROWTERMINATOR = '0x0b') WITH (jsonContent varchar(MAX)) AS [result]\nunion \nSELECT TOP 1\n     JSON_VALUE (jsonContent, '$.skills[1].skillId') AS skillId\n    ,JSON_VALUE (jsonContent, '$.skills[1].area') AS area\n    ,JSON_VALUE (jsonContent, '$.skills[1].solutionArea') AS solutionArea\n    ,JSON_VALUE (jsonContent, '$.skills[1].category') AS category\n    ,JSON_VALUE (jsonContent, '$.skills[1].practice') AS practice\n    ,JSON_VALUE (jsonContent, '$.skills[1].buildingBlock') AS buildingBlock\n    ,JSON_VALUE (jsonContent, '$.skills[1].name') AS name\n    ,jsonContent\nFROM OPENROWSET(BULK 'https://minastirith.dfs.core.windows.net/datalake/01-fresh/skills-json/skills.json', FORMAT = 'CSV',FIELDQUOTE = '0x0b',FIELDTERMINATOR ='0x0b',ROWTERMINATOR = '0x0b') WITH (jsonContent varchar(MAX)) AS [result]\nunion\nSELECT TOP 1\n     JSON_VALUE (jsonContent, '$.skills[2].skillId') AS skillId\n    ,JSON_VALUE (jsonContent, '$.skills[2].area') AS area\n    ,JSON_VALUE (jsonContent, '$.skills[2].solutionArea') AS solutionArea\n    ,JSON_VALUE (jsonContent, '$.skills[2].category') AS category\n    ,JSON_VALUE (jsonContent, '$.skills[2].practice') AS practice\n    ,JSON_VALUE (jsonContent, '$.skills[2].buildingBlock') AS buildingBlock\n    ,JSON_VALUE (jsonContent, '$.skills[2].name') AS name\n    ,jsonContent\nFROM OPENROWSET(BULK 'https://minastirith.dfs.core.windows.net/datalake/01-fresh/skills-json/skills.json', FORMAT = 'CSV',FIELDQUOTE = '0x0b',FIELDTERMINATOR ='0x0b',ROWTERMINATOR = '0x0b') WITH (jsonContent varchar(MAX)) AS [result]\nunion\nSELECT TOP 1\n     JSON_VALUE (jsonContent, '$.skills[3].skillId') AS skillId\n    ,JSON_VALUE (jsonContent, '$.skills[3].area') AS area\n    ,JSON_VALUE (jsonContent, '$.skills[3].solutionArea') AS solutionArea\n    ,JSON_VALUE (jsonContent, '$.skills[3].category') AS category\n    ,JSON_VALUE (jsonContent, '$.skills[3].practice') AS practice\n    ,JSON_VALUE (jsonContent, '$.skills[3].buildingBlock') AS buildingBlock\n    ,JSON_VALUE (jsonContent, '$.skills[3].name') AS name\n    ,jsonContent\nFROM OPENROWSET(BULK 'https://minastirith.dfs.core.windows.net/datalake/01-fresh/skills-json/skills.json', FORMAT = 'CSV',FIELDQUOTE = '0x0b',FIELDTERMINATOR ='0x0b',ROWTERMINATOR = '0x0b') WITH (jsonContent varchar(MAX)) AS [result]\nunion\nSELECT TOP 1\n     JSON_VALUE (jsonContent, '$.skills[4].skillId') AS skillId\n    ,JSON_VALUE (jsonContent, '$.skills[4].area') AS area\n    ,JSON_VALUE (jsonContent, '$.skills[4].solutionArea') AS solutionArea\n    ,JSON_VALUE (jsonContent, '$.skills[4].category') AS category\n    ,JSON_VALUE (jsonContent, '$.skills[4].practice') AS practice\n    ,JSON_VALUE (jsonContent, '$.skills[4].buildingBlock') AS buildingBlock\n    ,JSON_VALUE (jsonContent, '$.skills[4].name') AS name\n    ,jsonContent\nFROM OPENROWSET(BULK 'https://minastirith.dfs.core.windows.net/datalake/01-fresh/skills-json/skills.json', FORMAT = 'CSV',FIELDQUOTE = '0x0b',FIELDTERMINATOR ='0x0b',ROWTERMINATOR = '0x0b') WITH (jsonContent varchar(MAX)) AS [result]\nunion\nSELECT TOP 1\n     JSON_VALUE (jsonContent, '$.skills[5].skillId') AS skillId\n    ,JSON_VALUE (jsonContent, '$.skills[5].area') AS area\n    ,JSON_VALUE (jsonContent, '$.skills[5].solutionArea') AS solutionArea\n    ,JSON_VALUE (jsonContent, '$.skills[5].category') AS category\n    ,JSON_VALUE (jsonContent, '$.skills[5].practice') AS practice\n    ,JSON_VALUE (jsonContent, '$.skills[5].buildingBlock') AS buildingBlock\n    ,JSON_VALUE (jsonContent, '$.skills[5].name') AS name\n    ,jsonContent\nFROM OPENROWSET(BULK 'https://minastirith.dfs.core.windows.net/datalake/01-fresh/skills-json/skills.json', FORMAT = 'CSV',FIELDQUOTE = '0x0b',FIELDTERMINATOR ='0x0b',ROWTERMINATOR = '0x0b') WITH (jsonContent varchar(MAX)) AS [result]\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/serverless_tables')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Misc/TPC-DS"
				},
				"content": {
					"query": "DROP VIEW IF EXISTS [call_center]; \nGO\n\nDROP VIEW IF EXISTS [catalog_page]; \nGO\n\nDROP VIEW IF EXISTS [catalog_returns]; \nGO\n\nDROP VIEW IF EXISTS [catalog_sales]; \nGO\n\nDROP VIEW IF EXISTS [customer]; \nGO\n\nDROP VIEW IF EXISTS [customer_address]; \nGO\n\nDROP VIEW IF EXISTS [customer_demographics]; \nGO\n\nDROP VIEW IF EXISTS [date_dim]; \nGO\n\nDROP VIEW IF EXISTS [household_demographics]; \nGO\n\nDROP VIEW IF EXISTS [income_band]; \nGO\n\nDROP VIEW IF EXISTS [inventory]; \nGO\n\nDROP VIEW IF EXISTS [item]; \nGO\n\nDROP VIEW IF EXISTS [promotion];\nGO\n\nDROP VIEW IF EXISTS [reason]; \nGO\n\nDROP VIEW IF EXISTS [ship_mode]; \nGO\n\nDROP VIEW IF EXISTS [store]; \nGO\n\nDROP VIEW IF EXISTS [store_returns];\nGO\n\nDROP VIEW IF EXISTS [store_sales];\nGO\n\nDROP VIEW IF EXISTS [time_dim];\nGO\n\nDROP VIEW IF EXISTS [warehouse];\nGO\n\nDROP VIEW IF EXISTS [web_page];\nGO\n\nDROP VIEW IF EXISTS [web_site];\nGO\n\nDROP VIEW IF EXISTS [web_returns];\nGO\n\nDROP VIEW IF EXISTS [web_sales];\nGO\n\n\nCREATE VIEW [call_center] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/call_center/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    CC_CALL_CENTER_SK         integer,\n    CC_CALL_CENTER_ID         char(16) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_REC_START_DATE         date,\n    CC_REC_END_DATE           date,\n    CC_CLOSED_DATE_SK         integer,\n    CC_OPEN_DATE_SK           integer,\n    CC_NAME                   varchar(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_CLASS                  varchar(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_EMPLOYEES              integer,\n    CC_SQ_FT                  integer,\n    CC_HOURS                  char(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_MANAGER                varchar(40) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_MKT_ID                 integer,\n    CC_MKT_CLASS              char(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_MKT_DESC               varchar(100) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_MARKET_MANAGER         varchar(40) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_DIVISION               integer,\n    CC_DIVISION_NAME          varchar(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_COMPANY                integer,\n    CC_COMPANY_NAME           char(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_STREET_NUMBER          char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_STREET_NAME            varchar(60) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_STREET_TYPE            char(15) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_SUITE_NUMBER           char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_CITY                   varchar(60) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_COUNTY                 varchar(30) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_STATE                  char(2) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_ZIP                    char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_COUNTRY                varchar(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    CC_GMT_OFFSET             decimal(5,2),\n    CC_TAX_PERCENTAGE         decimal(5,2)\n) AS call_center;\nGO\n\nCREATE VIEW [catalog_page] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/catalog_page/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    CP_CATALOG_PAGE_SK        integer,\n    CP_CATALOG_PAGE_ID        char(16) COLLATE Latin1_General_100_BIN2_UTF8,\n    CP_START_DATE_SK          integer,\n    CP_END_DATE_SK            integer,\n    CP_DEPARTMENT             varchar(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    CP_CATALOG_NUMBER         integer,\n    CP_CATALOG_PAGE_NUMBER    integer,\n    CP_DESCRIPTION            varchar(100) COLLATE Latin1_General_100_BIN2_UTF8,\n    CP_TYPE                   varchar(100) COLLATE Latin1_General_100_BIN2_UTF8\n) AS catalog_page;\nGO\n\nCREATE VIEW [catalog_returns] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/catalog_returns/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    CR_RETURNED_DATE_SK             integer,\n    CR_RETURNED_TIME_SK             integer,\n    CR_ITEM_SK                      integer,\n    CR_REFUNDED_CUSTOMER_SK         integer,\n    CR_REFUNDED_CDEMO_SK            integer,\n    CR_REFUNDED_HDEMO_SK            integer,\n    CR_REFUNDED_ADDR_SK             integer,\n    CR_RETURNING_CUSTOMER_SK        integer,\n    CR_RETURNING_CDEMO_SK           integer,\n    CR_RETURNING_HDEMO_SK           integer,\n    CR_RETURNING_ADDR_SK            integer,\n    CR_CALL_CENTER_SK               integer,\n    CR_CATALOG_PAGE_SK              integer,\n    CR_SHIP_MODE_SK                 integer,\n    CR_WAREHOUSE_SK                 integer,\n    CR_REASON_SK                    integer,\n    CR_ORDER_NUMBER                 bigint,\n    CR_RETURN_QUANTITY              integer,\n    CR_RETURN_AMOUNT                decimal(7,2),\n    CR_RETURN_TAX                   decimal(7,2),\n    CR_RETURN_AMT_INC_TAX           decimal(7,2),\n    CR_FEE                          decimal(7,2),\n    CR_RETURN_SHIP_COST             decimal(7,2),\n    CR_REFUNDED_CASH                decimal(7,2),\n    CR_REVERSED_CHARGE              decimal(7,2),\n    CR_STORE_CREDIT                 decimal(7,2),\n    CR_NET_LOSS                     decimal(7,2)\n) AS catalog_returns;\nGO\n\nCREATE VIEW [catalog_sales] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/catalog_sales/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n\tCS_SOLD_DATE_SK                 integer,\n    CS_SOLD_TIME_SK                 integer,\n    CS_SHIP_DATE_SK                 integer,\n    CS_BILL_CUSTOMER_SK             integer,\n    CS_BILL_CDEMO_SK                integer,\n    CS_BILL_HDEMO_SK                integer,\n    CS_BILL_ADDR_SK                 integer,\n    CS_SHIP_CUSTOMER_SK             integer,\n    CS_SHIP_CDEMO_SK                integer,\n    CS_SHIP_HDEMO_SK                integer,\n    CS_SHIP_ADDR_SK                 integer,\n    CS_CALL_CENTER_SK               integer,\n    CS_CATALOG_PAGE_SK              integer,\n    CS_SHIP_MODE_SK                 integer,\n    CS_WAREHOUSE_SK                 integer,\n    CS_ITEM_SK                      integer,\n    CS_PROMO_SK                     integer,\n    CS_ORDER_NUMBER                 bigint,\n    CS_QUANTITY                     integer,\n    CS_WHOLESALE_COST               decimal(7,2),\n    CS_LIST_PRICE                   decimal(7,2),\n    CS_SALES_PRICE                  decimal(7,2),\n    CS_EXT_DISCOUNT_AMT             decimal(7,2),\n    CS_EXT_SALES_PRICE              decimal(7,2),\n    CS_EXT_WHOLESALE_COST           decimal(7,2),\n    CS_EXT_LIST_PRICE               decimal(7,2),\n    CS_EXT_TAX                      decimal(7,2),\n    CS_COUPON_AMT                   decimal(7,2),\n    CS_EXT_SHIP_COST                decimal(7,2),\n    CS_NET_PAID                     decimal(7,2),\n    CS_NET_PAID_INC_TAX             decimal(7,2),\n    CS_NET_PAID_INC_SHIP            decimal(7,2),\n    CS_NET_PAID_INC_SHIP_TAX        decimal(7,2),\n    CS_NET_PROFIT                   decimal(7,2)\n) AS catalog_sales;\nGO\n\nCREATE VIEW [customer] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/customer/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    C_CUSTOMER_SK                   integer,\n    C_CUSTOMER_ID                   char(16) COLLATE Latin1_General_100_BIN2_UTF8,\n    C_CURRENT_CDEMO_SK              integer,\n    C_CURRENT_HDEMO_SK              integer,\n    C_CURRENT_ADDR_SK               integer,\n    C_FIRST_SHIPTO_DATE_SK          integer,\n    C_FIRST_SALES_DATE_SK           integer,\n    C_SALUTATION                    char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    C_FIRST_NAME                    char(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    C_LAST_NAME                     char(30) COLLATE Latin1_General_100_BIN2_UTF8,\n    C_PREFERRED_CUST_FLAG           char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    C_BIRTH_DAY                     integer,\n    C_BIRTH_MONTH                   integer,\n    C_BIRTH_YEAR                    integer,\n    C_BIRTH_COUNTRY                 varchar(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    C_LOGIN                         char(13) COLLATE Latin1_General_100_BIN2_UTF8,\n    C_EMAIL_ADDRESS                 char(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    C_LAST_REVIEW_DATE_SK           integer\n) AS customer;\nGO\n\nCREATE VIEW [customer_address] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/customer_address/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    CA_ADDRESS_SK                   integer,\n    CA_ADDRESS_ID                   char(16) COLLATE Latin1_General_100_BIN2_UTF8,\n    CA_STREET_NUMBER                char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    CA_STREET_NAME                  varchar(60) COLLATE Latin1_General_100_BIN2_UTF8,\n    CA_STREET_TYPE                  char(15) COLLATE Latin1_General_100_BIN2_UTF8,\n    CA_SUITE_NUMBER                 char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    CA_CITY                         varchar(60) COLLATE Latin1_General_100_BIN2_UTF8,\n    CA_COUNTY                       varchar(30) COLLATE Latin1_General_100_BIN2_UTF8,\n    CA_STATE                        char(2) COLLATE Latin1_General_100_BIN2_UTF8,\n    CA_ZIP                          char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    CA_COUNTRY                      varchar(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    CA_GMT_OFFSET                   decimal(5,2),\n    CA_LOCATION_TYPE                char(20) COLLATE Latin1_General_100_BIN2_UTF8\n) AS customer_address;\nGO\n\nCREATE VIEW [customer_demographics] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/customer_demographics/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    CD_DEMO_SK                      integer,\n    CD_GENDER                       char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    CD_MARITAL_STATUS               char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    CD_EDUCATION_STATUS             char(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    CD_PURCHASE_ESTIMATE            integer,\n    CD_CREDIT_RATING                char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    CD_DEP_COUNT                    integer, \n    CD_DEP_EMPLOYED_COUNT           integer,\n    CD_DEP_COLLEGE_COUNT            integer\n) AS customer_demographics;\nGO\n\nCREATE VIEW [date_dim] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/date_dim/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    D_DATE_SK                 integer,\n    D_DATE_ID                 char(16) COLLATE Latin1_General_100_BIN2_UTF8,\n    D_DATE                    date,\n    D_MONTH_SEQ               integer,\n    D_WEEK_SEQ                integer,\n    D_QUARTER_SEQ             integer,\n    D_YEAR                    integer,\n    D_DOW                     integer,\n    D_MOY                     integer,\n    D_DOM                     integer,\n    D_QOY                     integer,\n    D_FY_YEAR                 integer,\n    D_FY_QUARTER_SEQ          integer,\n    D_FY_WEEK_SEQ             integer,\n    D_DAY_NAME                char(9) COLLATE Latin1_General_100_BIN2_UTF8,\n    D_QUARTER_NAME            char(6) COLLATE Latin1_General_100_BIN2_UTF8,\n    D_HOLIDAY                 char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    D_WEEKEND                 char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    D_FOLLOWING_HOLIDAY       char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    D_FIRST_DOM               integer,\n    D_LAST_DOM                integer,\n    D_SAME_DAY_LY             integer,\n    D_SAME_DAY_LQ             integer,\n    D_CURRENT_DAY             char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    D_CURRENT_WEEK            char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    D_CURRENT_MONTH           char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    D_CURRENT_QUARTER         char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    D_CURRENT_YEAR            char(1) COLLATE Latin1_General_100_BIN2_UTF8\n) AS date_dim;\nGO\n\nCREATE VIEW [household_demographics] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/household_demographics/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    HD_DEMO_SK                      integer,\n    HD_INCOME_BAND_SK               integer,\n    HD_BUY_POTENTIAL                char(15) COLLATE Latin1_General_100_BIN2_UTF8,\n    HD_DEP_COUNT                    integer,\n    HD_VEHICLE_COUNT                integer\n) AS household_demographics;\nGO\n\nCREATE VIEW [income_band] AS \nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/income_band/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    IB_INCOME_BAND_SK         integer,\n    IB_LOWER_BOUND            integer,\n    IB_UPPER_BOUND            integer\n) AS income_band;\nGO\n\nCREATE VIEW [inventory] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/inventory/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    INV_DATE_SK                     integer,\n    INV_ITEM_SK                     integer,\n    INV_WAREHOUSE_SK                integer,\n    INV_QUANTITY_ON_HAND            integer\n) AS inventory;\nGO\n\nCREATE VIEW [item] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/item/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    I_ITEM_SK                       integer,\n    I_ITEM_ID                       char(16) COLLATE Latin1_General_100_BIN2_UTF8,\n    I_REC_START_DATE                date,\n    I_REC_END_DATE                  date,\n    I_ITEM_DESC                     varchar(200) COLLATE Latin1_General_100_BIN2_UTF8,\n    I_CURRENT_PRICE                 decimal(7,2),\n    I_WHOLESALE_COST                decimal(7,2),\n    I_BRAND_ID                      integer,\n    I_BRAND                         char(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    I_CLASS_ID                      integer,\n    I_CLASS                         char(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    I_CTGRY_ID                      integer,\n    I_CTGRY                         char(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    I_MANUFACT_ID                   integer,\n    I_MANUFACT                      char(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    I_SIZE                          char(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    I_FORMULATION                   char(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    I_COLOR                         char(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    I_UNITS                         char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    I_CONTAINER                     char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    I_MANAGER_ID                    integer,\n    I_PRODUCT_NAME                  char(50) COLLATE Latin1_General_100_BIN2_UTF8\n) AS item;\nGO\n \nCREATE VIEW [promotion] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/promotion/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    P_PROMO_SK                      integer,\n    P_PROMO_ID                      char(16) COLLATE Latin1_General_100_BIN2_UTF8,\n    P_START_DATE_SK                 integer,\n    P_END_DATE_SK                   integer,\n    P_ITEM_SK                       integer,\n    P_COST                          decimal(15,2),\n    P_RESPONSE_TARGET               integer,\n    P_PROMO_NAME                    char(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    P_CHANNEL_DMAIL                 char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    P_CHANNEL_EMAIL                 char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    P_CHANNEL_CATALOG               char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    P_CHANNEL_TV                    char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    P_CHANNEL_RADIO                 char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    P_CHANNEL_PRESS                 char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    P_CHANNEL_EVENT                 char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    P_CHANNEL_DEMO                  char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    P_CHANNEL_DETAILS               varchar(100) COLLATE Latin1_General_100_BIN2_UTF8,\n    P_PURPOSE                       char(15) COLLATE Latin1_General_100_BIN2_UTF8,\n    P_DISCOUNT_ACTIVE               char(1) COLLATE Latin1_General_100_BIN2_UTF8\n) AS promotion;\nGO\n\nCREATE VIEW [reason] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/reason/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    R_REASON_SK               integer,\n    R_REASON_ID               char(16) COLLATE Latin1_General_100_BIN2_UTF8,\n    R_REASON_DESC             char(100) COLLATE Latin1_General_100_BIN2_UTF8\n) AS reason;\nGO\n\nCREATE VIEW [ship_mode] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/ship_mode/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    SM_SHIP_MODE_SK           integer,\n    SM_SHIP_MODE_ID           char(16) COLLATE Latin1_General_100_BIN2_UTF8,\n    SM_TYPE                   char(30) COLLATE Latin1_General_100_BIN2_UTF8,\n    SM_CODE                   char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    SM_CARRIER                char(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    SM_CONTRACT               char(20) COLLATE Latin1_General_100_BIN2_UTF8\n) AS ship_mode;\nGO\n\nCREATE VIEW [store] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/store/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    S_STORE_SK                      integer,\n    S_STORE_ID                      char(16) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_REC_START_DATE                date,\n    S_REC_END_DATE                  date,\n    S_CLOSED_DATE_SK                integer,\n    S_STORE_NAME                    varchar(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_NUMBER_EMPLOYEES              integer,\n    S_FLOOR_SPACE                   integer,\n    S_HOURS                         char(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_MANAGER                       varchar(40) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_MARKET_ID                     integer,\n    S_GEOGRAPHY_CLASS               varchar(100) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_MARKET_DESC                   varchar(100) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_MARKET_MANAGER                varchar(40) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_DIVISION_ID                   integer,\n    S_DIVISION_NAME                 varchar(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_COMPANY_ID                    integer,\n    S_COMPANY_NAME                  varchar(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_STREET_NUMBER                 varchar(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_STREET_NAME                   varchar(60) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_STREET_TYPE                   char(15) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_SUITE_NUMBER                  char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_CITY                          varchar(60) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_COUNTY                        varchar(30) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_STATE                         char(2) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_ZIP                           char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_COUNTRY                       varchar(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    S_GMT_OFFSET                    decimal(5,2),\n    S_TAX_PRECENTAGE                decimal(5,2)\n) AS store;\nGO\n\nCREATE VIEW [store_returns] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/store_returns/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    SR_RETURNED_DATE_SK       integer,\n    SR_RETURN_TIME_SK         integer,\n    SR_ITEM_SK                integer,\n    SR_CUSTOMER_SK            integer,\n    SR_CDEMO_SK               integer,\n    SR_HDEMO_SK               integer,\n    SR_ADDR_SK                integer,\n    SR_STORE_SK               integer,\n    SR_REASON_SK              integer,\n    SR_TICKET_NUMBER          integer,\n    SR_RETURN_QUANTITY        integer,\n    SR_RETURN_AMT             decimal(7,2),\n    SR_RETURN_TAX             decimal(7,2),\n    SR_RETURN_AMT_INC_TAX     decimal(7,2),\n    SR_FEE                    decimal(7,2),\n    SR_RETURN_SHIP_COST       decimal(7,2),\n    SR_REFUNDED_CASH          decimal(7,2),\n    SR_REVERSED_CHARGE        decimal(7,2),\n    SR_STORE_CREDIT           decimal(7,2),\n    SR_NET_LOSS               decimal(7,2)\n) AS store_returns;\nGO\n\nCREATE VIEW [store_sales] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/store_sales/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    SS_SOLD_DATE_SK                   integer,\n    SS_SOLD_TIME_SK                   integer,\n    SS_ITEM_SK                        integer,\n    SS_CUSTOMER_SK                    integer,\n    SS_CDEMO_SK                       integer,\n    SS_HDEMO_SK                       integer,\n    SS_ADDR_SK                        integer,\n    SS_STORE_SK                       integer,\n    SS_PROMO_SK                       integer,\n    SS_TICKET_NUMBER                  integer,\n    SS_QUANTITY                       integer,\n    SS_WHOLESALE_COST                 decimal(7, 2),\n    SS_LIST_PRICE                     decimal(7, 2),\n    SS_SALES_PRICE                    decimal(7, 2),\n    SS_EXT_DISCOUNT_AMT               decimal(7, 2),\n    SS_EXT_SALES_PRICE                decimal(7, 2),\n    SS_EXT_WHOLESALE_COST             decimal(7, 2),\n    SS_EXT_LIST_PRICE                 decimal(7, 2),\n    SS_EXT_TAX                        decimal(7, 2),\n    SS_COUPON_AMT                     decimal(7, 2),\n    SS_NET_PAID                       decimal(7, 2),\n    SS_NET_PAID_INC_TAX               decimal(7, 2),\n    SS_NET_PROFIT                     decimal(7, 2)\n) AS store_sales;\nGO\n\nCREATE VIEW [time_dim] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/time_dim/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    T_TIME_SK                 integer,\n    T_TIME_ID                 char(16) COLLATE Latin1_General_100_BIN2_UTF8,\n    T_TIME                    integer,\n    T_HOUR                    integer,\n    T_MINUTE                  integer,\n    T_SECOND                  integer,\n    T_AM_PM                   char(2) COLLATE Latin1_General_100_BIN2_UTF8,\n    T_SHIFT                   char(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    T_SUB_SHIFT               char(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    T_MEAL_TIME               char(20) COLLATE Latin1_General_100_BIN2_UTF8\n) AS time_dim;\nGO\n\nCREATE VIEW [warehouse] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/warehouse/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    W_WAREHOUSE_SK            integer,\n    W_WAREHOUSE_ID            char(16) COLLATE Latin1_General_100_BIN2_UTF8,\n    W_WAREHOUSE_NAME          varchar(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    W_WAREHOUSE_SQ_FT         integer,\n    W_STREET_NUMBER           char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    W_STREET_NAME             varchar(60) COLLATE Latin1_General_100_BIN2_UTF8,\n    W_STREET_TYPE             char(15) COLLATE Latin1_General_100_BIN2_UTF8,\n    W_SUITE_NUMBER            char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    W_CITY                    varchar(60) COLLATE Latin1_General_100_BIN2_UTF8,\n    W_COUNTY                  varchar(30) COLLATE Latin1_General_100_BIN2_UTF8,\n    W_STATE                   char(2) COLLATE Latin1_General_100_BIN2_UTF8,\n    W_ZIP                     char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    W_COUNTRY                 varchar(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    W_GMT_OFFSET              decimal(5,2)\n) AS warehouse;\nGO\n\nCREATE VIEW [web_page] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/web_page/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    WP_WEB_PAGE_SK            integer,\n    WP_WEB_PAGE_ID            char(16) COLLATE Latin1_General_100_BIN2_UTF8,\n    WP_REC_START_DATE         date,\n    WP_REC_END_DATE           date,\n    WP_CREATION_DATE_SK       integer,\n    WP_ACCESS_DATE_SK         integer,\n    WP_AUTOGEN_FLAG           char(1) COLLATE Latin1_General_100_BIN2_UTF8,\n    WP_CUSTOMER_SK            integer,\n    WP_URL                    varchar(100) COLLATE Latin1_General_100_BIN2_UTF8,\n    WP_TYPE                   char(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    WP_CHAR_COUNT             integer,\n    WP_LINK_COUNT             integer,\n    WP_IMAGE_COUNT            integer,\n    WP_MAX_AD_COUNT           integer\n) AS web_page;\nGO\n\nCREATE VIEW [web_returns] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/web_returns/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    WR_RETURNED_DATE_SK             integer,\n    WR_RETURNED_TIME_SK             integer,\n    WR_ITEM_SK                      integer,\n    WR_REFUNDED_CUSTOMER_SK         integer,\n    WR_REFUNDED_CDEMO_SK            integer,\n    WR_REFUNDED_HDEMO_SK            integer,\n    WR_REFUNDED_ADDR_SK             integer,\n    WR_RETURNING_CUSTOMER_SK        integer,\n    WR_RETURNING_CDEMO_SK           integer,\n    WR_RETURNING_HDEMO_SK           integer,\n    WR_RETURNING_ADDR_SK            integer,\n    WR_WEB_PAGE_SK                  integer,\n    WR_REASON_SK                    integer,\n    WR_ORDER_NUMBER                 integer,\n    WR_RETURN_QUANTITY              integer,\n    WR_RETURN_AMT                   decimal(7,2),\n    WR_RETURN_TAX                   decimal(7,2),\n    WR_RETURN_AMT_INC_TAX           decimal(7,2),\n    WR_FEE                          decimal(7,2),\n    WR_RETURN_SHIP_COST             decimal(7,2),\n    WR_REFUNDED_CASH                decimal(7,2),\n    WR_REVERSED_CHARGE              decimal(7,2),\n    WR_ACCOUNT_CREDIT               decimal(7,2),\n    WR_NET_LOSS                     decimal(7,2)\n) AS web_returns;\nGO\n\nCREATE VIEW [web_sales] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/web_sales/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    WS_SOLD_DATE_SK                 integer,\n    WS_SOLD_TIME_SK                 integer,\n    WS_SHIP_DATE_SK                 integer,\n    WS_ITEM_SK                      integer,\n    WS_BILL_CUSTOMER_SK             integer,\n    WS_BILL_CDEMO_SK                integer,\n    WS_BILL_HDEMO_SK                integer,\n    WS_BILL_ADDR_SK                 integer,\n    WS_SHIP_CUSTOMER_SK             integer,\n    WS_SHIP_CDEMO_SK                integer,\n    WS_SHIP_HDEMO_SK                integer,\n    WS_SHIP_ADDR_SK                 integer,\n    WS_WEB_PAGE_SK                  integer,\n    WS_WEB_SITE_SK                  integer,\n    WS_SHIP_MODE_SK                 integer,\n    WS_WAREHOUSE_SK                 integer,\n    WS_PROMO_SK                     integer,\n    WS_ORDER_NUMBER                 integer,\n    WS_QUANTITY                     integer,\n    WS_WHOLESALE_COST               decimal(7,2),\n    WS_LIST_PRICE                   decimal(7,2),\n    WS_SALES_PRICE                  decimal(7,2),\n    WS_EXT_DISCOUNT_AMT             decimal(7,2),\n    WS_EXT_SALES_PRICE              decimal(7,2),\n    WS_EXT_WHOLESALE_COST           decimal(7,2),\n    WS_EXT_LIST_PRICE               decimal(7,2),\n    WS_EXT_TAX                      decimal(7,2),\n    WS_COUPON_AMT                   decimal(7,2),\n    WS_EXT_SHIP_COST                decimal(7,2),\n    WS_NET_PAID                     decimal(7,2),\n    WS_NET_PAID_INC_TAX             decimal(7,2),\n    WS_NET_PAID_INC_SHIP            decimal(7,2),\n    WS_NET_PAID_INC_SHIP_TAX        decimal(7,2),\n    WS_NET_PROFIT                   decimal(7,2)\n) AS web_sales;\nGO\n\nCREATE VIEW [web_site] AS\nSELECT * FROM\nOPENROWSET(\n\tBULK N'parquet/web_site/*', FORMAT = 'PARQUET', FIELDTERMINATOR = '|', DATA_SOURCE = 'tpcds_data') \n\tWITH (\n    WEB_SITE_SK               integer,\n    WEB_SITE_ID               char(16) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_REC_START_DATE        date,\n    WEB_REC_END_DATE          date,\n    WEB_NAME                  varchar(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_OPEN_DATE_SK          integer,\n    WEB_CLOSE_DATE_SK         integer,\n    WEB_CLASS                 varchar(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_MANAGER               varchar(40) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_MKT_ID                integer,\n    WEB_MKT_CLASS             varchar(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_MKT_DESC              varchar(100) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_MARKET_MANAGER        varchar(40) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_COMPANY_ID            integer,\n    WEB_COMPANY_NAME          char(50) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_STREET_NUMBER         char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_STREET_NAME           varchar(60) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_STREET_TYPE           char(15) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_SUITE_NUMBER          char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_CITY                  varchar(60) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_COUNTY                varchar(30) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_STATE                 char(2) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_ZIP                   char(10) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_COUNTRY               varchar(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    WEB_GMT_OFFSET            decimal(5,2),\n    WEB_TAX_PERCENTAGE        decimal(5,2)\n) AS web_site;\nGO\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tpc-ds-external-tables')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Misc/TPC-DS"
				},
				"content": {
					"query": "-- Create the external file format if it doesn't exist already\nIF NOT EXISTS (SELECT * FROM sys.external_file_formats WHERE name = 'SynapseDelimitedTextFormat') \n\tCREATE EXTERNAL FILE FORMAT [SynapseDelimitedTextFormat] \n\tWITH ( FORMAT_TYPE = DELIMITEDTEXT ,\n\t       FORMAT_OPTIONS (\n\t\t\t FIELD_TERMINATOR = ',',\n\t\t\t USE_TYPE_DEFAULT = FALSE\n\t\t\t))\nGO\n\n-- Create the external data source if it doesn't exist already\nIF NOT EXISTS (SELECT * FROM sys.external_data_sources WHERE name = 'datalake2020_minastirith_dfs_core_windows_net') \n\tCREATE EXTERNAL DATA SOURCE [datalake2020_minastirith_dfs_core_windows_net] \n\tWITH (\n\t\tLOCATION = 'abfss://datalake2020@minastirith.dfs.core.windows.net', \n\t\tTYPE = HADOOP \n\t)\nGO\n\n\n-- Create the ext schema\ncreate schema ext;\n\n--drop EXTERNAL TABLE catalog_sales;\n\nCREATE EXTERNAL TABLE ext.catalog_sales (\n\tcs_sold_date_sk VARCHAR(2000)\n\t,cs_sold_time_sk VARCHAR(2000)\n\t,cs_ship_date_sk VARCHAR(2000)\n\t,cs_bill_customer_sk VARCHAR(2000)\n\t,cs_bill_cdemo_sk VARCHAR(2000)\n\t,cs_bill_hdemo_sk VARCHAR(2000)\n\t,cs_bill_addr_sk VARCHAR(2000)\n\t,cs_ship_customer_sk VARCHAR(2000)\n\t,cs_ship_cdemo_sk VARCHAR(2000)\n\t,cs_ship_hdemo_sk VARCHAR(2000)\n\t,cs_ship_addr_sk VARCHAR(2000)\n\t,cs_call_center_sk VARCHAR(2000)\n\t,cs_catalog_page_sk VARCHAR(2000)\n\t,cs_ship_mode_sk VARCHAR(2000)\n\t,cs_warehouse_sk VARCHAR(2000)\n\t,cs_item_sk VARCHAR(2000)\n\t,cs_promo_sk VARCHAR(2000)\n\t,cs_order_number VARCHAR(2000)\n\t,cs_quantity VARCHAR(2000)\n\t,cs_wholesale_cost VARCHAR(2000)\n\t,cs_list_price VARCHAR(2000)\n\t,cs_sales_price VARCHAR(2000)\n\t,cs_ext_discount_amt VARCHAR(2000)\n\t,cs_ext_sales_price VARCHAR(2000)\n\t,cs_ext_wholesale_cost VARCHAR(2000)\n\t,cs_ext_list_price VARCHAR(2000)\n\t,cs_ext_tax VARCHAR(2000)\n\t,cs_coupon_amt VARCHAR(2000)\n\t,cs_ext_ship_cost VARCHAR(2000)\n\t,cs_net_paid VARCHAR(2000)\n\t,cs_net_paid_inc_tax VARCHAR(2000)\n\t,cs_net_paid_inc_ship VARCHAR(2000)\n\t,cs_net_paid_inc_ship_tax VARCHAR(2000)\n\t,cs_net_profit VARCHAR(2000)\n\t)\n\tWITH (\n\tLOCATION = 'TPC-DS/SourceFiles001TB_csv/catalog_sales/part-00000-tid-8479618599068395054-a7843efc-19d3-441d-a884-fa8224b1de09-96-1-c000.csv',\n\tDATA_SOURCE = [datalake2020_minastirith_dfs_core_windows_net],\n\tFILE_FORMAT = [SynapseDelimitedTextFormat]\n\t)\nGO\n\n\nSELECT TOP 100 * FROM ext.catalog_sales\nGO\n\nSELECT count(*) FROM ext.catalog_sales\nGO\n-- 368,637,378\n\n-- Create a smaller table - 70m records instead of 368m\nCREATE EXTERNAL TABLE ext.catalog_sales70M\nWITH (  \n        LOCATION='TPC-DS/SourceFiles001TB_csv/catalog_sales70M/',  \n        DATA_SOURCE = datalake2020_minastirith_dfs_core_windows_net,\n        FILE_FORMAT = SynapseDelimitedTextFormat\n) AS \nselect top 70000000 * from ext.catalog_sales;\n-- 00:34:26\n\nselect top 10 * from ext.catalog_sales70M",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Demo-KQL-IoT-Building-Sensor')]",
			"type": "Microsoft.Synapse/workspaces/kqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "// Drop target table for IoT data:\n//.drop table buidingenv\n\n// Create target table for IoT data:\n.create table buidingenv (timestamp: datetime, temperature: real, humidity: real)\n.create table buidingenv ingestion json mapping 'buidingenvMapping' '[{\"column\": \"timestamp\",\"path\": \"$.timestamp\",\"datatype\": \"datetime\" },{\"column\": \"humidity\",\"path\": \"$.humidity\",\"datatype\": \"real\"},{\"column\": \"temperature\",\"path\": \"$.temperature\",\"datatype\": \"real\"}]'\n\n// Return all records\nbuidingenv_v2 | count\n\n\n// Return all records for the last day\nbuidingenv_v2\n//| where timestamp > now(-1d) and timestamp <= now()\n| order by timestamp desc\n| limit 10\n| count\n\n\n// Average temperature by date & hour, rounded to 2 decimal places\nbuidingenv \n| summarize round(avg(temperature),2) by \n     year = datetime_part(\"year\", timestamp)\n    ,month = datetime_part(\"month\", timestamp)\n    ,day = datetime_part(\"day\", timestamp)\n    ,hour = datetime_part(\"hour\", timestamp)\n| where hour != ''\n| order by year asc, month asc, day asc, hour asc\n\n// Count of records per hour\nbuidingenv \n| summarize RecordCount = count() by ISO8601 = substring(tostring(timestamp),0,13)\n| where ISO8601 != ''\n| order by ISO8601 asc\n\n\n// Now switch to the new table\n\n// Count of messages per deviceID\nbuidingenv_v2\n| summarize RecordCount = count() by device = deviceid\n| order by device asc\n// IoTUbuntu           3405\n// IoTWinServer2019    2493\n\n// Count of records per hour\nbuidingenv_v2\n| summarize RecordCount = count() by ISO8601 = substring(tostring(timestamp),0,13), deviceid\n| where ISO8601 != '' and ISO8601 != '2021-09-24T13'\n| order by ISO8601 desc, deviceid asc\n\n\n\n// Daily query to extract from ADX cluster & persist for historical analysis\nbuidingenv_v2\n| where toint(datetime_part(\"day\", timestamp)) == datetime_part(\"day\", now(-1d))\n| count\n// 77,820\n\n// Compare yesterday's data to the day before\nbuidingenv_v2\n| where toint(datetime_part(\"day\", timestamp)) == datetime_part(\"day\", now(-2d))\n| count\n// 138,451\n\n// Compare yesterday's data to the day before, and the day before that\nbuidingenv_v2\n| where toint(datetime_part(\"day\", timestamp)) == datetime_part(\"day\", now(-3d))\n| count\n// 162,208\n\n// Count of records per hour, exclude first hour data was sent in & latest 1 hour increment\nbuidingenv_v2\n| summarize RecordCount = count() by ISO8601 = substring(tostring(timestamp),0,13), deviceid\n| where ISO8601 != '' and ISO8601 != '2021-09-24T13' and ISO8601 != substring(tostring(now()),0,13)\n| order by ISO8601 desc, deviceid asc\n\n// Return most recent records added\nbuidingenv_v2\n| order by timestamp desc\n| limit 15",
					"metadata": {
						"language": "kql"
					}
				},
				"type": "KqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Misc-KQL-Create-IoT-Table')]",
			"type": "Microsoft.Synapse/workspaces/kqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "// Create a table to ingest data into from IoT Hub\n//.create table PerceptInferences (col1: string, col2: string)\n\n.drop table PerceptInferences\n\n.create table PerceptInferences (label: string, confidence: real, timestamp: real)\n.create table PerceptInferences ingestion json mapping 'PerceptMapping' '[{\"column\":\"label\",\"path\":\"$.NEURAL_NETWORK.label\",\"datatype\":\"string\"},{\"column\":\"confidence\",\"path\":\"$.NEURAL_NETWORK.confidence\",\"datatype\":\"real\"},,{\"column\":\"timestamp\",\"path\":\"$.NEURAL_NETWORK.timestamp\",\"datatype\":\"real\"}]'\n\n\n",
					"metadata": {
						"language": "kql"
					}
				},
				"type": "KqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Misc-KQL-Query-ADLS-CSV')]",
			"type": "Microsoft.Synapse/workspaces/kqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "// This seems to create the table, but I don't think the connection string is correct\n.create external table ExternalTable (tripduration:string, starttime:string, stoptime:string, start_station_id:string, start_station_name:string, start_station_lat:string, start_station_long:string, end_station_id:string, end_station_name:string, end_station_lat:string, end_station_long:string, bikeid:string, usertype:string, birth_year:string, gender:string)  \nkind=adl\ndataformat=csv \n( \n   h@'https://minastirith.dfs.core.windows.net/datalake2020/01-fresh/biketrips/2020/202001-citibike-tripdata.csv' \n)\n\n// show me the data - shows me an empty table with error\nexternal_table('ExternalTable') | take 1000\n\n\n// drop the table\n.drop external table ExternalTable",
					"metadata": {
						"language": "kql"
					}
				},
				"type": "KqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Misc-KQL-iot-building-sensor')]",
			"type": "Microsoft.Synapse/workspaces/kqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "// Drop target table for IoT data:\n//.drop table buidingenv\n\n// Create target table for IoT data:\n.create table buidingenv_v2 (timestamp: datetime, deviceid: string, temperature: real, humidity: real)\n.create table buidingenv_v2 ingestion json mapping 'buidingenvMapping_v2' '[{\"column\": \"timestamp\",\"path\": \"$.timestamp\",\"datatype\": \"datetime\" },{\"column\": \"deviceid\",\"path\": \"$.deviceid\",\"datatype\": \"string\" },{\"column\": \"humidity\",\"path\": \"$.humidity\",\"datatype\": \"real\"},{\"column\": \"temperature\",\"path\": \"$.temperature\",\"datatype\": \"real\"}]'\n\n// Return all records\nbuidingenv_v2 | count\n\n\n// Return all records for the last day\nbuidingenv\n| where timestamp > now(-2d) and timestamp <= now(-1d)\n| order by timestamp asc\n| count\n// As of 20210923 4pm - 79727 \n// As of 20210924 9am - \n\n// Average temperature by hour\nbuidingenv\n| summarize round(avg(temperature),2) by hour = datetime_part(\"hour\", timestamp) \n\n\n// Average temperature by hour, rounded to 2 decimal places\nbuidingenv | summarize round(avg(temperature),2) by hour = datetime_part(\"hour\", timestamp) \n\n\n// Average temperature by date & hour, rounded to 2 decimal places\nbuidingenv \n| summarize round(avg(temperature),2) by \n     year = datetime_part(\"year\", timestamp)\n    ,month = datetime_part(\"month\", timestamp)\n    ,day = datetime_part(\"day\", timestamp)\n    ,hour = datetime_part(\"hour\", timestamp)\n| where hour != ''\n| order by year asc, month asc, day asc, hour asc\n\n\n// Count records in the table\nbuidingenv | count\n// 148,415\n\n\n// View data in the table\nbuidingenv\n| order by timestamp desc\n| limit 10 \n\n\n// Count of records per hour\nbuidingenv \n| summarize RecordCount = count() by \n     ISO8601 = strcat(datetime_part(\"year\", timestamp),\"-\",iif(toint(datetime_part(\"month\", timestamp)) < 10, strcat(\"0\",datetime_part(\"month\", timestamp)),tostring((datetime_part(\"month\", timestamp)))),\"-\",iif(toint(datetime_part(\"day\", timestamp)) < 10, strcat(\"0\",datetime_part(\"day\", timestamp)),tostring((datetime_part(\"day\", timestamp)))),\"T\",iif(toint(datetime_part(\"hour\", timestamp)) < 10, strcat(\"0\",datetime_part(\"hour\", timestamp)),tostring((datetime_part(\"hour\", timestamp)))))\n    ,timestamp\n    ,ISO2 = substring(tostring(timestamp),0,13)\n    ,year = datetime_part(\"year\", timestamp)\n    ,month = iif(toint(datetime_part(\"month\", timestamp)) < 10, strcat(\"0\",datetime_part(\"month\", timestamp)),tostring((datetime_part(\"month\", timestamp))))\n    ,day = iif(toint(datetime_part(\"day\", timestamp)) < 10, strcat(\"0\",datetime_part(\"day\", timestamp)),tostring((datetime_part(\"day\", timestamp))))\n    ,hour = iif(toint(datetime_part(\"hour\", timestamp)) < 10, strcat(\"0\",datetime_part(\"hour\", timestamp)),tostring((datetime_part(\"hour\", timestamp))))\n| where hour != ''\n//| order by year asc, month asc, day asc, hour asc\n| order by ISO8601 asc\n\n\n\n\n\n// Return all records for yesterday\nbuidingenv\n| where toint(datetime_part(\"day\", timestamp)) == datetime_part(\"day\", now(-0d))\n| order by timestamp desc\n| count\n// 40562\n// asc  2021-09-24 00:00:00.132696Z\n// desc 2021-09-24 12:24:55.9175481Z\n\nbuidingenv\n| where toint(datetime_part(\"day\", timestamp)) == datetime_part(\"day\", now(-1d))\n| order by timestamp desc \n| count\n// 78704\n// asc  2021-09-23 00:02:05.7587822Z\n// desc 2021-09-23 23:59:59.0917272Z\n\n\nbuidingenv\n| where toint(datetime_part(\"day\", timestamp)) == datetime_part(\"day\", now(-2d))\n| order by timestamp desc\n| count\n// 80334\n// asc  2021-09-22 00:00:01.0465696Z\n// desc 2021-09-22 23:59:14.7105275Z\n\n\nbuidingenv\n| where toint(datetime_part(\"day\", timestamp)) == datetime_part(\"day\", now(-3d))\n| order by timestamp desc\n| count\n// 38742\n// asc  2021-09-21 12:11:18.5879796Z\n// desc 2021-09-21 23:59:59.99837Z\n\n\n// Switch to new table\n\nbuidingenv_v2\n| where toint(datetime_part(\"day\", timestamp)) == datetime_part(\"day\", now(-3d))\n| order by timestamp desc\n| count\n// 68441\n// asc  2021-09-24T13:34:38.7563626Z\n// desc 2021-09-24T23:59:59.9342816Z\n\n\nbuidingenv_v2\n| where toint(datetime_part(\"day\", timestamp)) == datetime_part(\"day\", now(-2d))\n| order by timestamp asc\n| count\n// 159599\n// asc  2021-09-25T00:00:00.5650615Z\n// desc 2021-09-25T23:59:59.8014913Z\n\nbuidingenv_v2\n| where toint(datetime_part(\"day\", timestamp)) == datetime_part(\"day\", now(-1d)) \n    and substring(tostring(timestamp),0,13) != '' \n    and substring(tostring(timestamp),0,13) != '2021-09-24T13'\n| order by timestamp desc\n| count\n// 162208\n// asc  2021-09-26T00:00:00.5705084Z\n// desc 2021-09-26T23:59:59.990929Z\n\nbuidingenv_v2\n| where toint(datetime_part(\"day\", timestamp)) == datetime_part(\"day\", now(-0d))\n| order by timestamp desc\n| count\n// 96616\n// asc  2021-09-27T00:00:00.8152044Z\n// desc 2021-09-27T14:38:45.077497Z\n\n",
					"metadata": {
						"language": "kql"
					}
				},
				"type": "KqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Misc-KQL-last-hour')]",
			"type": "Microsoft.Synapse/workspaces/kqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "// Compare yesterday's data to the day before, and the day before that\nbuidingenv_v2\n| where toint(datetime_part(\"day\", timestamp)) == datetime_part(\"day\", now(-3d))\n| count\n// 162,208\n\n// Count of records per hour, exclude first hour data was sent in & latest 1 hour increment\nbuidingenv_v2\n| summarize RecordCount = count() by ISO8601 = substring(tostring(timestamp),0,13), deviceid\n| where ISO8601 != '' and ISO8601 != '2021-09-24T13' and ISO8601 != substring(tostring(now()),0,13)\n| order by ISO8601 desc, deviceid asc\n\n// Records from the last 1 hour\nbuidingenv_v2\n| where timestamp > ago(8h)\n| order by timestamp desc\n| limit 15",
					"metadata": {
						"language": "kql"
					}
				},
				"type": "KqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/00_createAllTablesAndDFs')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "TPC-DS/TPC-DS-01-Create"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "tpcdsXLarge",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "224g",
					"driverCores": 32,
					"executorMemory": "224g",
					"executorCores": 32,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "4f521831-87f9-43e7-97ee-3aaaff7e429e"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/e1bee07b-a025-41e2-ae0f-2291101bce96/resourceGroups/MiddleEarth/providers/Microsoft.Synapse/workspaces/anarion/bigDataPools/tpcdsXLarge",
						"name": "tpcdsXLarge",
						"type": "Spark",
						"endpoint": "https://anarion.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/tpcdsXLarge",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 32,
						"memory": 224
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Set variables in the cell below to be used for each table/DF creation."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"datalakePath='abfss://calembel@gondor2.dfs.core.windows.net/TPC-DS/SourceFiles001TB_parquet/'\r\n",
							"storageFormat='parquet'\r\n",
							"databaseName='tpcds1tb'"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Run the next cell only if doing this the first time, to create the Spark SQL/Lake database"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"create database tpcds1tb;"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Change each cell for the specific schema/table needed. \r\n",
							"This is the list of tables in the TPC-DS schema:\r\n",
							"1. call_center\r\n",
							"1. catalog_page\r\n",
							"2. catalog_returns\r\n",
							"3. catalog_sales\r\n",
							"4. customer\r\n",
							"5. customer_address\r\n",
							"6. customer_demographics\r\n",
							"7. date_dim\r\n",
							"8. houshold_demographics\r\n",
							"9. income_band\r\n",
							"10. inventory\r\n",
							"11. item\r\n",
							"12. promotion\r\n",
							"13. reason\r\n",
							"14. ship_mode\r\n",
							"15. store\r\n",
							"16. store_returns\r\n",
							"17. store_sales\r\n",
							"18. time_dim\r\n",
							"19. warehouse\r\n",
							"20. web_page\r\n",
							"21. web_returns\r\n",
							"22. web_sales\r\n",
							"23. web_site"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='call_center'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='catalog_page'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='catalog_returns'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='catalog_sales'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='customer'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='customer_address'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='customer_demographics'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='date_dim'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='household_demographics'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='income_band'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='inventory'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 20
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='item'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='promotion'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='reason'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='ship_mode'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 24
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='store'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 25
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='store_returns'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 26
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='store_sales'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 27
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='time_dim'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 28
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='warehouse'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 29
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='web_page'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 30
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='web_returns'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 31
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='web_sales'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 32
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"schemaType='web_site'\r\n",
							"\r\n",
							"dataPath=datalakePath + schemaType + '/'\r\n",
							"tableName=databaseName + '.' + schemaType\r\n",
							"df = spark.read.load(dataPath, format=storageFormat)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(tableName)\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 33
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/00_testQueryTables')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "TPC-DS/TPC-DS-01-Create"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "tpcdsSmall",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "584b43b1-7ba6-454f-a0df-ab4bc8c0a28c"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "sql"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/e1bee07b-a025-41e2-ae0f-2291101bce96/resourceGroups/MiddleEarth/providers/Microsoft.Synapse/workspaces/anarion/bigDataPools/tpcdsSmall",
						"name": "tpcdsSmall",
						"type": "Spark",
						"endpoint": "https://anarion.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/tpcdsSmall",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Queries below only used to ensure Spark SQL tables are in place for upcoming standard TPC-DS queries."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"use tpcds1tb;"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from call_center limit 10;"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from catalog_page limit 10;"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from catalog_returns limit 10;"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from catalog_sales limit 10;"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from customer limit 10;"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from customer_address limit 10;"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from customer_demographics limit 10;"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from date_dim limit 10;"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from household_demographics limit 10;"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from income_band limit 10;"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from inventory limit 10;"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from item limit 10;"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from promotion limit 10;"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from reason limit 10;"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from ship_mode limit 10;"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from store limit 10;"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from store_returns limit 10;"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from store_sales limit 10;"
						],
						"outputs": [],
						"execution_count": 20
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from time_dim limit 10;"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from warehouse limit 10;"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from web_page limit 10;"
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from web_returns limit 10;"
						],
						"outputs": [],
						"execution_count": 24
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from web_sales limit 10;"
						],
						"outputs": [],
						"execution_count": 25
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"select * from web_site limit 10;"
						],
						"outputs": [],
						"execution_count": 26
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ADLSGen2-data')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Examples"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseSpark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "e429725d-3594-4840-b3ac-53b39598aa2e"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/e1bee07b-a025-41e2-ae0f-2291101bce96/resourceGroups/MiddleEarth/providers/Microsoft.Synapse/workspaces/anarion/bigDataPools/SynapseSpark",
						"name": "SynapseSpark",
						"type": "Spark",
						"endpoint": "https://anarion.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseSpark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Demo notebook for Synapse Spark"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"mssparkutils.fs.mount(\"abfss://calembel@gondor2.dfs.core.windows.net/\",\"/mnt/adls\",{\"linkedService\":\"anarion-WorkspaceDefaultStorage\"}\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Get the JobID of the current/running session (Spark Application)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"mssparkutils.env.getJobId()"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## List files from the ADLS Gen2 mountpoint"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"mssparkutils.fs.ls(\"synfs:/0/mnt/adls/01-raw/biketrips/2022/\")"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import pandas\r\n",
							"\r\n",
							"#read csv file\r\n",
							"df = pandas.read_csv('abfss://calembel@gondor2.dfs.core.windows.net/01-raw/biketrips/2022/202207-citbike-tripdata.csv', low_memory=False)\r\n",
							"print(df)"
						],
						"outputs": [],
						"execution_count": 22
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Example-OpenDatasets')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Examples"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseSpark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "081e6796-229b-482a-9dcb-aeb662eb8981"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/e1bee07b-a025-41e2-ae0f-2291101bce96/resourceGroups/MiddleEarth/providers/Microsoft.Synapse/workspaces/anarion/bigDataPools/SynapseSpark",
						"name": "SynapseSpark",
						"type": "Spark",
						"endpoint": "https://anarion.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseSpark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Data visualization with Synapse Spark"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"In this tutorial, we'll use several different libraries to help us visualize the dataset. To do this analysis, import the following libraries:"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"import matplotlib.pyplot as plt\r\n",
							"import seaborn as sns\r\n",
							"import pandas as pd"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Because the raw data is in a Parquet format, you can use the Spark context to pull the file into memory as a DataFrame directly. \r\n",
							"\r\n",
							"Create a Spark DataFrame by retrieving the data via the Open Datasets API. Here, we use the Spark DataFrame schema on read properties to infer the datatypes and schema."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from azureml.opendatasets import NycTlcYellow\r\n",
							"from datetime import datetime\r\n",
							"from dateutil import parser\r\n",
							"\r\n",
							"end_date = parser.parse('2018-06-06')\r\n",
							"start_date = parser.parse('2018-05-01')\r\n",
							"nyc_tlc = NycTlcYellow(start_date=start_date, end_date=end_date)\r\n",
							"df = nyc_tlc.to_spark_dataframe()"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"After the data is read, we'll want to do some initial filtering to clean the dataset. We might remove unneeded columns and add columns that extract important information. \r\n",
							"\r\n",
							"In addition, we'll filter out anomalies within the dataset and create a temporary view that we can query with Spark SQL."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Filter the dataset \r\n",
							"from pyspark.sql.functions import *\r\n",
							"\r\n",
							"filtered_df = df.select('vendorID', 'passengerCount', 'tripDistance','paymentType', 'fareAmount', 'tipAmount'\\\r\n",
							"                                , date_format('tpepPickupDateTime', 'hh').alias('hour_of_day')\\\r\n",
							"                                , dayofweek('tpepPickupDateTime').alias('day_of_week')\\\r\n",
							"                                , dayofmonth(col('tpepPickupDateTime')).alias('day_of_month'))\\\r\n",
							"                            .filter((df.passengerCount > 0)\\\r\n",
							"                                & (df.tipAmount >= 0)\\\r\n",
							"                                & (df.fareAmount >= 1) & (df.fareAmount <= 250)\\\r\n",
							"                                & (df.tripDistance > 0) & (df.tripDistance <= 200))\r\n",
							"\r\n",
							"filtered_df.createOrReplaceTempView(\"taxi_dataset\")"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"By using this query, we want to understand how the average tip amounts have changed over the period we've selected. \r\n",
							"\r\n",
							"This query will also help us identify other useful insights, including the minimum/maximum tip amount per day and the average fare amount."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"SELECT \r\n",
							"    day_of_month\r\n",
							"    , MIN(tipAmount) AS minTipAmount\r\n",
							"    , MAX(tipAmount) AS maxTipAmount\r\n",
							"    , AVG(tipAmount) AS avgTipAmount\r\n",
							"    , AVG(fareAmount) as fareAmount\r\n",
							"FROM taxi_dataset \r\n",
							"GROUP BY day_of_month\r\n",
							"ORDER BY day_of_month ASC"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"To make development easier and less expensive, we'll downsample the dataset. We'll use the built-in Apache Spark sampling capability. \r\n",
							"\r\n",
							"In addition, both Seaborn and Matplotlib require a Pandas DataFrame or NumPy array. To get a Pandas DataFrame, use the toPandas() command to convert the DataFrame."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# To make development easier, faster, and less expensive, downsample for now\r\n",
							"sampled_taxi_df = filtered_df.sample(True, 0.001, seed=1234)\r\n",
							"\r\n",
							"# The charting package needs a Pandas DataFrame or NumPy array to do the conversion\r\n",
							"sampled_taxi_pd_df = sampled_taxi_df.toPandas()"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"We want to understand the distribution of tips in our dataset. We'll use Matplotlib to create a histogram that shows the distribution of tip amount and count. Based on the distribution, we can see that tips are skewed toward amounts less than or equal to $10."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Look at a histogram of tips by count by using Matplotlib\r\n",
							"\r\n",
							"ax1 = sampled_taxi_pd_df['tipAmount'].plot(kind='hist', bins=25, facecolor='lightblue')\r\n",
							"ax1.set_title('Tip amount distribution')\r\n",
							"ax1.set_xlabel('Tip Amount ($)')\r\n",
							"ax1.set_ylabel('Counts')\r\n",
							"plt.suptitle('')\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Next, we want to understand the relationship between the tips for a given trip and the day of the week. \r\n",
							"\r\n",
							"Use Seaborn to create a box plot that summarizes the trends for each day of the week."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# View the distribution of tips by day of week using Seaborn\r\n",
							"ax = sns.boxplot(x=\"day_of_week\", y=\"tipAmount\",data=sampled_taxi_pd_df, showfliers = False)\r\n",
							"ax.set_title('Tip amount distribution per day')\r\n",
							"ax.set_xlabel('Day of Week')\r\n",
							"ax.set_ylabel('Tip Amount ($)')\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Another hypothesis of ours might be that there's a positive relationship between the number of passengers and the total taxi tip amount. \r\n",
							"\r\n",
							"To verify this relationship, run the following code to generate a box plot that illustrates the distribution of tips for each passenger count."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# How many passengers tipped by various amounts \r\n",
							"ax2 = sampled_taxi_pd_df.boxplot(column=['tipAmount'], by=['passengerCount'])\r\n",
							"ax2.set_title('Tip amount by Passenger count')\r\n",
							"ax2.set_xlabel('Passenger count')\r\n",
							"ax2.set_ylabel('Tip Amount ($)')\r\n",
							"ax2.set_ylim(0,30)\r\n",
							"plt.suptitle('')\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Last, we want to understand the relationship between the fare amount and the tip amount. Based on the results, we can see that there are several observations where people don't tip. \r\n",
							"\r\n",
							"However, we also see a positive relationship between the overall fare and tip amounts."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Look at the relationship between fare and tip amounts\r\n",
							"\r\n",
							"ax = sampled_taxi_pd_df.plot(kind='scatter', x= 'fareAmount', y = 'tipAmount', c='blue', alpha = 0.10, s=2.5*(sampled_taxi_pd_df['passengerCount']))\r\n",
							"ax.set_title('Tip amount by Fare amount')\r\n",
							"ax.set_xlabel('Fare Amount ($)')\r\n",
							"ax.set_ylabel('Tip Amount ($)')\r\n",
							"plt.axis([-2, 80, -2, 20])\r\n",
							"plt.suptitle('')\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 20
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Import-Public-Dataset')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Examples"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseSpark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "6538840b-06b5-43b0-b88b-0fce39ca58e3"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/e1bee07b-a025-41e2-ae0f-2291101bce96/resourceGroups/MiddleEarth/providers/Microsoft.Synapse/workspaces/anarion/bigDataPools/SynapseSpark",
						"name": "SynapseSpark",
						"type": "Spark",
						"endpoint": "https://anarion.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseSpark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"# This is a package in preview.\r\n",
							"from azureml.opendatasets import UsPopulationZip\r\n",
							"\r\n",
							"population = UsPopulationZip()\r\n",
							"population_df = population.to_spark_dataframe()"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# Display top 5 rows\r\n",
							"display(population_df.limit(5))"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"population_df.distinct().count()"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"population_df.write.parquet(\"abfss://calembel@gondor2.dfs.core.windows.net/01-raw/US-Population-by-postal-code/parquet\")"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"population_df.write.csv(\"abfss://calembel@gondor2.dfs.core.windows.net/01-raw/US-Population-by-postal-code/csv\")"
						],
						"outputs": [],
						"execution_count": 19
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tpc-ds-queries-1tb-medium')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "TPC-DS/TPC-DS-02-Run-Queries"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "tpcdsMedium",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "d10a1a51-3ace-4897-a7d7-155676e78208"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_sparksql",
						"display_name": "sql"
					},
					"language_info": {
						"name": "sql"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/e1bee07b-a025-41e2-ae0f-2291101bce96/resourceGroups/MiddleEarth/providers/Microsoft.Synapse/workspaces/anarion/bigDataPools/tpcdsMedium",
						"name": "tpcdsMedium",
						"type": "Spark",
						"endpoint": "https://anarion.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/tpcdsMedium",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 3,
						"cores": 8,
						"memory": 56
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"use tpcds1tb;"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query1\r\n",
							"with customer_total_return as\r\n",
							"(select sr_customer_sk as ctr_customer_sk\r\n",
							",sr_store_sk as ctr_store_sk\r\n",
							",sum(SR_RETURN_AMT) as ctr_total_return\r\n",
							"from store_returns\r\n",
							",date_dim\r\n",
							"where sr_returned_date_sk = d_date_sk\r\n",
							"and d_year =2000\r\n",
							"group by sr_customer_sk\r\n",
							",sr_store_sk)\r\n",
							" select  c_customer_id\r\n",
							"from customer_total_return ctr1\r\n",
							",store\r\n",
							",customer\r\n",
							"where ctr1.ctr_total_return > (select avg(ctr_total_return)*1.2\r\n",
							"from customer_total_return ctr2\r\n",
							"where ctr1.ctr_store_sk = ctr2.ctr_store_sk)\r\n",
							"and s_store_sk = ctr1.ctr_store_sk\r\n",
							"and s_state = 'TN'\r\n",
							"and ctr1.ctr_customer_sk = c_customer_sk\r\n",
							"order by c_customer_id\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query2\r\n",
							" with wscs as\r\n",
							" (select sold_date_sk\r\n",
							"        ,sales_price\r\n",
							"  from  (select ws_sold_date_sk sold_date_sk\r\n",
							"              ,ws_ext_sales_price sales_price\r\n",
							"        from web_sales \r\n",
							"        union all\r\n",
							"        select cs_sold_date_sk sold_date_sk\r\n",
							"              ,cs_ext_sales_price sales_price\r\n",
							"        from catalog_sales) x ),\r\n",
							" wswscs as \r\n",
							" (select d_week_seq,\r\n",
							"        sum(case when (d_day_name='Sunday') then sales_price else null end) sun_sales,\r\n",
							"        sum(case when (d_day_name='Monday') then sales_price else null end) mon_sales,\r\n",
							"        sum(case when (d_day_name='Tuesday') then sales_price else  null end) tue_sales,\r\n",
							"        sum(case when (d_day_name='Wednesday') then sales_price else null end) wed_sales,\r\n",
							"        sum(case when (d_day_name='Thursday') then sales_price else null end) thu_sales,\r\n",
							"        sum(case when (d_day_name='Friday') then sales_price else null end) fri_sales,\r\n",
							"        sum(case when (d_day_name='Saturday') then sales_price else null end) sat_sales\r\n",
							" from wscs\r\n",
							"     ,date_dim\r\n",
							" where d_date_sk = sold_date_sk\r\n",
							" group by d_week_seq)\r\n",
							" select d_week_seq1\r\n",
							"       ,round(sun_sales1/sun_sales2,2)\r\n",
							"       ,round(mon_sales1/mon_sales2,2)\r\n",
							"       ,round(tue_sales1/tue_sales2,2)\r\n",
							"       ,round(wed_sales1/wed_sales2,2)\r\n",
							"       ,round(thu_sales1/thu_sales2,2)\r\n",
							"       ,round(fri_sales1/fri_sales2,2)\r\n",
							"       ,round(sat_sales1/sat_sales2,2)\r\n",
							" from\r\n",
							" (select wswscs.d_week_seq d_week_seq1\r\n",
							"        ,sun_sales sun_sales1\r\n",
							"        ,mon_sales mon_sales1\r\n",
							"        ,tue_sales tue_sales1\r\n",
							"        ,wed_sales wed_sales1\r\n",
							"        ,thu_sales thu_sales1\r\n",
							"        ,fri_sales fri_sales1\r\n",
							"        ,sat_sales sat_sales1\r\n",
							"  from wswscs,date_dim \r\n",
							"  where date_dim.d_week_seq = wswscs.d_week_seq and\r\n",
							"        d_year = 2001) y,\r\n",
							" (select wswscs.d_week_seq d_week_seq2\r\n",
							"        ,sun_sales sun_sales2\r\n",
							"        ,mon_sales mon_sales2\r\n",
							"        ,tue_sales tue_sales2\r\n",
							"        ,wed_sales wed_sales2\r\n",
							"        ,thu_sales thu_sales2\r\n",
							"        ,fri_sales fri_sales2\r\n",
							"        ,sat_sales sat_sales2\r\n",
							"  from wswscs\r\n",
							"      ,date_dim \r\n",
							"  where date_dim.d_week_seq = wswscs.d_week_seq and\r\n",
							"        d_year = 2001+1) z\r\n",
							" where d_week_seq1=d_week_seq2-53\r\n",
							" order by d_week_seq1;\r\n",
							""
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query3\r\n",
							"  select  dt.d_year \r\n",
							"       ,item.i_brand_id brand_id \r\n",
							"       ,item.i_brand brand\r\n",
							"       ,sum(ss_ext_sales_price) sum_agg\r\n",
							" from  date_dim dt \r\n",
							"      ,store_sales\r\n",
							"      ,item\r\n",
							" where dt.d_date_sk = store_sales.ss_sold_date_sk\r\n",
							"   and store_sales.ss_item_sk = item.i_item_sk\r\n",
							"   and item.i_manufact_id = 128\r\n",
							"   and dt.d_moy=11\r\n",
							" group by dt.d_year\r\n",
							"      ,item.i_brand\r\n",
							"      ,item.i_brand_id\r\n",
							" order by dt.d_year\r\n",
							"         ,sum_agg desc\r\n",
							"         ,brand_id\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query4\r\n",
							"with year_total as (\r\n",
							" select c_customer_id customer_id\r\n",
							"       ,c_first_name customer_first_name\r\n",
							"       ,c_last_name customer_last_name\r\n",
							"       ,c_preferred_cust_flag customer_preferred_cust_flag\r\n",
							"       ,c_birth_country customer_birth_country\r\n",
							"       ,c_login customer_login\r\n",
							"       ,c_email_address customer_email_address\r\n",
							"       ,d_year dyear\r\n",
							"       ,sum(((ss_ext_list_price-ss_ext_wholesale_cost-ss_ext_discount_amt)+ss_ext_sales_price)/2) year_total\r\n",
							"       ,'s' sale_type\r\n",
							" from customer\r\n",
							"     ,store_sales\r\n",
							"     ,date_dim\r\n",
							" where c_customer_sk = ss_customer_sk\r\n",
							"   and ss_sold_date_sk = d_date_sk\r\n",
							" group by c_customer_id\r\n",
							"         ,c_first_name\r\n",
							"         ,c_last_name\r\n",
							"         ,c_preferred_cust_flag\r\n",
							"         ,c_birth_country\r\n",
							"         ,c_login\r\n",
							"         ,c_email_address\r\n",
							"         ,d_year\r\n",
							" union all\r\n",
							" select c_customer_id customer_id\r\n",
							"       ,c_first_name customer_first_name\r\n",
							"       ,c_last_name customer_last_name\r\n",
							"       ,c_preferred_cust_flag customer_preferred_cust_flag\r\n",
							"       ,c_birth_country customer_birth_country\r\n",
							"       ,c_login customer_login\r\n",
							"       ,c_email_address customer_email_address\r\n",
							"       ,d_year dyear\r\n",
							"       ,sum((((cs_ext_list_price-cs_ext_wholesale_cost-cs_ext_discount_amt)+cs_ext_sales_price)/2) ) year_total\r\n",
							"       ,'c' sale_type\r\n",
							" from customer\r\n",
							"     ,catalog_sales\r\n",
							"     ,date_dim\r\n",
							" where c_customer_sk = cs_bill_customer_sk\r\n",
							"   and cs_sold_date_sk = d_date_sk\r\n",
							" group by c_customer_id\r\n",
							"         ,c_first_name\r\n",
							"         ,c_last_name\r\n",
							"         ,c_preferred_cust_flag\r\n",
							"         ,c_birth_country\r\n",
							"         ,c_login\r\n",
							"         ,c_email_address\r\n",
							"         ,d_year\r\n",
							"union all\r\n",
							" select c_customer_id customer_id\r\n",
							"       ,c_first_name customer_first_name\r\n",
							"       ,c_last_name customer_last_name\r\n",
							"       ,c_preferred_cust_flag customer_preferred_cust_flag\r\n",
							"       ,c_birth_country customer_birth_country\r\n",
							"       ,c_login customer_login\r\n",
							"       ,c_email_address customer_email_address\r\n",
							"       ,d_year dyear\r\n",
							"       ,sum((((ws_ext_list_price-ws_ext_wholesale_cost-ws_ext_discount_amt)+ws_ext_sales_price)/2) ) year_total\r\n",
							"       ,'w' sale_type\r\n",
							" from customer\r\n",
							"     ,web_sales\r\n",
							"     ,date_dim\r\n",
							" where c_customer_sk = ws_bill_customer_sk\r\n",
							"   and ws_sold_date_sk = d_date_sk\r\n",
							" group by c_customer_id\r\n",
							"         ,c_first_name\r\n",
							"         ,c_last_name\r\n",
							"         ,c_preferred_cust_flag\r\n",
							"         ,c_birth_country\r\n",
							"         ,c_login\r\n",
							"         ,c_email_address\r\n",
							"         ,d_year\r\n",
							"         )\r\n",
							"  select  \r\n",
							"                  t_s_secyear.customer_id\r\n",
							"                 ,t_s_secyear.customer_first_name\r\n",
							"                 ,t_s_secyear.customer_last_name\r\n",
							"                 ,t_s_secyear.customer_preferred_cust_flag\r\n",
							" from year_total t_s_firstyear\r\n",
							"     ,year_total t_s_secyear\r\n",
							"     ,year_total t_c_firstyear\r\n",
							"     ,year_total t_c_secyear\r\n",
							"     ,year_total t_w_firstyear\r\n",
							"     ,year_total t_w_secyear\r\n",
							" where t_s_secyear.customer_id = t_s_firstyear.customer_id\r\n",
							"   and t_s_firstyear.customer_id = t_c_secyear.customer_id\r\n",
							"   and t_s_firstyear.customer_id = t_c_firstyear.customer_id\r\n",
							"   and t_s_firstyear.customer_id = t_w_firstyear.customer_id\r\n",
							"   and t_s_firstyear.customer_id = t_w_secyear.customer_id\r\n",
							"   and t_s_firstyear.sale_type = 's'\r\n",
							"   and t_c_firstyear.sale_type = 'c'\r\n",
							"   and t_w_firstyear.sale_type = 'w'\r\n",
							"   and t_s_secyear.sale_type = 's'\r\n",
							"   and t_c_secyear.sale_type = 'c'\r\n",
							"   and t_w_secyear.sale_type = 'w'\r\n",
							"   and t_s_firstyear.dyear =  2001\r\n",
							"   and t_s_secyear.dyear = 2001+1\r\n",
							"   and t_c_firstyear.dyear =  2001\r\n",
							"   and t_c_secyear.dyear =  2001+1\r\n",
							"   and t_w_firstyear.dyear = 2001\r\n",
							"   and t_w_secyear.dyear = 2001+1\r\n",
							"   and t_s_firstyear.year_total > 0\r\n",
							"   and t_c_firstyear.year_total > 0\r\n",
							"   and t_w_firstyear.year_total > 0\r\n",
							"   and case when t_c_firstyear.year_total > 0 then t_c_secyear.year_total / t_c_firstyear.year_total else null end\r\n",
							"           > case when t_s_firstyear.year_total > 0 then t_s_secyear.year_total / t_s_firstyear.year_total else null end\r\n",
							"   and case when t_c_firstyear.year_total > 0 then t_c_secyear.year_total / t_c_firstyear.year_total else null end\r\n",
							"           > case when t_w_firstyear.year_total > 0 then t_w_secyear.year_total / t_w_firstyear.year_total else null end\r\n",
							" order by t_s_secyear.customer_id\r\n",
							"         ,t_s_secyear.customer_first_name\r\n",
							"         ,t_s_secyear.customer_last_name\r\n",
							"         ,t_s_secyear.customer_preferred_cust_flag\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query5\r\n",
							" with ssr as\r\n",
							" (select s_store_id,\r\n",
							"        sum(sales_price) as sales,\r\n",
							"        sum(profit) as profit,\r\n",
							"        sum(return_amt) as returns,\r\n",
							"        sum(net_loss) as profit_loss\r\n",
							" from\r\n",
							"  ( select  ss_store_sk as store_sk,\r\n",
							"            ss_sold_date_sk  as date_sk,\r\n",
							"            ss_ext_sales_price as sales_price,\r\n",
							"            ss_net_profit as profit,\r\n",
							"            cast(0 as decimal(7,2)) as return_amt,\r\n",
							"            cast(0 as decimal(7,2)) as net_loss\r\n",
							"    from store_sales\r\n",
							"    union all\r\n",
							"    select sr_store_sk as store_sk,\r\n",
							"           sr_returned_date_sk as date_sk,\r\n",
							"           cast(0 as decimal(7,2)) as sales_price,\r\n",
							"           cast(0 as decimal(7,2)) as profit,\r\n",
							"           sr_return_amt as return_amt,\r\n",
							"           sr_net_loss as net_loss\r\n",
							"    from store_returns\r\n",
							"   ) salesreturns,\r\n",
							"     date_dim,\r\n",
							"     store\r\n",
							" where date_sk = d_date_sk\r\n",
							"       and d_date between cast('2000-08-23' as date) \r\n",
							"                  and date_add(cast('2000-08-23' as date), 14 )\r\n",
							"       and store_sk = s_store_sk\r\n",
							" group by s_store_id)\r\n",
							" ,\r\n",
							" csr as\r\n",
							" (select cp_catalog_page_id,\r\n",
							"        sum(sales_price) as sales,\r\n",
							"        sum(profit) as profit,\r\n",
							"        sum(return_amt) as returns,\r\n",
							"        sum(net_loss) as profit_loss\r\n",
							" from\r\n",
							"  ( select  cs_catalog_page_sk as page_sk,\r\n",
							"            cs_sold_date_sk  as date_sk,\r\n",
							"            cs_ext_sales_price as sales_price,\r\n",
							"            cs_net_profit as profit,\r\n",
							"            cast(0 as decimal(7,2)) as return_amt,\r\n",
							"            cast(0 as decimal(7,2)) as net_loss\r\n",
							"    from catalog_sales\r\n",
							"    union all\r\n",
							"    select cr_catalog_page_sk as page_sk,\r\n",
							"           cr_returned_date_sk as date_sk,\r\n",
							"           cast(0 as decimal(7,2)) as sales_price,\r\n",
							"           cast(0 as decimal(7,2)) as profit,\r\n",
							"           cr_return_amount as return_amt,\r\n",
							"           cr_net_loss as net_loss\r\n",
							"    from catalog_returns\r\n",
							"   ) salesreturns,\r\n",
							"     date_dim,\r\n",
							"     catalog_page\r\n",
							" where date_sk = d_date_sk\r\n",
							"       and d_date between cast('2000-08-23' as date)\r\n",
							"                  and date_add(cast('2000-08-23' as date), 14 )\r\n",
							"       and page_sk = cp_catalog_page_sk\r\n",
							" group by cp_catalog_page_id)\r\n",
							" ,\r\n",
							" wsr as\r\n",
							" (select web_site_id,\r\n",
							"        sum(sales_price) as sales,\r\n",
							"        sum(profit) as profit,\r\n",
							"        sum(return_amt) as returns,\r\n",
							"        sum(net_loss) as profit_loss\r\n",
							" from\r\n",
							"  ( select  ws_web_site_sk as wsr_web_site_sk,\r\n",
							"            ws_sold_date_sk  as date_sk,\r\n",
							"            ws_ext_sales_price as sales_price,\r\n",
							"            ws_net_profit as profit,\r\n",
							"            cast(0 as decimal(7,2)) as return_amt,\r\n",
							"            cast(0 as decimal(7,2)) as net_loss\r\n",
							"    from web_sales\r\n",
							"    union all\r\n",
							"    select ws_web_site_sk as wsr_web_site_sk,\r\n",
							"           wr_returned_date_sk as date_sk,\r\n",
							"           cast(0 as decimal(7,2)) as sales_price,\r\n",
							"           cast(0 as decimal(7,2)) as profit,\r\n",
							"           wr_return_amt as return_amt,\r\n",
							"           wr_net_loss as net_loss\r\n",
							"    from web_returns left outer join web_sales on\r\n",
							"         ( wr_item_sk = ws_item_sk\r\n",
							"           and wr_order_number = ws_order_number)\r\n",
							"   ) salesreturns,\r\n",
							"     date_dim,\r\n",
							"     web_site\r\n",
							" where date_sk = d_date_sk\r\n",
							"       and d_date between cast('2000-08-23' as date)\r\n",
							"                  and date_add(cast('2000-08-23' as date), 14 )\r\n",
							"       and wsr_web_site_sk = web_site_sk\r\n",
							" group by web_site_id)\r\n",
							"  select  channel\r\n",
							"        , id\r\n",
							"        , sum(sales) as sales\r\n",
							"        , sum(returns) as returns\r\n",
							"        , sum(profit) as profit\r\n",
							" from \r\n",
							" (select 'store channel' as channel\r\n",
							"        , concat('store', s_store_id) as id\r\n",
							"        , sales\r\n",
							"        , returns\r\n",
							"        , (profit - profit_loss) as profit\r\n",
							" from   ssr\r\n",
							" union all\r\n",
							" select 'catalog channel' as channel\r\n",
							"        , concat('catalog_page', cp_catalog_page_id) as id\r\n",
							"        , sales\r\n",
							"        , returns\r\n",
							"        , (profit - profit_loss) as profit\r\n",
							" from  csr\r\n",
							" union all\r\n",
							" select 'web channel' as channel\r\n",
							"        , concat('web_site', web_site_id) as id\r\n",
							"        , sales\r\n",
							"        , returns\r\n",
							"        , (profit - profit_loss) as profit\r\n",
							" from   wsr\r\n",
							" ) x\r\n",
							" group by rollup (channel, id)\r\n",
							" order by channel\r\n",
							"         ,id\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query6\r\n",
							"  select  a.ca_state state, count(*) cnt\r\n",
							" from customer_address a\r\n",
							"     ,customer c\r\n",
							"     ,store_sales s\r\n",
							"     ,date_dim d\r\n",
							"     ,item i\r\n",
							" where       a.ca_address_sk = c.c_current_addr_sk\r\n",
							" \tand c.c_customer_sk = s.ss_customer_sk\r\n",
							" \tand s.ss_sold_date_sk = d.d_date_sk\r\n",
							" \tand s.ss_item_sk = i.i_item_sk\r\n",
							" \tand d.d_month_seq = \r\n",
							" \t     (select distinct (d_month_seq)\r\n",
							" \t      from date_dim\r\n",
							"               where d_year = 2001\r\n",
							" \t        and d_moy = 1 )\r\n",
							" \tand i.i_current_price > 1.2 * \r\n",
							"             (select avg(j.i_current_price) \r\n",
							" \t     from item j \r\n",
							" \t     where j.i_category = i.i_category)\r\n",
							" group by a.ca_state\r\n",
							" having count(*) >= 10\r\n",
							" order by cnt \r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query7\r\n",
							"  select  i_item_id, \r\n",
							"        avg(ss_quantity) agg1,\r\n",
							"        avg(ss_list_price) agg2,\r\n",
							"        avg(ss_coupon_amt) agg3,\r\n",
							"        avg(ss_sales_price) agg4 \r\n",
							" from store_sales, customer_demographics, date_dim, item, promotion\r\n",
							" where ss_sold_date_sk = d_date_sk and\r\n",
							"       ss_item_sk = i_item_sk and\r\n",
							"       ss_cdemo_sk = cd_demo_sk and\r\n",
							"       ss_promo_sk = p_promo_sk and\r\n",
							"       cd_gender = 'M' and \r\n",
							"       cd_marital_status = 'S' and\r\n",
							"       cd_education_status = 'College' and\r\n",
							"       (p_channel_email = 'N' or p_channel_event = 'N') and\r\n",
							"       d_year = 2000 \r\n",
							" group by i_item_id\r\n",
							" order by i_item_id\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query8\r\n",
							"  select  s_store_name\r\n",
							"      ,sum(ss_net_profit)\r\n",
							" from store_sales\r\n",
							"     ,date_dim\r\n",
							"     ,store,\r\n",
							"     (select ca_zip\r\n",
							"     from (\r\n",
							"      SELECT substr(ca_zip,1,5) ca_zip\r\n",
							"      FROM customer_address\r\n",
							"      WHERE substr(ca_zip,1,5) IN (\r\n",
							"                          '24128','76232','65084','87816','83926','77556',\r\n",
							"                          '20548','26231','43848','15126','91137',\r\n",
							"                          '61265','98294','25782','17920','18426',\r\n",
							"                          '98235','40081','84093','28577','55565',\r\n",
							"                          '17183','54601','67897','22752','86284',\r\n",
							"                          '18376','38607','45200','21756','29741',\r\n",
							"                          '96765','23932','89360','29839','25989',\r\n",
							"                          '28898','91068','72550','10390','18845',\r\n",
							"                          '47770','82636','41367','76638','86198',\r\n",
							"                          '81312','37126','39192','88424','72175',\r\n",
							"                          '81426','53672','10445','42666','66864',\r\n",
							"                          '66708','41248','48583','82276','18842',\r\n",
							"                          '78890','49448','14089','38122','34425',\r\n",
							"                          '79077','19849','43285','39861','66162',\r\n",
							"                          '77610','13695','99543','83444','83041',\r\n",
							"                          '12305','57665','68341','25003','57834',\r\n",
							"                          '62878','49130','81096','18840','27700',\r\n",
							"                          '23470','50412','21195','16021','76107',\r\n",
							"                          '71954','68309','18119','98359','64544',\r\n",
							"                          '10336','86379','27068','39736','98569',\r\n",
							"                          '28915','24206','56529','57647','54917',\r\n",
							"                          '42961','91110','63981','14922','36420',\r\n",
							"                          '23006','67467','32754','30903','20260',\r\n",
							"                          '31671','51798','72325','85816','68621',\r\n",
							"                          '13955','36446','41766','68806','16725',\r\n",
							"                          '15146','22744','35850','88086','51649',\r\n",
							"                          '18270','52867','39972','96976','63792',\r\n",
							"                          '11376','94898','13595','10516','90225',\r\n",
							"                          '58943','39371','94945','28587','96576',\r\n",
							"                          '57855','28488','26105','83933','25858',\r\n",
							"                          '34322','44438','73171','30122','34102',\r\n",
							"                          '22685','71256','78451','54364','13354',\r\n",
							"                          '45375','40558','56458','28286','45266',\r\n",
							"                          '47305','69399','83921','26233','11101',\r\n",
							"                          '15371','69913','35942','15882','25631',\r\n",
							"                          '24610','44165','99076','33786','70738',\r\n",
							"                          '26653','14328','72305','62496','22152',\r\n",
							"                          '10144','64147','48425','14663','21076',\r\n",
							"                          '18799','30450','63089','81019','68893',\r\n",
							"                          '24996','51200','51211','45692','92712',\r\n",
							"                          '70466','79994','22437','25280','38935',\r\n",
							"                          '71791','73134','56571','14060','19505',\r\n",
							"                          '72425','56575','74351','68786','51650',\r\n",
							"                          '20004','18383','76614','11634','18906',\r\n",
							"                          '15765','41368','73241','76698','78567',\r\n",
							"                          '97189','28545','76231','75691','22246',\r\n",
							"                          '51061','90578','56691','68014','51103',\r\n",
							"                          '94167','57047','14867','73520','15734',\r\n",
							"                          '63435','25733','35474','24676','94627',\r\n",
							"                          '53535','17879','15559','53268','59166',\r\n",
							"                          '11928','59402','33282','45721','43933',\r\n",
							"                          '68101','33515','36634','71286','19736',\r\n",
							"                          '58058','55253','67473','41918','19515',\r\n",
							"                          '36495','19430','22351','77191','91393',\r\n",
							"                          '49156','50298','87501','18652','53179',\r\n",
							"                          '18767','63193','23968','65164','68880',\r\n",
							"                          '21286','72823','58470','67301','13394',\r\n",
							"                          '31016','70372','67030','40604','24317',\r\n",
							"                          '45748','39127','26065','77721','31029',\r\n",
							"                          '31880','60576','24671','45549','13376',\r\n",
							"                          '50016','33123','19769','22927','97789',\r\n",
							"                          '46081','72151','15723','46136','51949',\r\n",
							"                          '68100','96888','64528','14171','79777',\r\n",
							"                          '28709','11489','25103','32213','78668',\r\n",
							"                          '22245','15798','27156','37930','62971',\r\n",
							"                          '21337','51622','67853','10567','38415',\r\n",
							"                          '15455','58263','42029','60279','37125',\r\n",
							"                          '56240','88190','50308','26859','64457',\r\n",
							"                          '89091','82136','62377','36233','63837',\r\n",
							"                          '58078','17043','30010','60099','28810',\r\n",
							"                          '98025','29178','87343','73273','30469',\r\n",
							"                          '64034','39516','86057','21309','90257',\r\n",
							"                          '67875','40162','11356','73650','61810',\r\n",
							"                          '72013','30431','22461','19512','13375',\r\n",
							"                          '55307','30625','83849','68908','26689',\r\n",
							"                          '96451','38193','46820','88885','84935',\r\n",
							"                          '69035','83144','47537','56616','94983',\r\n",
							"                          '48033','69952','25486','61547','27385',\r\n",
							"                          '61860','58048','56910','16807','17871',\r\n",
							"                          '35258','31387','35458','35576')\r\n",
							"     intersect\r\n",
							"      select ca_zip\r\n",
							"      from (SELECT substr(ca_zip,1,5) ca_zip,count(*) cnt\r\n",
							"            FROM customer_address, customer\r\n",
							"            WHERE ca_address_sk = c_current_addr_sk and\r\n",
							"                  c_preferred_cust_flag='Y'\r\n",
							"            group by ca_zip\r\n",
							"            having count(*) > 10)A1)A2) V1\r\n",
							" where ss_store_sk = s_store_sk\r\n",
							"  and ss_sold_date_sk = d_date_sk\r\n",
							"  and d_qoy = 2 and d_year = 1998\r\n",
							"  and (substr(s_zip,1,2) = substr(V1.ca_zip,1,2))\r\n",
							" group by s_store_name\r\n",
							" order by s_store_name\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query9\r\n",
							"select case when (select count(*) \r\n",
							"                  from store_sales \r\n",
							"                  where ss_quantity between 1 and 20) > 74129\r\n",
							"            then (select avg(ss_ext_discount_amt) \r\n",
							"                  from store_sales \r\n",
							"                  where ss_quantity between 1 and 20) \r\n",
							"            else (select avg(ss_net_paid)\r\n",
							"                  from store_sales\r\n",
							"                  where ss_quantity between 1 and 20) end bucket1 ,\r\n",
							"       case when (select count(*)\r\n",
							"                  from store_sales\r\n",
							"                  where ss_quantity between 21 and 40) > 122840\r\n",
							"            then (select avg(ss_ext_discount_amt)\r\n",
							"                  from store_sales\r\n",
							"                  where ss_quantity between 21 and 40) \r\n",
							"            else (select avg(ss_net_paid)\r\n",
							"                  from store_sales\r\n",
							"                  where ss_quantity between 21 and 40) end bucket2,\r\n",
							"       case when (select count(*)\r\n",
							"                  from store_sales\r\n",
							"                  where ss_quantity between 41 and 60) > 56580\r\n",
							"            then (select avg(ss_ext_discount_amt)\r\n",
							"                  from store_sales\r\n",
							"                  where ss_quantity between 41 and 60)\r\n",
							"            else (select avg(ss_net_paid)\r\n",
							"                  from store_sales\r\n",
							"                  where ss_quantity between 41 and 60) end bucket3,\r\n",
							"       case when (select count(*)\r\n",
							"                  from store_sales\r\n",
							"                  where ss_quantity between 61 and 80) > 10097\r\n",
							"            then (select avg(ss_ext_discount_amt)\r\n",
							"                  from store_sales\r\n",
							"                  where ss_quantity between 61 and 80)\r\n",
							"            else (select avg(ss_net_paid)\r\n",
							"                  from store_sales\r\n",
							"                  where ss_quantity between 61 and 80) end bucket4,\r\n",
							"       case when (select count(*)\r\n",
							"                  from store_sales\r\n",
							"                  where ss_quantity between 81 and 100) > 165306\r\n",
							"            then (select avg(ss_ext_discount_amt)\r\n",
							"                  from store_sales\r\n",
							"                  where ss_quantity between 81 and 100)\r\n",
							"            else (select avg(ss_net_paid)\r\n",
							"                  from store_sales\r\n",
							"                  where ss_quantity between 81 and 100) end bucket5\r\n",
							"from reason\r\n",
							"where r_reason_sk = 1;"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query10\r\n",
							"  select  \r\n",
							"  cd_gender,\r\n",
							"  cd_marital_status,\r\n",
							"  cd_education_status,\r\n",
							"  count(*) cnt1,\r\n",
							"  cd_purchase_estimate,\r\n",
							"  count(*) cnt2,\r\n",
							"  cd_credit_rating,\r\n",
							"  count(*) cnt3,\r\n",
							"  cd_dep_count,\r\n",
							"  count(*) cnt4,\r\n",
							"  cd_dep_employed_count,\r\n",
							"  count(*) cnt5,\r\n",
							"  cd_dep_college_count,\r\n",
							"  count(*) cnt6\r\n",
							" from\r\n",
							"  customer c,customer_address ca,customer_demographics\r\n",
							" where\r\n",
							"  c.c_current_addr_sk = ca.ca_address_sk and\r\n",
							"  ca_county in ('Rush County','Toole County','Jefferson County','Dona Ana County','La Porte County') and\r\n",
							"  cd_demo_sk = c.c_current_cdemo_sk and \r\n",
							"  exists (select *\r\n",
							"          from store_sales,date_dim\r\n",
							"          where c.c_customer_sk = ss_customer_sk and\r\n",
							"                ss_sold_date_sk = d_date_sk and\r\n",
							"                d_year = 2002 and\r\n",
							"                d_moy between 1 and 1+3) and\r\n",
							"   (exists (select *\r\n",
							"            from web_sales,date_dim\r\n",
							"            where c.c_customer_sk = ws_bill_customer_sk and\r\n",
							"                  ws_sold_date_sk = d_date_sk and\r\n",
							"                  d_year = 2002 and\r\n",
							"                  d_moy between 1 ANd 1+3) or \r\n",
							"    exists (select * \r\n",
							"            from catalog_sales,date_dim\r\n",
							"            where c.c_customer_sk = cs_ship_customer_sk and\r\n",
							"                  cs_sold_date_sk = d_date_sk and\r\n",
							"                  d_year = 2002 and\r\n",
							"                  d_moy between 1 and 1+3))\r\n",
							" group by cd_gender,\r\n",
							"          cd_marital_status,\r\n",
							"          cd_education_status,\r\n",
							"          cd_purchase_estimate,\r\n",
							"          cd_credit_rating,\r\n",
							"          cd_dep_count,\r\n",
							"          cd_dep_employed_count,\r\n",
							"          cd_dep_college_count\r\n",
							" order by cd_gender,\r\n",
							"          cd_marital_status,\r\n",
							"          cd_education_status,\r\n",
							"          cd_purchase_estimate,\r\n",
							"          cd_credit_rating,\r\n",
							"          cd_dep_count,\r\n",
							"          cd_dep_employed_count,\r\n",
							"          cd_dep_college_count\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query11\r\n",
							" with year_total as (\r\n",
							" select c_customer_id customer_id\r\n",
							"       ,c_first_name customer_first_name\r\n",
							"       ,c_last_name customer_last_name\r\n",
							"       ,c_preferred_cust_flag customer_preferred_cust_flag\r\n",
							"       ,c_birth_country customer_birth_country\r\n",
							"       ,c_login customer_login\r\n",
							"       ,c_email_address customer_email_address\r\n",
							"       ,d_year dyear\r\n",
							"       ,sum(ss_ext_list_price-ss_ext_discount_amt) year_total\r\n",
							"       ,'s' sale_type\r\n",
							" from customer\r\n",
							"     ,store_sales\r\n",
							"     ,date_dim\r\n",
							" where c_customer_sk = ss_customer_sk\r\n",
							"   and ss_sold_date_sk = d_date_sk\r\n",
							" group by c_customer_id\r\n",
							"         ,c_first_name\r\n",
							"         ,c_last_name\r\n",
							"         ,c_preferred_cust_flag \r\n",
							"         ,c_birth_country\r\n",
							"         ,c_login\r\n",
							"         ,c_email_address\r\n",
							"         ,d_year \r\n",
							" union all\r\n",
							" select c_customer_id customer_id\r\n",
							"       ,c_first_name customer_first_name\r\n",
							"       ,c_last_name customer_last_name\r\n",
							"       ,c_preferred_cust_flag customer_preferred_cust_flag\r\n",
							"       ,c_birth_country customer_birth_country\r\n",
							"       ,c_login customer_login\r\n",
							"       ,c_email_address customer_email_address\r\n",
							"       ,d_year dyear\r\n",
							"       ,sum(ws_ext_list_price-ws_ext_discount_amt) year_total\r\n",
							"       ,'w' sale_type\r\n",
							" from customer\r\n",
							"     ,web_sales\r\n",
							"     ,date_dim\r\n",
							" where c_customer_sk = ws_bill_customer_sk\r\n",
							"   and ws_sold_date_sk = d_date_sk\r\n",
							" group by c_customer_id\r\n",
							"         ,c_first_name\r\n",
							"         ,c_last_name\r\n",
							"         ,c_preferred_cust_flag \r\n",
							"         ,c_birth_country\r\n",
							"         ,c_login\r\n",
							"         ,c_email_address\r\n",
							"         ,d_year\r\n",
							"         )\r\n",
							"  select  \r\n",
							"                  t_s_secyear.customer_id\r\n",
							"                 ,t_s_secyear.customer_first_name\r\n",
							"                 ,t_s_secyear.customer_last_name\r\n",
							"                 ,t_s_secyear.customer_preferred_cust_flag\r\n",
							" from year_total t_s_firstyear\r\n",
							"     ,year_total t_s_secyear\r\n",
							"     ,year_total t_w_firstyear\r\n",
							"     ,year_total t_w_secyear\r\n",
							" where t_s_secyear.customer_id = t_s_firstyear.customer_id\r\n",
							"         and t_s_firstyear.customer_id = t_w_secyear.customer_id\r\n",
							"         and t_s_firstyear.customer_id = t_w_firstyear.customer_id\r\n",
							"         and t_s_firstyear.sale_type = 's'\r\n",
							"         and t_w_firstyear.sale_type = 'w'\r\n",
							"         and t_s_secyear.sale_type = 's'\r\n",
							"         and t_w_secyear.sale_type = 'w'\r\n",
							"         and t_s_firstyear.dyear = 2001\r\n",
							"         and t_s_secyear.dyear = 2001+1\r\n",
							"         and t_w_firstyear.dyear = 2001\r\n",
							"         and t_w_secyear.dyear = 2001+1\r\n",
							"         and t_s_firstyear.year_total > 0\r\n",
							"         and t_w_firstyear.year_total > 0\r\n",
							"         and case when t_w_firstyear.year_total > 0 then t_w_secyear.year_total / t_w_firstyear.year_total else 0.0 end\r\n",
							"             > case when t_s_firstyear.year_total > 0 then t_s_secyear.year_total / t_s_firstyear.year_total else 0.0 end\r\n",
							" order by t_s_secyear.customer_id\r\n",
							"         ,t_s_secyear.customer_first_name\r\n",
							"         ,t_s_secyear.customer_last_name\r\n",
							"         ,t_s_secyear.customer_preferred_cust_flag\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query12\r\n",
							" select  i_item_id\r\n",
							"      ,i_item_desc \r\n",
							"      ,i_category \r\n",
							"      ,i_class \r\n",
							"      ,i_current_price\r\n",
							"      ,sum(ws_ext_sales_price) as itemrevenue \r\n",
							"      ,sum(ws_ext_sales_price)*100/sum(sum(ws_ext_sales_price)) over\r\n",
							"          (partition by i_class) as revenueratio\r\n",
							"from\t\r\n",
							"\tweb_sales\r\n",
							"    \t,item \r\n",
							"    \t,date_dim\r\n",
							"where \r\n",
							"\tws_item_sk = i_item_sk \r\n",
							"  \tand i_category in ('Sports', 'Books', 'Home')\r\n",
							"  \tand ws_sold_date_sk = d_date_sk\r\n",
							"\tand d_date between cast('1999-02-22' as date) \r\n",
							"                                and date_add(cast('1999-02-22' as date), 30 )\r\n",
							"group by \r\n",
							"\ti_item_id\r\n",
							"        ,i_item_desc \r\n",
							"        ,i_category\r\n",
							"        ,i_class\r\n",
							"        ,i_current_price\r\n",
							"order by \r\n",
							"\ti_category\r\n",
							"        ,i_class\r\n",
							"        ,i_item_id\r\n",
							"        ,i_item_desc\r\n",
							"        ,revenueratio\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query13\r\n",
							" select avg(ss_quantity)\r\n",
							"       ,avg(ss_ext_sales_price)\r\n",
							"       ,avg(ss_ext_wholesale_cost)\r\n",
							"       ,sum(ss_ext_wholesale_cost)\r\n",
							" from store_sales\r\n",
							"     ,store\r\n",
							"     ,customer_demographics\r\n",
							"     ,household_demographics\r\n",
							"     ,customer_address\r\n",
							"     ,date_dim\r\n",
							" where s_store_sk = ss_store_sk\r\n",
							" and  ss_sold_date_sk = d_date_sk and d_year = 2001\r\n",
							" and((ss_hdemo_sk=hd_demo_sk\r\n",
							"  and cd_demo_sk = ss_cdemo_sk\r\n",
							"  and cd_marital_status = 'M'\r\n",
							"  and cd_education_status = 'Advanced Degree'\r\n",
							"  and ss_sales_price between 100.00 and 150.00\r\n",
							"  and hd_dep_count = 3   \r\n",
							"     )or\r\n",
							"     (ss_hdemo_sk=hd_demo_sk\r\n",
							"  and cd_demo_sk = ss_cdemo_sk\r\n",
							"  and cd_marital_status = 'S'\r\n",
							"  and cd_education_status = 'College'\r\n",
							"  and ss_sales_price between 50.00 and 100.00   \r\n",
							"  and hd_dep_count = 1\r\n",
							"     ) or \r\n",
							"     (ss_hdemo_sk=hd_demo_sk\r\n",
							"  and cd_demo_sk = ss_cdemo_sk\r\n",
							"  and cd_marital_status = 'W'\r\n",
							"  and cd_education_status = '2 yr Degree'\r\n",
							"  and ss_sales_price between 150.00 and 200.00 \r\n",
							"  and hd_dep_count = 1  \r\n",
							"     ))\r\n",
							" and((ss_addr_sk = ca_address_sk\r\n",
							"  and ca_country = 'United States'\r\n",
							"  and ca_state in ('TX', 'OH', 'TX')\r\n",
							"  and ss_net_profit between 100 and 200  \r\n",
							"     ) or\r\n",
							"     (ss_addr_sk = ca_address_sk\r\n",
							"  and ca_country = 'United States'\r\n",
							"  and ca_state in ('OR', 'NM', 'KY')\r\n",
							"  and ss_net_profit between 150 and 300  \r\n",
							"     ) or\r\n",
							"     (ss_addr_sk = ca_address_sk\r\n",
							"  and ca_country = 'United States'\r\n",
							"  and ca_state in ('VA', 'TX', 'MS')\r\n",
							"  and ss_net_profit between 50 and 250  \r\n",
							"     ));"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query14\r\n",
							"with  cross_items as\r\n",
							" (select i_item_sk ss_item_sk\r\n",
							" from item,\r\n",
							" (select iss.i_brand_id brand_id\r\n",
							"     ,iss.i_class_id class_id\r\n",
							"     ,iss.i_category_id category_id\r\n",
							" from store_sales\r\n",
							"     ,item iss\r\n",
							"     ,date_dim d1\r\n",
							" where ss_item_sk = iss.i_item_sk\r\n",
							"   and ss_sold_date_sk = d1.d_date_sk\r\n",
							"   and d1.d_year between 1999 AND 1999 + 2\r\n",
							" intersect \r\n",
							" select ics.i_brand_id\r\n",
							"     ,ics.i_class_id\r\n",
							"     ,ics.i_category_id\r\n",
							" from catalog_sales\r\n",
							"     ,item ics\r\n",
							"     ,date_dim d2\r\n",
							" where cs_item_sk = ics.i_item_sk\r\n",
							"   and cs_sold_date_sk = d2.d_date_sk\r\n",
							"   and d2.d_year between 1999 AND 1999 + 2\r\n",
							" intersect\r\n",
							" select iws.i_brand_id\r\n",
							"     ,iws.i_class_id\r\n",
							"     ,iws.i_category_id\r\n",
							" from web_sales\r\n",
							"     ,item iws\r\n",
							"     ,date_dim d3\r\n",
							" where ws_item_sk = iws.i_item_sk\r\n",
							"   and ws_sold_date_sk = d3.d_date_sk\r\n",
							"   and d3.d_year between 1999 AND 1999 + 2)\r\n",
							" where i_brand_id = brand_id\r\n",
							"      and i_class_id = class_id\r\n",
							"      and i_category_id = category_id\r\n",
							"),\r\n",
							" avg_sales as\r\n",
							" (select avg(quantity*list_price) average_sales\r\n",
							"  from (select ss_quantity quantity\r\n",
							"             ,ss_list_price list_price\r\n",
							"       from store_sales\r\n",
							"           ,date_dim\r\n",
							"       where ss_sold_date_sk = d_date_sk\r\n",
							"         and d_year between 1999 and 1999 + 2\r\n",
							"       union all \r\n",
							"       select cs_quantity quantity \r\n",
							"             ,cs_list_price list_price\r\n",
							"       from catalog_sales\r\n",
							"           ,date_dim\r\n",
							"       where cs_sold_date_sk = d_date_sk\r\n",
							"         and d_year between 1999 and 1999 + 2 \r\n",
							"       union all\r\n",
							"       select ws_quantity quantity\r\n",
							"             ,ws_list_price list_price\r\n",
							"       from web_sales\r\n",
							"           ,date_dim\r\n",
							"       where ws_sold_date_sk = d_date_sk\r\n",
							"         and d_year between 1999 and 1999 + 2) x)\r\n",
							"  select  channel, i_brand_id,i_class_id,i_category_id,sum(sales), sum(number_sales)\r\n",
							" from(\r\n",
							"       select 'store' channel, i_brand_id,i_class_id\r\n",
							"             ,i_category_id,sum(ss_quantity*ss_list_price) sales\r\n",
							"             , count(*) number_sales\r\n",
							"       from store_sales\r\n",
							"           ,item\r\n",
							"           ,date_dim\r\n",
							"       where ss_item_sk in (select ss_item_sk from cross_items)\r\n",
							"         and ss_item_sk = i_item_sk\r\n",
							"         and ss_sold_date_sk = d_date_sk\r\n",
							"         and d_year = 1999+2 \r\n",
							"         and d_moy = 11\r\n",
							"       group by i_brand_id,i_class_id,i_category_id\r\n",
							"       having sum(ss_quantity*ss_list_price) > (select average_sales from avg_sales)\r\n",
							"       union all\r\n",
							"       select 'catalog' channel, i_brand_id,i_class_id,i_category_id, sum(cs_quantity*cs_list_price) sales, count(*) number_sales\r\n",
							"       from catalog_sales\r\n",
							"           ,item\r\n",
							"           ,date_dim\r\n",
							"       where cs_item_sk in (select ss_item_sk from cross_items)\r\n",
							"         and cs_item_sk = i_item_sk\r\n",
							"         and cs_sold_date_sk = d_date_sk\r\n",
							"         and d_year = 1999+2 \r\n",
							"         and d_moy = 11\r\n",
							"       group by i_brand_id,i_class_id,i_category_id\r\n",
							"       having sum(cs_quantity*cs_list_price) > (select average_sales from avg_sales)\r\n",
							"       union all\r\n",
							"       select 'web' channel, i_brand_id,i_class_id,i_category_id, sum(ws_quantity*ws_list_price) sales , count(*) number_sales\r\n",
							"       from web_sales\r\n",
							"           ,item\r\n",
							"           ,date_dim\r\n",
							"       where ws_item_sk in (select ss_item_sk from cross_items)\r\n",
							"         and ws_item_sk = i_item_sk\r\n",
							"         and ws_sold_date_sk = d_date_sk\r\n",
							"         and d_year = 1999+2\r\n",
							"         and d_moy = 11\r\n",
							"       group by i_brand_id,i_class_id,i_category_id\r\n",
							"       having sum(ws_quantity*ws_list_price) > (select average_sales from avg_sales)\r\n",
							" ) y\r\n",
							" group by rollup (channel, i_brand_id,i_class_id,i_category_id)\r\n",
							" order by channel,i_brand_id,i_class_id,i_category_id\r\n",
							"  limit 100;\r\n",
							" with  cross_items as\r\n",
							" (select i_item_sk ss_item_sk\r\n",
							" from item,\r\n",
							" (select iss.i_brand_id brand_id\r\n",
							"     ,iss.i_class_id class_id\r\n",
							"     ,iss.i_category_id category_id\r\n",
							" from store_sales\r\n",
							"     ,item iss\r\n",
							"     ,date_dim d1\r\n",
							" where ss_item_sk = iss.i_item_sk\r\n",
							"   and ss_sold_date_sk = d1.d_date_sk\r\n",
							"   and d1.d_year between 1999 AND 1999 + 2\r\n",
							" intersect\r\n",
							" select ics.i_brand_id\r\n",
							"     ,ics.i_class_id\r\n",
							"     ,ics.i_category_id\r\n",
							" from catalog_sales\r\n",
							"     ,item ics\r\n",
							"     ,date_dim d2\r\n",
							" where cs_item_sk = ics.i_item_sk\r\n",
							"   and cs_sold_date_sk = d2.d_date_sk\r\n",
							"   and d2.d_year between 1999 AND 1999 + 2\r\n",
							" intersect\r\n",
							" select iws.i_brand_id\r\n",
							"     ,iws.i_class_id\r\n",
							"     ,iws.i_category_id\r\n",
							" from web_sales\r\n",
							"     ,item iws\r\n",
							"     ,date_dim d3\r\n",
							" where ws_item_sk = iws.i_item_sk\r\n",
							"   and ws_sold_date_sk = d3.d_date_sk\r\n",
							"   and d3.d_year between 1999 AND 1999 + 2) x\r\n",
							" where i_brand_id = brand_id\r\n",
							"      and i_class_id = class_id\r\n",
							"      and i_category_id = category_id\r\n",
							"),\r\n",
							" avg_sales as\r\n",
							"(select avg(quantity*list_price) average_sales\r\n",
							"  from (select ss_quantity quantity\r\n",
							"             ,ss_list_price list_price\r\n",
							"       from store_sales\r\n",
							"           ,date_dim\r\n",
							"       where ss_sold_date_sk = d_date_sk\r\n",
							"         and d_year between 1999 and 1999 + 2\r\n",
							"       union all\r\n",
							"       select cs_quantity quantity\r\n",
							"             ,cs_list_price list_price\r\n",
							"       from catalog_sales\r\n",
							"           ,date_dim\r\n",
							"       where cs_sold_date_sk = d_date_sk\r\n",
							"         and d_year between 1999 and 1999 + 2\r\n",
							"       union all\r\n",
							"       select ws_quantity quantity\r\n",
							"             ,ws_list_price list_price\r\n",
							"       from web_sales\r\n",
							"           ,date_dim\r\n",
							"       where ws_sold_date_sk = d_date_sk\r\n",
							"         and d_year between 1999 and 1999 + 2) x)\r\n",
							"  select  * from\r\n",
							" (select 'store' channel, i_brand_id,i_class_id,i_category_id\r\n",
							"        ,sum(ss_quantity*ss_list_price) sales, count(*) number_sales\r\n",
							" from store_sales \r\n",
							"     ,item\r\n",
							"     ,date_dim\r\n",
							" where ss_item_sk in (select ss_item_sk from cross_items)\r\n",
							"   and ss_item_sk = i_item_sk\r\n",
							"   and ss_sold_date_sk = d_date_sk\r\n",
							"   and d_week_seq = (select d_week_seq\r\n",
							"                     from date_dim\r\n",
							"                     where d_year = 1999 + 1\r\n",
							"                       and d_moy = 12\r\n",
							"                       and d_dom = 11)\r\n",
							" group by i_brand_id,i_class_id,i_category_id\r\n",
							" having sum(ss_quantity*ss_list_price) > (select average_sales from avg_sales)) this_year,\r\n",
							" (select 'store' channel_2, i_brand_id as i_brand_id_2, i_class_id as i_class_id_2\r\n",
							"        ,i_category_id as i_category_id_2 , sum(ss_quantity*ss_list_price) sales_2, count(*) number_sales_2\r\n",
							" from store_sales\r\n",
							"     ,item\r\n",
							"     ,date_dim\r\n",
							" where ss_item_sk in (select ss_item_sk from cross_items)\r\n",
							"   and ss_item_sk = i_item_sk\r\n",
							"   and ss_sold_date_sk = d_date_sk\r\n",
							"   and d_week_seq = (select d_week_seq\r\n",
							"                     from date_dim\r\n",
							"                     where d_year = 1999\r\n",
							"                       and d_moy = 12\r\n",
							"                       and d_dom = 11)\r\n",
							" group by i_brand_id,i_class_id,i_category_id\r\n",
							" having sum(ss_quantity*ss_list_price) > (select average_sales from avg_sales)) last_year\r\n",
							" where this_year.i_brand_id= last_year.i_brand_id_2\r\n",
							"   and this_year.i_class_id = last_year.i_class_id_2\r\n",
							"   and this_year.i_category_id = last_year.i_category_id_2\r\n",
							" order by this_year.channel, this_year.i_brand_id, this_year.i_class_id, this_year.i_category_id\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query15\r\n",
							"  select  ca_zip\r\n",
							"       ,sum(cs_sales_price)\r\n",
							" from catalog_sales\r\n",
							"     ,customer\r\n",
							"     ,customer_address\r\n",
							"     ,date_dim\r\n",
							" where cs_bill_customer_sk = c_customer_sk\r\n",
							" \tand c_current_addr_sk = ca_address_sk \r\n",
							" \tand ( substr(ca_zip,1,5) in ('85669', '86197','88274','83405','86475',\r\n",
							"                                   '85392', '85460', '80348', '81792')\r\n",
							" \t      or ca_state in ('CA','WA','GA')\r\n",
							" \t      or cs_sales_price > 500)\r\n",
							" \tand cs_sold_date_sk = d_date_sk\r\n",
							" \tand d_qoy = 2 and d_year = 2001\r\n",
							" group by ca_zip\r\n",
							" order by ca_zip\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query16\r\n",
							" select  \r\n",
							"   count(distinct cs_order_number) as order_count\r\n",
							"  ,sum(cs_ext_ship_cost) as total_shipping_cost\r\n",
							"  ,sum(cs_net_profit) as total_net_profit\r\n",
							"from\r\n",
							"   catalog_sales cs1\r\n",
							"  ,date_dim\r\n",
							"  ,customer_address\r\n",
							"  ,call_center\r\n",
							"where\r\n",
							"    d_date between cast('2002-2-01' as date) and \r\n",
							"           date_add(cast('2002-2-01' as date), 60 )\r\n",
							"and cs1.cs_ship_date_sk = d_date_sk\r\n",
							"and cs1.cs_ship_addr_sk = ca_address_sk\r\n",
							"and ca_state = 'GA'\r\n",
							"and cs1.cs_call_center_sk = cc_call_center_sk\r\n",
							"and cc_county in ('Williamson County','Williamson County','Williamson County','Williamson County',\r\n",
							"                  'Williamson County'\r\n",
							")\r\n",
							"and exists (select *\r\n",
							"            from catalog_sales cs2\r\n",
							"            where cs1.cs_order_number = cs2.cs_order_number\r\n",
							"              and cs1.cs_warehouse_sk <> cs2.cs_warehouse_sk)\r\n",
							"and not exists(select *\r\n",
							"               from catalog_returns cr1\r\n",
							"               where cs1.cs_order_number = cr1.cr_order_number)\r\n",
							"order by count(distinct cs_order_number)\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query17\r\n",
							"  select  i_item_id\r\n",
							"       ,i_item_desc\r\n",
							"       ,s_state\r\n",
							"       ,count(ss_quantity) as store_sales_quantitycount\r\n",
							"       ,avg(ss_quantity) as store_sales_quantityave\r\n",
							"       ,stddev_samp(ss_quantity) as store_sales_quantitystdev\r\n",
							"       ,stddev_samp(ss_quantity)/avg(ss_quantity) as store_sales_quantitycov\r\n",
							"       ,count(sr_return_quantity) as store_returns_quantitycount\r\n",
							"       ,avg(sr_return_quantity) as store_returns_quantityave\r\n",
							"       ,stddev_samp(sr_return_quantity) as store_returns_quantitystdev\r\n",
							"       ,stddev_samp(sr_return_quantity)/avg(sr_return_quantity) as store_returns_quantitycov\r\n",
							"       ,count(cs_quantity) as catalog_sales_quantitycount ,avg(cs_quantity) as catalog_sales_quantityave\r\n",
							"       ,stddev_samp(cs_quantity) as catalog_sales_quantitystdev\r\n",
							"       ,stddev_samp(cs_quantity)/avg(cs_quantity) as catalog_sales_quantitycov\r\n",
							" from store_sales\r\n",
							"     ,store_returns\r\n",
							"     ,catalog_sales\r\n",
							"     ,date_dim d1\r\n",
							"     ,date_dim d2\r\n",
							"     ,date_dim d3\r\n",
							"     ,store\r\n",
							"     ,item\r\n",
							" where d1.d_quarter_name = '2001Q1'\r\n",
							"   and d1.d_date_sk = ss_sold_date_sk\r\n",
							"   and i_item_sk = ss_item_sk\r\n",
							"   and s_store_sk = ss_store_sk\r\n",
							"   and ss_customer_sk = sr_customer_sk\r\n",
							"   and ss_item_sk = sr_item_sk\r\n",
							"   and ss_ticket_number = sr_ticket_number\r\n",
							"   and sr_returned_date_sk = d2.d_date_sk\r\n",
							"   and d2.d_quarter_name in ('2001Q1','2001Q2','2001Q3')\r\n",
							"   and sr_customer_sk = cs_bill_customer_sk\r\n",
							"   and sr_item_sk = cs_item_sk\r\n",
							"   and cs_sold_date_sk = d3.d_date_sk\r\n",
							"   and d3.d_quarter_name in ('2001Q1','2001Q2','2001Q3')\r\n",
							" group by i_item_id\r\n",
							"         ,i_item_desc\r\n",
							"         ,s_state\r\n",
							" order by i_item_id\r\n",
							"         ,i_item_desc\r\n",
							"         ,s_state\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query18\r\n",
							"  select  i_item_id,\r\n",
							"        ca_country,\r\n",
							"        ca_state, \r\n",
							"        ca_county,\r\n",
							"        avg( cast(cs_quantity as decimal(12,2))) agg1,\r\n",
							"        avg( cast(cs_list_price as decimal(12,2))) agg2,\r\n",
							"        avg( cast(cs_coupon_amt as decimal(12,2))) agg3,\r\n",
							"        avg( cast(cs_sales_price as decimal(12,2))) agg4,\r\n",
							"        avg( cast(cs_net_profit as decimal(12,2))) agg5,\r\n",
							"        avg( cast(c_birth_year as decimal(12,2))) agg6,\r\n",
							"        avg( cast(cd1.cd_dep_count as decimal(12,2))) agg7\r\n",
							" from catalog_sales, customer_demographics cd1, \r\n",
							"      customer_demographics cd2, customer, customer_address, date_dim, item\r\n",
							" where cs_sold_date_sk = d_date_sk and\r\n",
							"       cs_item_sk = i_item_sk and\r\n",
							"       cs_bill_cdemo_sk = cd1.cd_demo_sk and\r\n",
							"       cs_bill_customer_sk = c_customer_sk and\r\n",
							"       cd1.cd_gender = 'F' and \r\n",
							"       cd1.cd_education_status = 'Unknown' and\r\n",
							"       c_current_cdemo_sk = cd2.cd_demo_sk and\r\n",
							"       c_current_addr_sk = ca_address_sk and\r\n",
							"       c_birth_month in (1,6,8,9,12,2) and\r\n",
							"       d_year = 1998 and\r\n",
							"       ca_state in ('MS','IN','ND'\r\n",
							"                   ,'OK','NM','VA','MS')\r\n",
							" group by rollup (i_item_id, ca_country, ca_state, ca_county)\r\n",
							" order by ca_country,\r\n",
							"        ca_state, \r\n",
							"        ca_county,\r\n",
							"\ti_item_id\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query19\r\n",
							"  select  i_brand_id brand_id, i_brand brand, i_manufact_id, i_manufact,\r\n",
							" \tsum(ss_ext_sales_price) ext_price\r\n",
							" from date_dim, store_sales, item,customer,customer_address,store\r\n",
							" where d_date_sk = ss_sold_date_sk\r\n",
							"   and ss_item_sk = i_item_sk\r\n",
							"   and i_manager_id=8\r\n",
							"   and d_moy=11\r\n",
							"   and d_year=1998\r\n",
							"   and ss_customer_sk = c_customer_sk \r\n",
							"   and c_current_addr_sk = ca_address_sk\r\n",
							"   and substr(ca_zip,1,5) <> substr(s_zip,1,5) \r\n",
							"   and ss_store_sk = s_store_sk \r\n",
							" group by i_brand\r\n",
							"      ,i_brand_id\r\n",
							"      ,i_manufact_id\r\n",
							"      ,i_manufact\r\n",
							" order by ext_price desc\r\n",
							"         ,i_brand\r\n",
							"         ,i_brand_id\r\n",
							"         ,i_manufact_id\r\n",
							"         ,i_manufact\r\n",
							" limit 100 ;"
						],
						"outputs": [],
						"execution_count": 20
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query20\r\n",
							"  select  i_item_id\r\n",
							"       ,i_item_desc \r\n",
							"       ,i_category \r\n",
							"       ,i_class \r\n",
							"       ,i_current_price\r\n",
							"       ,sum(cs_ext_sales_price) as itemrevenue \r\n",
							"       ,sum(cs_ext_sales_price)*100/sum(sum(cs_ext_sales_price)) over\r\n",
							"           (partition by i_class) as revenueratio\r\n",
							" from\tcatalog_sales\r\n",
							"     ,item \r\n",
							"     ,date_dim\r\n",
							" where cs_item_sk = i_item_sk \r\n",
							"   and i_category in ('Sports', 'Books', 'Home')\r\n",
							"   and cs_sold_date_sk = d_date_sk\r\n",
							" and d_date between cast('1999-02-22' as date) \r\n",
							"                                and date_add(cast('1999-02-22' as date), 30)\r\n",
							" group by i_item_id\r\n",
							"         ,i_item_desc \r\n",
							"         ,i_category\r\n",
							"         ,i_class\r\n",
							"         ,i_current_price\r\n",
							" order by i_category\r\n",
							"         ,i_class\r\n",
							"         ,i_item_id\r\n",
							"         ,i_item_desc\r\n",
							"         ,revenueratio\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query21\r\n",
							"  select  *\r\n",
							" from(select w_warehouse_name\r\n",
							"            ,i_item_id\r\n",
							"            ,sum(case when (cast(d_date as date) < cast ('2000-03-11' as date))\r\n",
							"\t                then inv_quantity_on_hand \r\n",
							"                      else 0 end) as inv_before\r\n",
							"            ,sum(case when (cast(d_date as date) >= cast ('2000-03-11' as date))\r\n",
							"                      then inv_quantity_on_hand \r\n",
							"                      else 0 end) as inv_after\r\n",
							"   from inventory\r\n",
							"       ,warehouse\r\n",
							"       ,item\r\n",
							"       ,date_dim\r\n",
							"   where i_current_price between 0.99 and 1.49\r\n",
							"     and i_item_sk          = inv_item_sk\r\n",
							"     and inv_warehouse_sk   = w_warehouse_sk\r\n",
							"     and inv_date_sk    = d_date_sk\r\n",
							"     and d_date between date_sub(cast ('2000-03-11' as date), 30 )\r\n",
							"                    and date_add(cast ('2000-03-11' as date), 30 )\r\n",
							"   group by w_warehouse_name, i_item_id) x\r\n",
							" where (case when inv_before > 0 \r\n",
							"             then inv_after / inv_before \r\n",
							"             else null\r\n",
							"             end) between 2.0/3.0 and 3.0/2.0\r\n",
							" order by w_warehouse_name\r\n",
							"         ,i_item_id\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query22\r\n",
							" select  i_product_name\r\n",
							"             ,i_brand\r\n",
							"             ,i_class\r\n",
							"             ,i_category\r\n",
							"             ,avg(inv_quantity_on_hand) qoh\r\n",
							"       from inventory\r\n",
							"           ,date_dim\r\n",
							"           ,item\r\n",
							"       where inv_date_sk=d_date_sk\r\n",
							"              and inv_item_sk=i_item_sk\r\n",
							"              and d_month_seq between 1200 and 1200 + 11\r\n",
							"       group by rollup(i_product_name\r\n",
							"                       ,i_brand\r\n",
							"                       ,i_class\r\n",
							"                       ,i_category)\r\n",
							"order by qoh, i_product_name, i_brand, i_class, i_category\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query23\r\n",
							" with frequent_ss_items as \r\n",
							" (select substr(i_item_desc,1,30) itemdesc,i_item_sk item_sk,d_date solddate,count(*) cnt\r\n",
							"  from store_sales\r\n",
							"      ,date_dim \r\n",
							"      ,item\r\n",
							"  where ss_sold_date_sk = d_date_sk\r\n",
							"    and ss_item_sk = i_item_sk \r\n",
							"    and d_year in (2000,2000+1,2000+2,2000+3)\r\n",
							"  group by substr(i_item_desc,1,30),i_item_sk,d_date\r\n",
							"  having count(*) >4),\r\n",
							" max_store_sales as\r\n",
							" (select max(csales) tpcds_cmax \r\n",
							"  from (select c_customer_sk,sum(ss_quantity*ss_sales_price) csales\r\n",
							"        from store_sales\r\n",
							"            ,customer\r\n",
							"            ,date_dim \r\n",
							"        where ss_customer_sk = c_customer_sk\r\n",
							"         and ss_sold_date_sk = d_date_sk\r\n",
							"         and d_year in (2000,2000+1,2000+2,2000+3) \r\n",
							"        group by c_customer_sk)),\r\n",
							" best_ss_customer as\r\n",
							" (select c_customer_sk,sum(ss_quantity*ss_sales_price) ssales\r\n",
							"  from store_sales\r\n",
							"      ,customer\r\n",
							"  where ss_customer_sk = c_customer_sk\r\n",
							"  group by c_customer_sk\r\n",
							"  having sum(ss_quantity*ss_sales_price) > (50/100.0) * (select\r\n",
							"  *\r\n",
							"from\r\n",
							" max_store_sales))\r\n",
							"  select  sum(sales)\r\n",
							" from (select cs_quantity*cs_list_price sales\r\n",
							"       from catalog_sales\r\n",
							"           ,date_dim \r\n",
							"       where d_year = 2000 \r\n",
							"         and d_moy = 2 \r\n",
							"         and cs_sold_date_sk = d_date_sk \r\n",
							"         and cs_item_sk in (select item_sk from frequent_ss_items)\r\n",
							"         and cs_bill_customer_sk in (select c_customer_sk from best_ss_customer)\r\n",
							"      union all\r\n",
							"      select ws_quantity*ws_list_price sales\r\n",
							"       from web_sales \r\n",
							"           ,date_dim \r\n",
							"       where d_year = 2000 \r\n",
							"         and d_moy = 2 \r\n",
							"         and ws_sold_date_sk = d_date_sk \r\n",
							"         and ws_item_sk in (select item_sk from frequent_ss_items)\r\n",
							"         and ws_bill_customer_sk in (select c_customer_sk from best_ss_customer)) \r\n",
							"  limit 100; \r\n",
							" with frequent_ss_items as\r\n",
							" (select substr(i_item_desc,1,30) itemdesc,i_item_sk item_sk,d_date solddate,count(*) cnt\r\n",
							"  from store_sales\r\n",
							"      ,date_dim\r\n",
							"      ,item\r\n",
							"  where ss_sold_date_sk = d_date_sk\r\n",
							"    and ss_item_sk = i_item_sk\r\n",
							"    and d_year in (2000,2000 + 1,2000 + 2,2000 + 3)\r\n",
							"  group by substr(i_item_desc,1,30),i_item_sk,d_date\r\n",
							"  having count(*) >4),\r\n",
							" max_store_sales as\r\n",
							" (select max(csales) tpcds_cmax\r\n",
							"  from (select c_customer_sk,sum(ss_quantity*ss_sales_price) csales\r\n",
							"        from store_sales\r\n",
							"            ,customer\r\n",
							"            ,date_dim \r\n",
							"        where ss_customer_sk = c_customer_sk\r\n",
							"         and ss_sold_date_sk = d_date_sk\r\n",
							"         and d_year in (2000,2000+1,2000+2,2000+3)\r\n",
							"        group by c_customer_sk)),\r\n",
							" best_ss_customer as\r\n",
							" (select c_customer_sk,sum(ss_quantity*ss_sales_price) ssales\r\n",
							"  from store_sales\r\n",
							"      ,customer\r\n",
							"  where ss_customer_sk = c_customer_sk\r\n",
							"  group by c_customer_sk\r\n",
							"  having sum(ss_quantity*ss_sales_price) > (50/100.0) * (select\r\n",
							"  *\r\n",
							" from max_store_sales))\r\n",
							"  select  c_last_name,c_first_name,sales\r\n",
							" from (select c_last_name,c_first_name,sum(cs_quantity*cs_list_price) sales\r\n",
							"        from catalog_sales\r\n",
							"            ,customer\r\n",
							"            ,date_dim \r\n",
							"        where d_year = 2000 \r\n",
							"         and d_moy = 2 \r\n",
							"         and cs_sold_date_sk = d_date_sk \r\n",
							"         and cs_item_sk in (select item_sk from frequent_ss_items)\r\n",
							"         and cs_bill_customer_sk in (select c_customer_sk from best_ss_customer)\r\n",
							"         and cs_bill_customer_sk = c_customer_sk \r\n",
							"       group by c_last_name,c_first_name\r\n",
							"      union all\r\n",
							"      select c_last_name,c_first_name,sum(ws_quantity*ws_list_price) sales\r\n",
							"       from web_sales\r\n",
							"           ,customer\r\n",
							"           ,date_dim \r\n",
							"       where d_year = 2000 \r\n",
							"         and d_moy = 2 \r\n",
							"         and ws_sold_date_sk = d_date_sk \r\n",
							"         and ws_item_sk in (select item_sk from frequent_ss_items)\r\n",
							"         and ws_bill_customer_sk in (select c_customer_sk from best_ss_customer)\r\n",
							"         and ws_bill_customer_sk = c_customer_sk\r\n",
							"       group by c_last_name,c_first_name) \r\n",
							"     order by c_last_name,c_first_name,sales\r\n",
							"   limit 100;"
						],
						"outputs": [],
						"execution_count": 24
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query24\r\n",
							"with ssales as\r\n",
							"(select c_last_name\r\n",
							"      ,c_first_name\r\n",
							"      ,s_store_name\r\n",
							"      ,ca_state\r\n",
							"      ,s_state\r\n",
							"      ,i_color\r\n",
							"      ,i_current_price\r\n",
							"      ,i_manager_id\r\n",
							"      ,i_units\r\n",
							"      ,i_size\r\n",
							"      ,sum(ss_net_paid) netpaid\r\n",
							"from store_sales\r\n",
							"    ,store_returns\r\n",
							"    ,store\r\n",
							"    ,item\r\n",
							"    ,customer\r\n",
							"    ,customer_address\r\n",
							"where ss_ticket_number = sr_ticket_number\r\n",
							"  and ss_item_sk = sr_item_sk\r\n",
							"  and ss_customer_sk = c_customer_sk\r\n",
							"  and ss_item_sk = i_item_sk\r\n",
							"  and ss_store_sk = s_store_sk\r\n",
							"  and c_current_addr_sk = ca_address_sk\r\n",
							"  and c_birth_country <> upper(ca_country)\r\n",
							"  and s_zip = ca_zip\r\n",
							"and s_market_id=8\r\n",
							"group by c_last_name\r\n",
							"        ,c_first_name\r\n",
							"        ,s_store_name\r\n",
							"        ,ca_state\r\n",
							"        ,s_state\r\n",
							"        ,i_color\r\n",
							"        ,i_current_price\r\n",
							"        ,i_manager_id\r\n",
							"        ,i_units\r\n",
							"        ,i_size)\r\n",
							"select c_last_name\r\n",
							"      ,c_first_name\r\n",
							"      ,s_store_name\r\n",
							"      ,sum(netpaid) paid\r\n",
							"from ssales\r\n",
							"where i_color = 'pale'\r\n",
							"group by c_last_name\r\n",
							"        ,c_first_name\r\n",
							"        ,s_store_name\r\n",
							"having sum(netpaid) > (select 0.05*avg(netpaid)\r\n",
							"                                 from ssales)\r\n",
							"order by c_last_name\r\n",
							"        ,c_first_name\r\n",
							"        ,s_store_name\r\n",
							";\r\n",
							"with ssales as\r\n",
							"(select c_last_name\r\n",
							"      ,c_first_name\r\n",
							"      ,s_store_name\r\n",
							"      ,ca_state\r\n",
							"      ,s_state\r\n",
							"      ,i_color\r\n",
							"      ,i_current_price\r\n",
							"      ,i_manager_id\r\n",
							"      ,i_units\r\n",
							"      ,i_size\r\n",
							"      ,sum(ss_net_paid) netpaid\r\n",
							"from store_sales\r\n",
							"    ,store_returns\r\n",
							"    ,store\r\n",
							"    ,item\r\n",
							"    ,customer\r\n",
							"    ,customer_address\r\n",
							"where ss_ticket_number = sr_ticket_number\r\n",
							"  and ss_item_sk = sr_item_sk\r\n",
							"  and ss_customer_sk = c_customer_sk\r\n",
							"  and ss_item_sk = i_item_sk\r\n",
							"  and ss_store_sk = s_store_sk\r\n",
							"  and c_current_addr_sk = ca_address_sk\r\n",
							"  and c_birth_country <> upper(ca_country)\r\n",
							"  and s_zip = ca_zip\r\n",
							"  and s_market_id = 8\r\n",
							"group by c_last_name\r\n",
							"        ,c_first_name\r\n",
							"        ,s_store_name\r\n",
							"        ,ca_state\r\n",
							"        ,s_state\r\n",
							"        ,i_color\r\n",
							"        ,i_current_price\r\n",
							"        ,i_manager_id\r\n",
							"        ,i_units\r\n",
							"        ,i_size)\r\n",
							"select c_last_name\r\n",
							"      ,c_first_name\r\n",
							"      ,s_store_name\r\n",
							"      ,sum(netpaid) paid\r\n",
							"from ssales\r\n",
							"where i_color = 'chiffon'\r\n",
							"group by c_last_name\r\n",
							"        ,c_first_name\r\n",
							"        ,s_store_name\r\n",
							"having sum(netpaid) > (select 0.05*avg(netpaid)\r\n",
							"                           from ssales)\r\n",
							"order by c_last_name\r\n",
							"        ,c_first_name\r\n",
							"        ,s_store_name;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query25\r\n",
							"  select  \r\n",
							" i_item_id\r\n",
							" ,i_item_desc\r\n",
							" ,s_store_id\r\n",
							" ,s_store_name\r\n",
							" ,sum(ss_net_profit) as store_sales_profit\r\n",
							" ,sum(sr_net_loss) as store_returns_loss\r\n",
							" ,sum(cs_net_profit) as catalog_sales_profit\r\n",
							" from\r\n",
							" store_sales\r\n",
							" ,store_returns\r\n",
							" ,catalog_sales\r\n",
							" ,date_dim d1\r\n",
							" ,date_dim d2\r\n",
							" ,date_dim d3\r\n",
							" ,store\r\n",
							" ,item\r\n",
							" where\r\n",
							" d1.d_moy = 4\r\n",
							" and d1.d_year = 2001\r\n",
							" and d1.d_date_sk = ss_sold_date_sk\r\n",
							" and i_item_sk = ss_item_sk\r\n",
							" and s_store_sk = ss_store_sk\r\n",
							" and ss_customer_sk = sr_customer_sk\r\n",
							" and ss_item_sk = sr_item_sk\r\n",
							" and ss_ticket_number = sr_ticket_number\r\n",
							" and sr_returned_date_sk = d2.d_date_sk\r\n",
							" and d2.d_moy               between 4 and  10\r\n",
							" and d2.d_year              = 2001\r\n",
							" and sr_customer_sk = cs_bill_customer_sk\r\n",
							" and sr_item_sk = cs_item_sk\r\n",
							" and cs_sold_date_sk = d3.d_date_sk\r\n",
							" and d3.d_moy               between 4 and  10 \r\n",
							" and d3.d_year              = 2001\r\n",
							" group by\r\n",
							" i_item_id\r\n",
							" ,i_item_desc\r\n",
							" ,s_store_id\r\n",
							" ,s_store_name\r\n",
							" order by\r\n",
							" i_item_id\r\n",
							" ,i_item_desc\r\n",
							" ,s_store_id\r\n",
							" ,s_store_name\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query26\r\n",
							"  select  i_item_id, \r\n",
							"        avg(cs_quantity) agg1,\r\n",
							"        avg(cs_list_price) agg2,\r\n",
							"        avg(cs_coupon_amt) agg3,\r\n",
							"        avg(cs_sales_price) agg4 \r\n",
							" from catalog_sales, customer_demographics, date_dim, item, promotion\r\n",
							" where cs_sold_date_sk = d_date_sk and\r\n",
							"       cs_item_sk = i_item_sk and\r\n",
							"       cs_bill_cdemo_sk = cd_demo_sk and\r\n",
							"       cs_promo_sk = p_promo_sk and\r\n",
							"       cd_gender = 'M' and \r\n",
							"       cd_marital_status = 'S' and\r\n",
							"       cd_education_status = 'College' and\r\n",
							"       (p_channel_email = 'N' or p_channel_event = 'N') and\r\n",
							"       d_year = 2000 \r\n",
							" group by i_item_id\r\n",
							" order by i_item_id\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query27\r\n",
							"  select  i_item_id,\r\n",
							"        s_state, grouping(s_state) g_state,\r\n",
							"        avg(ss_quantity) agg1,\r\n",
							"        avg(ss_list_price) agg2,\r\n",
							"        avg(ss_coupon_amt) agg3,\r\n",
							"        avg(ss_sales_price) agg4\r\n",
							" from store_sales, customer_demographics, date_dim, store, item\r\n",
							" where ss_sold_date_sk = d_date_sk and\r\n",
							"       ss_item_sk = i_item_sk and\r\n",
							"       ss_store_sk = s_store_sk and\r\n",
							"       ss_cdemo_sk = cd_demo_sk and\r\n",
							"       cd_gender = 'M' and\r\n",
							"       cd_marital_status = 'S' and\r\n",
							"       cd_education_status = 'College' and\r\n",
							"       d_year = 2002 and\r\n",
							"       s_state in ('TN','TN', 'TN', 'TN', 'TN', 'TN')\r\n",
							" group by rollup (i_item_id, s_state)\r\n",
							" order by i_item_id\r\n",
							"         ,s_state\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query28\r\n",
							" select  *\r\n",
							"from (select avg(ss_list_price) B1_LP\r\n",
							"            ,count(ss_list_price) B1_CNT\r\n",
							"            ,count(distinct ss_list_price) B1_CNTD\r\n",
							"      from store_sales\r\n",
							"      where ss_quantity between 0 and 5\r\n",
							"        and (ss_list_price between 8 and 8+10 \r\n",
							"             or ss_coupon_amt between 459 and 459+1000\r\n",
							"             or ss_wholesale_cost between 57 and 57+20)) B1,\r\n",
							"     (select avg(ss_list_price) B2_LP\r\n",
							"            ,count(ss_list_price) B2_CNT\r\n",
							"            ,count(distinct ss_list_price) B2_CNTD\r\n",
							"      from store_sales\r\n",
							"      where ss_quantity between 6 and 10\r\n",
							"        and (ss_list_price between 90 and 90+10\r\n",
							"          or ss_coupon_amt between 2323 and 2323+1000\r\n",
							"          or ss_wholesale_cost between 31 and 31+20)) B2,\r\n",
							"     (select avg(ss_list_price) B3_LP\r\n",
							"            ,count(ss_list_price) B3_CNT\r\n",
							"            ,count(distinct ss_list_price) B3_CNTD\r\n",
							"      from store_sales\r\n",
							"      where ss_quantity between 11 and 15\r\n",
							"        and (ss_list_price between 142 and 142+10\r\n",
							"          or ss_coupon_amt between 12214 and 12214+1000\r\n",
							"          or ss_wholesale_cost between 79 and 79+20)) B3,\r\n",
							"     (select avg(ss_list_price) B4_LP\r\n",
							"            ,count(ss_list_price) B4_CNT\r\n",
							"            ,count(distinct ss_list_price) B4_CNTD\r\n",
							"      from store_sales\r\n",
							"      where ss_quantity between 16 and 20\r\n",
							"        and (ss_list_price between 135 and 135+10\r\n",
							"          or ss_coupon_amt between 6071 and 6071+1000\r\n",
							"          or ss_wholesale_cost between 38 and 38+20)) B4,\r\n",
							"     (select avg(ss_list_price) B5_LP\r\n",
							"            ,count(ss_list_price) B5_CNT\r\n",
							"            ,count(distinct ss_list_price) B5_CNTD\r\n",
							"      from store_sales\r\n",
							"      where ss_quantity between 21 and 25\r\n",
							"        and (ss_list_price between 122 and 122+10\r\n",
							"          or ss_coupon_amt between 836 and 836+1000\r\n",
							"          or ss_wholesale_cost between 17 and 17+20)) B5,\r\n",
							"     (select avg(ss_list_price) B6_LP\r\n",
							"            ,count(ss_list_price) B6_CNT\r\n",
							"            ,count(distinct ss_list_price) B6_CNTD\r\n",
							"      from store_sales\r\n",
							"      where ss_quantity between 26 and 30\r\n",
							"        and (ss_list_price between 154 and 154+10\r\n",
							"          or ss_coupon_amt between 7326 and 7326+1000\r\n",
							"          or ss_wholesale_cost between 7 and 7+20)) B6\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query29\r\n",
							"  select   \r\n",
							"     i_item_id\r\n",
							"    ,i_item_desc\r\n",
							"    ,s_store_id\r\n",
							"    ,s_store_name\r\n",
							"    ,sum(ss_quantity)        as store_sales_quantity\r\n",
							"    ,sum(sr_return_quantity) as store_returns_quantity\r\n",
							"    ,sum(cs_quantity)        as catalog_sales_quantity\r\n",
							" from\r\n",
							"    store_sales\r\n",
							"   ,store_returns\r\n",
							"   ,catalog_sales\r\n",
							"   ,date_dim             d1\r\n",
							"   ,date_dim             d2\r\n",
							"   ,date_dim             d3\r\n",
							"   ,store\r\n",
							"   ,item\r\n",
							" where\r\n",
							"     d1.d_moy               = 9 \r\n",
							" and d1.d_year              = 1999\r\n",
							" and d1.d_date_sk           = ss_sold_date_sk\r\n",
							" and i_item_sk              = ss_item_sk\r\n",
							" and s_store_sk             = ss_store_sk\r\n",
							" and ss_customer_sk         = sr_customer_sk\r\n",
							" and ss_item_sk             = sr_item_sk\r\n",
							" and ss_ticket_number       = sr_ticket_number\r\n",
							" and sr_returned_date_sk    = d2.d_date_sk\r\n",
							" and d2.d_moy               between 9 and  9 + 3 \r\n",
							" and d2.d_year              = 1999\r\n",
							" and sr_customer_sk         = cs_bill_customer_sk\r\n",
							" and sr_item_sk             = cs_item_sk\r\n",
							" and cs_sold_date_sk        = d3.d_date_sk     \r\n",
							" and d3.d_year              in (1999,1999+1,1999+2)\r\n",
							" group by\r\n",
							"    i_item_id\r\n",
							"   ,i_item_desc\r\n",
							"   ,s_store_id\r\n",
							"   ,s_store_name\r\n",
							" order by\r\n",
							"    i_item_id \r\n",
							"   ,i_item_desc\r\n",
							"   ,s_store_id\r\n",
							"   ,s_store_name\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query30\r\n",
							" with customer_total_return as\r\n",
							" (select wr_returning_customer_sk as ctr_customer_sk\r\n",
							"        ,ca_state as ctr_state, \r\n",
							" \tsum(wr_return_amt) as ctr_total_return\r\n",
							" from web_returns\r\n",
							"     ,date_dim\r\n",
							"     ,customer_address\r\n",
							" where wr_returned_date_sk = d_date_sk \r\n",
							"   and d_year =2002\r\n",
							"   and wr_returning_addr_sk = ca_address_sk \r\n",
							" group by wr_returning_customer_sk\r\n",
							"         ,ca_state)\r\n",
							"  select  c_customer_id,c_salutation,c_first_name,c_last_name,c_preferred_cust_flag\r\n",
							"       ,c_birth_day,c_birth_month,c_birth_year,c_birth_country,c_login,c_email_address\r\n",
							"       ,c_last_review_date,ctr_total_return\r\n",
							" from customer_total_return ctr1\r\n",
							"     ,customer_address\r\n",
							"     ,customer\r\n",
							" where ctr1.ctr_total_return > (select avg(ctr_total_return)*1.2\r\n",
							" \t\t\t  from customer_total_return ctr2 \r\n",
							"                  \t  where ctr1.ctr_state = ctr2.ctr_state)\r\n",
							"       and ca_address_sk = c_current_addr_sk\r\n",
							"       and ca_state = 'GA'\r\n",
							"       and ctr1.ctr_customer_sk = c_customer_sk\r\n",
							" order by c_customer_id,c_salutation,c_first_name,c_last_name,c_preferred_cust_flag\r\n",
							"                  ,c_birth_day,c_birth_month,c_birth_year,c_birth_country,c_login,c_email_address\r\n",
							"                  ,c_last_review_date,ctr_total_return\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query31\r\n",
							" with ss as\r\n",
							" (select ca_county,d_qoy, d_year,sum(ss_ext_sales_price) as store_sales\r\n",
							" from store_sales,date_dim,customer_address\r\n",
							" where ss_sold_date_sk = d_date_sk\r\n",
							"  and ss_addr_sk=ca_address_sk\r\n",
							" group by ca_county,d_qoy, d_year),\r\n",
							" ws as\r\n",
							" (select ca_county,d_qoy, d_year,sum(ws_ext_sales_price) as web_sales\r\n",
							" from web_sales,date_dim,customer_address\r\n",
							" where ws_sold_date_sk = d_date_sk\r\n",
							"  and ws_bill_addr_sk=ca_address_sk\r\n",
							" group by ca_county,d_qoy, d_year)\r\n",
							" select \r\n",
							"        ss1.ca_county\r\n",
							"       ,ss1.d_year\r\n",
							"       ,ws2.web_sales/ws1.web_sales web_q1_q2_increase\r\n",
							"       ,ss2.store_sales/ss1.store_sales store_q1_q2_increase\r\n",
							"       ,ws3.web_sales/ws2.web_sales web_q2_q3_increase\r\n",
							"       ,ss3.store_sales/ss2.store_sales store_q2_q3_increase\r\n",
							" from\r\n",
							"        ss ss1\r\n",
							"       ,ss ss2\r\n",
							"       ,ss ss3\r\n",
							"       ,ws ws1\r\n",
							"       ,ws ws2\r\n",
							"       ,ws ws3\r\n",
							" where\r\n",
							"    ss1.d_qoy = 1\r\n",
							"    and ss1.d_year = 2000\r\n",
							"    and ss1.ca_county = ss2.ca_county\r\n",
							"    and ss2.d_qoy = 2\r\n",
							"    and ss2.d_year = 2000\r\n",
							" and ss2.ca_county = ss3.ca_county\r\n",
							"    and ss3.d_qoy = 3\r\n",
							"    and ss3.d_year = 2000\r\n",
							"    and ss1.ca_county = ws1.ca_county\r\n",
							"    and ws1.d_qoy = 1\r\n",
							"    and ws1.d_year = 2000\r\n",
							"    and ws1.ca_county = ws2.ca_county\r\n",
							"    and ws2.d_qoy = 2\r\n",
							"    and ws2.d_year = 2000\r\n",
							"    and ws1.ca_county = ws3.ca_county\r\n",
							"    and ws3.d_qoy = 3\r\n",
							"    and ws3.d_year =2000\r\n",
							"    and case when ws1.web_sales > 0 then ws2.web_sales/ws1.web_sales else null end \r\n",
							"       > case when ss1.store_sales > 0 then ss2.store_sales/ss1.store_sales else null end\r\n",
							"    and case when ws2.web_sales > 0 then ws3.web_sales/ws2.web_sales else null end\r\n",
							"       > case when ss2.store_sales > 0 then ss3.store_sales/ss2.store_sales else null end\r\n",
							" order by ss1.ca_county;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query32\r\n",
							"select  sum(cs_ext_discount_amt)  as excess_discount_amount\r\n",
							"from \r\n",
							"   catalog_sales \r\n",
							"   ,item \r\n",
							"   ,date_dim\r\n",
							"where\r\n",
							"i_manufact_id = 977\r\n",
							"and i_item_sk = cs_item_sk \r\n",
							"and d_date between '2000-01-27' and \r\n",
							"        date_add(cast('2000-01-27' as date), 90 )\r\n",
							"and d_date_sk = cs_sold_date_sk \r\n",
							"and cs_ext_discount_amt  \r\n",
							"     > ( \r\n",
							"         select \r\n",
							"            1.3 * avg(cs_ext_discount_amt) \r\n",
							"         from \r\n",
							"            catalog_sales \r\n",
							"           ,date_dim\r\n",
							"         where \r\n",
							"              cs_item_sk = i_item_sk \r\n",
							"          and d_date between '2000-01-27' and\r\n",
							"                             date_add(cast('2000-01-27' as date), 90 )\r\n",
							"          and d_date_sk = cs_sold_date_sk \r\n",
							"      ) \r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query33\r\n",
							" with ss as (\r\n",
							" select\r\n",
							"          i_manufact_id,sum(ss_ext_sales_price) total_sales\r\n",
							" from\r\n",
							" \tstore_sales,\r\n",
							" \tdate_dim,\r\n",
							"         customer_address,\r\n",
							"         item\r\n",
							" where\r\n",
							"         i_manufact_id in (select\r\n",
							"  i_manufact_id\r\n",
							"from\r\n",
							" item\r\n",
							"where i_category in ('Electronics'))\r\n",
							" and     ss_item_sk              = i_item_sk\r\n",
							" and     ss_sold_date_sk         = d_date_sk\r\n",
							" and     d_year                  = 1998\r\n",
							" and     d_moy                   = 5\r\n",
							" and     ss_addr_sk              = ca_address_sk\r\n",
							" and     ca_gmt_offset           = -5 \r\n",
							" group by i_manufact_id),\r\n",
							" cs as (\r\n",
							" select\r\n",
							"          i_manufact_id,sum(cs_ext_sales_price) total_sales\r\n",
							" from\r\n",
							" \tcatalog_sales,\r\n",
							" \tdate_dim,\r\n",
							"         customer_address,\r\n",
							"         item\r\n",
							" where\r\n",
							"         i_manufact_id               in (select\r\n",
							"  i_manufact_id\r\n",
							"from\r\n",
							" item\r\n",
							"where i_category in ('Electronics'))\r\n",
							" and     cs_item_sk              = i_item_sk\r\n",
							" and     cs_sold_date_sk         = d_date_sk\r\n",
							" and     d_year                  = 1998\r\n",
							" and     d_moy                   = 5\r\n",
							" and     cs_bill_addr_sk         = ca_address_sk\r\n",
							" and     ca_gmt_offset           = -5 \r\n",
							" group by i_manufact_id),\r\n",
							" ws as (\r\n",
							" select\r\n",
							"          i_manufact_id,sum(ws_ext_sales_price) total_sales\r\n",
							" from\r\n",
							" \tweb_sales,\r\n",
							" \tdate_dim,\r\n",
							"         customer_address,\r\n",
							"         item\r\n",
							" where\r\n",
							"         i_manufact_id               in (select\r\n",
							"  i_manufact_id\r\n",
							"from\r\n",
							" item\r\n",
							"where i_category in ('Electronics'))\r\n",
							" and     ws_item_sk              = i_item_sk\r\n",
							" and     ws_sold_date_sk         = d_date_sk\r\n",
							" and     d_year                  = 1998\r\n",
							" and     d_moy                   = 5\r\n",
							" and     ws_bill_addr_sk         = ca_address_sk\r\n",
							" and     ca_gmt_offset           = -5\r\n",
							" group by i_manufact_id)\r\n",
							"  select  i_manufact_id ,sum(total_sales) total_sales\r\n",
							" from  (select * from ss \r\n",
							"        union all\r\n",
							"        select * from cs \r\n",
							"        union all\r\n",
							"        select * from ws) tmp1\r\n",
							" group by i_manufact_id\r\n",
							" order by total_sales\r\n",
							" limit 100;\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query34\r\n",
							" select c_last_name\r\n",
							"       ,c_first_name\r\n",
							"       ,c_salutation\r\n",
							"       ,c_preferred_cust_flag\r\n",
							"       ,ss_ticket_number\r\n",
							"       ,cnt from\r\n",
							"   (select ss_ticket_number\r\n",
							"          ,ss_customer_sk\r\n",
							"          ,count(*) cnt\r\n",
							"    from store_sales,date_dim,store,household_demographics\r\n",
							"    where store_sales.ss_sold_date_sk = date_dim.d_date_sk\r\n",
							"    and store_sales.ss_store_sk = store.s_store_sk  \r\n",
							"    and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk\r\n",
							"    and (date_dim.d_dom between 1 and 3 or date_dim.d_dom between 25 and 28)\r\n",
							"    and (household_demographics.hd_buy_potential = '>10000' or\r\n",
							"         household_demographics.hd_buy_potential = 'Unknown')\r\n",
							"    and household_demographics.hd_vehicle_count > 0\r\n",
							"    and (case when household_demographics.hd_vehicle_count > 0 \r\n",
							"\tthen household_demographics.hd_dep_count/ household_demographics.hd_vehicle_count \r\n",
							"\telse null \r\n",
							"\tend)  > 1.2\r\n",
							"    and date_dim.d_year in (1999,1999+1,1999+2)\r\n",
							"    and store.s_county in ('Williamson County','Williamson County','Williamson County','Williamson County',\r\n",
							"                           'Williamson County','Williamson County','Williamson County','Williamson County')\r\n",
							"    group by ss_ticket_number,ss_customer_sk) dn,customer\r\n",
							"    where ss_customer_sk = c_customer_sk\r\n",
							"      and cnt between 15 and 20\r\n",
							"    order by c_last_name,c_first_name,c_salutation,c_preferred_cust_flag desc, ss_ticket_number;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query35\r\n",
							"  select   \r\n",
							"  ca_state,\r\n",
							"  cd_gender,\r\n",
							"  cd_marital_status,\r\n",
							"  cd_dep_count,\r\n",
							"  count(*) cnt1,\r\n",
							"  min(cd_dep_count),\r\n",
							"  max(cd_dep_count),\r\n",
							"  avg(cd_dep_count),\r\n",
							"  cd_dep_employed_count,\r\n",
							"  count(*) cnt2,\r\n",
							"  min(cd_dep_employed_count),\r\n",
							"  max(cd_dep_employed_count),\r\n",
							"  avg(cd_dep_employed_count),\r\n",
							"  cd_dep_college_count,\r\n",
							"  count(*) cnt3,\r\n",
							"  min(cd_dep_college_count),\r\n",
							"  max(cd_dep_college_count),\r\n",
							"  avg(cd_dep_college_count)\r\n",
							" from\r\n",
							"  customer c,customer_address ca,customer_demographics\r\n",
							" where\r\n",
							"  c.c_current_addr_sk = ca.ca_address_sk and\r\n",
							"  cd_demo_sk = c.c_current_cdemo_sk and \r\n",
							"  exists (select *\r\n",
							"          from store_sales,date_dim\r\n",
							"          where c.c_customer_sk = ss_customer_sk and\r\n",
							"                ss_sold_date_sk = d_date_sk and\r\n",
							"                d_year = 2002 and\r\n",
							"                d_qoy < 4) and\r\n",
							"   (exists (select *\r\n",
							"            from web_sales,date_dim\r\n",
							"            where c.c_customer_sk = ws_bill_customer_sk and\r\n",
							"                  ws_sold_date_sk = d_date_sk and\r\n",
							"                  d_year = 2002 and\r\n",
							"                  d_qoy < 4) or \r\n",
							"    exists (select * \r\n",
							"            from catalog_sales,date_dim\r\n",
							"            where c.c_customer_sk = cs_ship_customer_sk and\r\n",
							"                  cs_sold_date_sk = d_date_sk and\r\n",
							"                  d_year = 2002 and\r\n",
							"                  d_qoy < 4))\r\n",
							" group by ca_state,\r\n",
							"          cd_gender,\r\n",
							"          cd_marital_status,\r\n",
							"          cd_dep_count,\r\n",
							"          cd_dep_employed_count,\r\n",
							"          cd_dep_college_count\r\n",
							" order by ca_state,\r\n",
							"          cd_gender,\r\n",
							"          cd_marital_status,\r\n",
							"          cd_dep_count,\r\n",
							"          cd_dep_employed_count,\r\n",
							"          cd_dep_college_count\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query36\r\n",
							"  select  \r\n",
							"    sum(ss_net_profit)/sum(ss_ext_sales_price) as gross_margin\r\n",
							"   ,i_category\r\n",
							"   ,i_class\r\n",
							"   ,grouping(i_category)+grouping(i_class) as lochierarchy\r\n",
							"   ,rank() over (\r\n",
							" \tpartition by grouping(i_category)+grouping(i_class),\r\n",
							" \tcase when grouping(i_class) = 0 then i_category end \r\n",
							" \torder by sum(ss_net_profit)/sum(ss_ext_sales_price) asc) as rank_within_parent\r\n",
							" from\r\n",
							"    store_sales\r\n",
							"   ,date_dim       d1\r\n",
							"   ,item\r\n",
							"   ,store\r\n",
							" where\r\n",
							"    d1.d_year = 2001 \r\n",
							" and d1.d_date_sk = ss_sold_date_sk\r\n",
							" and i_item_sk  = ss_item_sk \r\n",
							" and s_store_sk  = ss_store_sk\r\n",
							" and s_state in ('TN','TN','TN','TN',\r\n",
							"                 'TN','TN','TN','TN')\r\n",
							" group by rollup(i_category,i_class)\r\n",
							" order by\r\n",
							"   lochierarchy desc\r\n",
							"  ,case when lochierarchy = 0 then i_category end\r\n",
							"  ,rank_within_parent\r\n",
							"   limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query37\r\n",
							"  select  i_item_id\r\n",
							"       ,i_item_desc\r\n",
							"       ,i_current_price\r\n",
							" from item, inventory, date_dim, catalog_sales\r\n",
							" where i_current_price between 68 and 68 + 30\r\n",
							" and inv_item_sk = i_item_sk\r\n",
							" and d_date_sk=inv_date_sk\r\n",
							" and d_date between cast('2000-02-01' as date) and date_add(cast('2000-02-01' as date), 60 )\r\n",
							" and i_manufact_id in (677,940,694,808)\r\n",
							" and inv_quantity_on_hand between 100 and 500\r\n",
							" and cs_item_sk = i_item_sk\r\n",
							" group by i_item_id,i_item_desc,i_current_price\r\n",
							" order by i_item_id\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query38\r\n",
							" select  count(*) from (\r\n",
							"    select distinct c_last_name, c_first_name, d_date\r\n",
							"    from store_sales, date_dim, customer\r\n",
							"          where store_sales.ss_sold_date_sk = date_dim.d_date_sk\r\n",
							"      and store_sales.ss_customer_sk = customer.c_customer_sk\r\n",
							"      and d_month_seq between 1200 and 1200 + 11\r\n",
							"  intersect\r\n",
							"    select distinct c_last_name, c_first_name, d_date\r\n",
							"    from catalog_sales, date_dim, customer\r\n",
							"          where catalog_sales.cs_sold_date_sk = date_dim.d_date_sk\r\n",
							"      and catalog_sales.cs_bill_customer_sk = customer.c_customer_sk\r\n",
							"      and d_month_seq between 1200 and 1200 + 11\r\n",
							"  intersect\r\n",
							"    select distinct c_last_name, c_first_name, d_date\r\n",
							"    from web_sales, date_dim, customer\r\n",
							"          where web_sales.ws_sold_date_sk = date_dim.d_date_sk\r\n",
							"      and web_sales.ws_bill_customer_sk = customer.c_customer_sk\r\n",
							"      and d_month_seq between 1200 and 1200 + 11\r\n",
							") hot_cust\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query39\r\n",
							"with inv as\r\n",
							"(select w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy\r\n",
							"       ,stdev,mean, case mean when 0 then null else stdev/mean end cov\r\n",
							" from(select w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy\r\n",
							"            ,stddev_samp(inv_quantity_on_hand) stdev,avg(inv_quantity_on_hand) mean\r\n",
							"      from inventory\r\n",
							"          ,item\r\n",
							"          ,warehouse\r\n",
							"          ,date_dim\r\n",
							"      where inv_item_sk = i_item_sk\r\n",
							"        and inv_warehouse_sk = w_warehouse_sk\r\n",
							"        and inv_date_sk = d_date_sk\r\n",
							"        and d_year =2001\r\n",
							"      group by w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy) foo\r\n",
							" where case mean when 0 then 0 else stdev/mean end > 1)\r\n",
							"select inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean, inv1.cov\r\n",
							"        ,inv2.w_warehouse_sk as w_warehouse_sk_2,inv2.i_item_sk as i_item_sk_2,inv2.d_moy as d_moy_2,inv2.mean as mean_2, inv2.cov as cov_2\r\n",
							"from inv inv1,inv inv2\r\n",
							"where inv1.i_item_sk = inv2.i_item_sk\r\n",
							"  and inv1.w_warehouse_sk =  inv2.w_warehouse_sk\r\n",
							"  and inv1.d_moy=1\r\n",
							"  and inv2.d_moy=1+1\r\n",
							"order by inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean,inv1.cov\r\n",
							"        ,d_moy_2,mean_2, cov_2\r\n",
							";\r\n",
							"with inv as\r\n",
							"(select w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy\r\n",
							"       ,stdev,mean, case mean when 0 then null else stdev/mean end cov\r\n",
							" from(select w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy\r\n",
							"            ,stddev_samp(inv_quantity_on_hand) stdev,avg(inv_quantity_on_hand) mean\r\n",
							"      from inventory\r\n",
							"          ,item\r\n",
							"          ,warehouse\r\n",
							"          ,date_dim\r\n",
							"      where inv_item_sk = i_item_sk\r\n",
							"        and inv_warehouse_sk = w_warehouse_sk\r\n",
							"        and inv_date_sk = d_date_sk\r\n",
							"        and d_year =2001\r\n",
							"      group by w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy) foo\r\n",
							" where case mean when 0 then 0 else stdev/mean end > 1)\r\n",
							"select inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean, inv1.cov\r\n",
							"        ,inv2.w_warehouse_sk as w_warehouse_sk_2,inv2.i_item_sk as i_item_sk_2,inv2.d_moy as d_moy_2,inv2.mean as mean_2, inv2.cov as cov_2\r\n",
							"from inv inv1,inv inv2\r\n",
							"where inv1.i_item_sk = inv2.i_item_sk\r\n",
							"  and inv1.w_warehouse_sk =  inv2.w_warehouse_sk\r\n",
							"  and inv1.d_moy=1\r\n",
							"  and inv2.d_moy=1+1\r\n",
							"  and inv1.cov > 1.5\r\n",
							"order by inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean,inv1.cov\r\n",
							"        ,d_moy_2,mean_2, cov_2;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query40\r\n",
							"  select  \r\n",
							"   w_state\r\n",
							"  ,i_item_id\r\n",
							"  ,sum(case when (cast(d_date as date) < cast ('2000-03-11' as date)) \r\n",
							" \t\tthen cs_sales_price - coalesce(cr_refunded_cash,0) else 0 end) as sales_before\r\n",
							"  ,sum(case when (cast(d_date as date) >= cast ('2000-03-11' as date)) \r\n",
							" \t\tthen cs_sales_price - coalesce(cr_refunded_cash,0) else 0 end) as sales_after\r\n",
							" from\r\n",
							"   catalog_sales left outer join catalog_returns on\r\n",
							"       (cs_order_number = cr_order_number \r\n",
							"        and cs_item_sk = cr_item_sk)\r\n",
							"  ,warehouse \r\n",
							"  ,item\r\n",
							"  ,date_dim\r\n",
							" where\r\n",
							"     i_current_price between 0.99 and 1.49\r\n",
							" and i_item_sk          = cs_item_sk\r\n",
							" and cs_warehouse_sk    = w_warehouse_sk \r\n",
							" and cs_sold_date_sk    = d_date_sk\r\n",
							" and d_date between date_sub(cast ('2000-03-11' as date), 30 )\r\n",
							"                and date_add(cast ('2000-03-11' as date), 30 ) \r\n",
							" group by\r\n",
							"    w_state,i_item_id\r\n",
							" order by w_state,i_item_id\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query41\r\n",
							"  select  distinct(i_product_name)\r\n",
							" from item i1\r\n",
							" where i_manufact_id between 738 and 738+40 \r\n",
							"   and (select count(*) as item_cnt\r\n",
							"        from item\r\n",
							"        where (i_manufact = i1.i_manufact and\r\n",
							"        ((i_category = 'Women' and \r\n",
							"        (i_color = 'powder' or i_color = 'khaki') and \r\n",
							"        (i_units = 'Ounce' or i_units = 'Oz') and\r\n",
							"        (i_size = 'medium' or i_size = 'extra large')\r\n",
							"        ) or\r\n",
							"        (i_category = 'Women' and\r\n",
							"        (i_color = 'brown' or i_color = 'honeydew') and\r\n",
							"        (i_units = 'Bunch' or i_units = 'Ton') and\r\n",
							"        (i_size = 'N/A' or i_size = 'small')\r\n",
							"        ) or\r\n",
							"        (i_category = 'Men' and\r\n",
							"        (i_color = 'floral' or i_color = 'deep') and\r\n",
							"        (i_units = 'N/A' or i_units = 'Dozen') and\r\n",
							"        (i_size = 'petite' or i_size = 'large')\r\n",
							"        ) or\r\n",
							"        (i_category = 'Men' and\r\n",
							"        (i_color = 'light' or i_color = 'cornflower') and\r\n",
							"        (i_units = 'Box' or i_units = 'Pound') and\r\n",
							"        (i_size = 'medium' or i_size = 'extra large')\r\n",
							"        ))) or\r\n",
							"       (i_manufact = i1.i_manufact and\r\n",
							"        ((i_category = 'Women' and \r\n",
							"        (i_color = 'midnight' or i_color = 'snow') and \r\n",
							"        (i_units = 'Pallet' or i_units = 'Gross') and\r\n",
							"        (i_size = 'medium' or i_size = 'extra large')\r\n",
							"        ) or\r\n",
							"        (i_category = 'Women' and\r\n",
							"        (i_color = 'cyan' or i_color = 'papaya') and\r\n",
							"        (i_units = 'Cup' or i_units = 'Dram') and\r\n",
							"        (i_size = 'N/A' or i_size = 'small')\r\n",
							"        ) or\r\n",
							"        (i_category = 'Men' and\r\n",
							"        (i_color = 'orange' or i_color = 'frosted') and\r\n",
							"        (i_units = 'Each' or i_units = 'Tbl') and\r\n",
							"        (i_size = 'petite' or i_size = 'large')\r\n",
							"        ) or\r\n",
							"        (i_category = 'Men' and\r\n",
							"        (i_color = 'forest' or i_color = 'ghost') and\r\n",
							"        (i_units = 'Lb' or i_units = 'Bundle') and\r\n",
							"        (i_size = 'medium' or i_size = 'extra large')\r\n",
							"        )))) > 0\r\n",
							" order by i_product_name\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query42\r\n",
							"  select  dt.d_year\r\n",
							" \t,item.i_category_id\r\n",
							" \t,item.i_category\r\n",
							" \t,sum(ss_ext_sales_price)\r\n",
							" from \tdate_dim dt\r\n",
							" \t,store_sales\r\n",
							" \t,item\r\n",
							" where dt.d_date_sk = store_sales.ss_sold_date_sk\r\n",
							" \tand store_sales.ss_item_sk = item.i_item_sk\r\n",
							" \tand item.i_manager_id = 1  \t\r\n",
							" \tand dt.d_moy=11\r\n",
							" \tand dt.d_year=2000\r\n",
							" group by \tdt.d_year\r\n",
							" \t\t,item.i_category_id\r\n",
							" \t\t,item.i_category\r\n",
							" order by       sum(ss_ext_sales_price) desc,dt.d_year\r\n",
							" \t\t,item.i_category_id\r\n",
							" \t\t,item.i_category\r\n",
							" limit 100 ;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query43\r\n",
							"  select  s_store_name, s_store_id,\r\n",
							"        sum(case when (d_day_name='Sunday') then ss_sales_price else null end) sun_sales,\r\n",
							"        sum(case when (d_day_name='Monday') then ss_sales_price else null end) mon_sales,\r\n",
							"        sum(case when (d_day_name='Tuesday') then ss_sales_price else  null end) tue_sales,\r\n",
							"        sum(case when (d_day_name='Wednesday') then ss_sales_price else null end) wed_sales,\r\n",
							"        sum(case when (d_day_name='Thursday') then ss_sales_price else null end) thu_sales,\r\n",
							"        sum(case when (d_day_name='Friday') then ss_sales_price else null end) fri_sales,\r\n",
							"        sum(case when (d_day_name='Saturday') then ss_sales_price else null end) sat_sales\r\n",
							" from date_dim, store_sales, store\r\n",
							" where d_date_sk = ss_sold_date_sk and\r\n",
							"       s_store_sk = ss_store_sk and\r\n",
							"       s_gmt_offset = -5 and\r\n",
							"       d_year = 2000 \r\n",
							" group by s_store_name, s_store_id\r\n",
							" order by s_store_name, s_store_id,sun_sales,mon_sales,tue_sales,wed_sales,thu_sales,fri_sales,sat_sales\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query44\r\n",
							" select  asceding.rnk, i1.i_product_name best_performing, i2.i_product_name worst_performing\r\n",
							"from(select *\r\n",
							"     from (select item_sk,rank() over (order by rank_col asc) rnk\r\n",
							"           from (select ss_item_sk item_sk,avg(ss_net_profit) rank_col \r\n",
							"                 from store_sales ss1\r\n",
							"                 where ss_store_sk = 4\r\n",
							"                 group by ss_item_sk\r\n",
							"                 having avg(ss_net_profit) > 0.9*(select avg(ss_net_profit) rank_col\r\n",
							"                                                  from store_sales\r\n",
							"                                                  where ss_store_sk = 4\r\n",
							"                                                    and ss_addr_sk is null\r\n",
							"                                                  group by ss_store_sk))V1)V11\r\n",
							"     where rnk  < 11) asceding,\r\n",
							"    (select *\r\n",
							"     from (select item_sk,rank() over (order by rank_col desc) rnk\r\n",
							"           from (select ss_item_sk item_sk,avg(ss_net_profit) rank_col\r\n",
							"                 from store_sales ss1\r\n",
							"                 where ss_store_sk = 4\r\n",
							"                 group by ss_item_sk\r\n",
							"                 having avg(ss_net_profit) > 0.9*(select avg(ss_net_profit) rank_col\r\n",
							"                                                  from store_sales\r\n",
							"                                                  where ss_store_sk = 4\r\n",
							"                                                    and ss_addr_sk is null\r\n",
							"                                                  group by ss_store_sk))V2)V21\r\n",
							"     where rnk  < 11) descending,\r\n",
							"item i1,\r\n",
							"item i2\r\n",
							"where asceding.rnk = descending.rnk \r\n",
							"  and i1.i_item_sk=asceding.item_sk\r\n",
							"  and i2.i_item_sk=descending.item_sk\r\n",
							"order by asceding.rnk\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query45\r\n",
							"  select  ca_zip, ca_city, sum(ws_sales_price)\r\n",
							" from web_sales, customer, customer_address, date_dim, item\r\n",
							" where ws_bill_customer_sk = c_customer_sk\r\n",
							" \tand c_current_addr_sk = ca_address_sk \r\n",
							" \tand ws_item_sk = i_item_sk \r\n",
							" \tand ( substr(ca_zip,1,5) in ('85669', '86197','88274','83405','86475', '85392', '85460', '80348', '81792')\r\n",
							" \t      or \r\n",
							" \t      i_item_id in (select i_item_id\r\n",
							"                             from item\r\n",
							"                             where i_item_sk in (2, 3, 5, 7, 11, 13, 17, 19, 23, 29)\r\n",
							"                             )\r\n",
							" \t    )\r\n",
							" \tand ws_sold_date_sk = d_date_sk\r\n",
							" \tand d_qoy = 2 and d_year = 2001\r\n",
							" group by ca_zip, ca_city\r\n",
							" order by ca_zip, ca_city\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query46\r\n",
							"  select  c_last_name\r\n",
							"       ,c_first_name\r\n",
							"       ,ca_city\r\n",
							"       ,bought_city\r\n",
							"       ,ss_ticket_number\r\n",
							"       ,amt,profit \r\n",
							" from\r\n",
							"   (select ss_ticket_number\r\n",
							"          ,ss_customer_sk\r\n",
							"          ,ca_city bought_city\r\n",
							"          ,sum(ss_coupon_amt) amt\r\n",
							"          ,sum(ss_net_profit) profit\r\n",
							"    from store_sales,date_dim,store,household_demographics,customer_address \r\n",
							"    where store_sales.ss_sold_date_sk = date_dim.d_date_sk\r\n",
							"    and store_sales.ss_store_sk = store.s_store_sk  \r\n",
							"    and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk\r\n",
							"    and store_sales.ss_addr_sk = customer_address.ca_address_sk\r\n",
							"    and (household_demographics.hd_dep_count = 4 or\r\n",
							"         household_demographics.hd_vehicle_count= 3)\r\n",
							"    and date_dim.d_dow in (6,0)\r\n",
							"    and date_dim.d_year in (1999,1999+1,1999+2) \r\n",
							"    and store.s_city in ('Fairview','Midway','Fairview','Fairview','Fairview') \r\n",
							"    group by ss_ticket_number,ss_customer_sk,ss_addr_sk,ca_city) dn,customer,customer_address current_addr\r\n",
							"    where ss_customer_sk = c_customer_sk\r\n",
							"      and customer.c_current_addr_sk = current_addr.ca_address_sk\r\n",
							"      and current_addr.ca_city <> bought_city\r\n",
							"  order by c_last_name\r\n",
							"          ,c_first_name\r\n",
							"          ,ca_city\r\n",
							"          ,bought_city\r\n",
							"          ,ss_ticket_number\r\n",
							"   limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query47\r\n",
							" with v1 as(\r\n",
							" select i_category, i_brand,\r\n",
							"        s_store_name, s_company_name,\r\n",
							"        d_year, d_moy,\r\n",
							"        sum(ss_sales_price) sum_sales,\r\n",
							"        avg(sum(ss_sales_price)) over\r\n",
							"          (partition by i_category, i_brand,\r\n",
							"                     s_store_name, s_company_name, d_year)\r\n",
							"          avg_monthly_sales,\r\n",
							"        rank() over\r\n",
							"          (partition by i_category, i_brand,\r\n",
							"                     s_store_name, s_company_name\r\n",
							"           order by d_year, d_moy) rn\r\n",
							" from item, store_sales, date_dim, store\r\n",
							" where ss_item_sk = i_item_sk and\r\n",
							"       ss_sold_date_sk = d_date_sk and\r\n",
							"       ss_store_sk = s_store_sk and\r\n",
							"       (\r\n",
							"         d_year = 1999 or\r\n",
							"         ( d_year = 1999-1 and d_moy =12) or\r\n",
							"         ( d_year = 1999+1 and d_moy =1)\r\n",
							"       )\r\n",
							" group by i_category, i_brand,\r\n",
							"          s_store_name, s_company_name,\r\n",
							"          d_year, d_moy),\r\n",
							" v2 as(\r\n",
							" select v1.i_category, v1.i_brand, v1.s_store_name, v1.s_company_name\r\n",
							"        ,v1.d_year, v1.d_moy\r\n",
							"        ,v1.avg_monthly_sales\r\n",
							"        ,v1.sum_sales, v1_lag.sum_sales psum, v1_lead.sum_sales nsum\r\n",
							" from v1, v1 v1_lag, v1 v1_lead\r\n",
							" where v1.i_category = v1_lag.i_category and\r\n",
							"       v1.i_category = v1_lead.i_category and\r\n",
							"       v1.i_brand = v1_lag.i_brand and\r\n",
							"       v1.i_brand = v1_lead.i_brand and\r\n",
							"       v1.s_store_name = v1_lag.s_store_name and\r\n",
							"       v1.s_store_name = v1_lead.s_store_name and\r\n",
							"       v1.s_company_name = v1_lag.s_company_name and\r\n",
							"       v1.s_company_name = v1_lead.s_company_name and\r\n",
							"       v1.rn = v1_lag.rn + 1 and\r\n",
							"       v1.rn = v1_lead.rn - 1)\r\n",
							"  select  *\r\n",
							" from v2\r\n",
							" where  d_year = 1999 and    \r\n",
							"        avg_monthly_sales > 0 and\r\n",
							"        case when avg_monthly_sales > 0 then abs(sum_sales - avg_monthly_sales) / avg_monthly_sales else null end > 0.1\r\n",
							" order by sum_sales - avg_monthly_sales, 3\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query48\r\n",
							" select sum (ss_quantity)\r\n",
							" from store_sales, store, customer_demographics, customer_address, date_dim\r\n",
							" where s_store_sk = ss_store_sk\r\n",
							" and  ss_sold_date_sk = d_date_sk and d_year = 2000\r\n",
							" and  \r\n",
							" (\r\n",
							"  (\r\n",
							"   cd_demo_sk = ss_cdemo_sk\r\n",
							"   and \r\n",
							"   cd_marital_status = 'M'\r\n",
							"   and \r\n",
							"   cd_education_status = '4 yr Degree'\r\n",
							"   and \r\n",
							"   ss_sales_price between 100.00 and 150.00  \r\n",
							"   )\r\n",
							" or\r\n",
							"  (\r\n",
							"  cd_demo_sk = ss_cdemo_sk\r\n",
							"   and \r\n",
							"   cd_marital_status = 'D'\r\n",
							"   and \r\n",
							"   cd_education_status = '2 yr Degree'\r\n",
							"   and \r\n",
							"   ss_sales_price between 50.00 and 100.00   \r\n",
							"  )\r\n",
							" or \r\n",
							" (\r\n",
							"  cd_demo_sk = ss_cdemo_sk\r\n",
							"  and \r\n",
							"   cd_marital_status = 'S'\r\n",
							"   and \r\n",
							"   cd_education_status = 'College'\r\n",
							"   and \r\n",
							"   ss_sales_price between 150.00 and 200.00  \r\n",
							" )\r\n",
							" )\r\n",
							" and\r\n",
							" (\r\n",
							"  (\r\n",
							"  ss_addr_sk = ca_address_sk\r\n",
							"  and\r\n",
							"  ca_country = 'United States'\r\n",
							"  and\r\n",
							"  ca_state in ('CO', 'OH', 'TX')\r\n",
							"  and ss_net_profit between 0 and 2000  \r\n",
							"  )\r\n",
							" or\r\n",
							"  (ss_addr_sk = ca_address_sk\r\n",
							"  and\r\n",
							"  ca_country = 'United States'\r\n",
							"  and\r\n",
							"  ca_state in ('OR', 'MN', 'KY')\r\n",
							"  and ss_net_profit between 150 and 3000 \r\n",
							"  )\r\n",
							" or\r\n",
							"  (ss_addr_sk = ca_address_sk\r\n",
							"  and\r\n",
							"  ca_country = 'United States'\r\n",
							"  and\r\n",
							"  ca_state in ('VA', 'CA', 'MS')\r\n",
							"  and ss_net_profit between 50 and 25000 \r\n",
							"  )\r\n",
							" );"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query49\r\n",
							"  select  \r\n",
							" 'web' as channel\r\n",
							" ,web.item\r\n",
							" ,web.return_ratio\r\n",
							" ,web.return_rank\r\n",
							" ,web.currency_rank\r\n",
							" from (\r\n",
							" \tselect \r\n",
							" \t item\r\n",
							" \t,return_ratio\r\n",
							" \t,currency_ratio\r\n",
							" \t,rank() over (order by return_ratio) as return_rank\r\n",
							" \t,rank() over (order by currency_ratio) as currency_rank\r\n",
							" \tfrom\r\n",
							" \t(\tselect ws.ws_item_sk as item\r\n",
							" \t\t,(cast(sum(coalesce(wr.wr_return_quantity,0)) as decimal(15,4))/\r\n",
							" \t\tcast(sum(coalesce(ws.ws_quantity,0)) as decimal(15,4) )) as return_ratio\r\n",
							" \t\t,(cast(sum(coalesce(wr.wr_return_amt,0)) as decimal(15,4))/\r\n",
							" \t\tcast(sum(coalesce(ws.ws_net_paid,0)) as decimal(15,4) )) as currency_ratio\r\n",
							" \t\tfrom \r\n",
							" \t\t web_sales ws left outer join web_returns wr \r\n",
							" \t\t\ton (ws.ws_order_number = wr.wr_order_number and \r\n",
							" \t\t\tws.ws_item_sk = wr.wr_item_sk)\r\n",
							"                 ,date_dim\r\n",
							" \t\twhere \r\n",
							" \t\t\twr.wr_return_amt > 10000 \r\n",
							" \t\t\tand ws.ws_net_profit > 1\r\n",
							"                         and ws.ws_net_paid > 0\r\n",
							"                         and ws.ws_quantity > 0\r\n",
							"                         and ws_sold_date_sk = d_date_sk\r\n",
							"                         and d_year = 2001\r\n",
							"                         and d_moy = 12\r\n",
							" \t\tgroup by ws.ws_item_sk\r\n",
							" \t) in_web\r\n",
							" ) web\r\n",
							" where \r\n",
							" (\r\n",
							" web.return_rank <= 10\r\n",
							" or\r\n",
							" web.currency_rank <= 10\r\n",
							" )\r\n",
							" union\r\n",
							" select \r\n",
							" 'catalog' as channel\r\n",
							" ,catalog.item\r\n",
							" ,catalog.return_ratio\r\n",
							" ,catalog.return_rank\r\n",
							" ,catalog.currency_rank\r\n",
							" from (\r\n",
							" \tselect \r\n",
							" \t item\r\n",
							" \t,return_ratio\r\n",
							" \t,currency_ratio\r\n",
							" \t,rank() over (order by return_ratio) as return_rank\r\n",
							" \t,rank() over (order by currency_ratio) as currency_rank\r\n",
							" \tfrom\r\n",
							" \t(\tselect \r\n",
							" \t\tcs.cs_item_sk as item\r\n",
							" \t\t,(cast(sum(coalesce(cr.cr_return_quantity,0)) as decimal(15,4))/\r\n",
							" \t\tcast(sum(coalesce(cs.cs_quantity,0)) as decimal(15,4) )) as return_ratio\r\n",
							" \t\t,(cast(sum(coalesce(cr.cr_return_amount,0)) as decimal(15,4))/\r\n",
							" \t\tcast(sum(coalesce(cs.cs_net_paid,0)) as decimal(15,4) )) as currency_ratio\r\n",
							" \t\tfrom \r\n",
							" \t\tcatalog_sales cs left outer join catalog_returns cr\r\n",
							" \t\t\ton (cs.cs_order_number = cr.cr_order_number and \r\n",
							" \t\t\tcs.cs_item_sk = cr.cr_item_sk)\r\n",
							"                ,date_dim\r\n",
							" \t\twhere \r\n",
							" \t\t\tcr.cr_return_amount > 10000 \r\n",
							" \t\t\tand cs.cs_net_profit > 1\r\n",
							"                         and cs.cs_net_paid > 0\r\n",
							"                         and cs.cs_quantity > 0\r\n",
							"                         and cs_sold_date_sk = d_date_sk\r\n",
							"                         and d_year = 2001\r\n",
							"                         and d_moy = 12\r\n",
							"                 group by cs.cs_item_sk\r\n",
							" \t) in_cat\r\n",
							" ) catalog\r\n",
							" where \r\n",
							" (\r\n",
							" catalog.return_rank <= 10\r\n",
							" or\r\n",
							" catalog.currency_rank <=10\r\n",
							" )\r\n",
							" union\r\n",
							" select \r\n",
							" 'store' as channel\r\n",
							" ,store.item\r\n",
							" ,store.return_ratio\r\n",
							" ,store.return_rank\r\n",
							" ,store.currency_rank\r\n",
							" from (\r\n",
							" \tselect \r\n",
							" \t item\r\n",
							" \t,return_ratio\r\n",
							" \t,currency_ratio\r\n",
							" \t,rank() over (order by return_ratio) as return_rank\r\n",
							" \t,rank() over (order by currency_ratio) as currency_rank\r\n",
							" \tfrom\r\n",
							" \t(\tselect sts.ss_item_sk as item\r\n",
							" \t\t,(cast(sum(coalesce(sr.sr_return_quantity,0)) as decimal(15,4))/cast(sum(coalesce(sts.ss_quantity,0)) as decimal(15,4) )) as return_ratio\r\n",
							" \t\t,(cast(sum(coalesce(sr.sr_return_amt,0)) as decimal(15,4))/cast(sum(coalesce(sts.ss_net_paid,0)) as decimal(15,4) )) as currency_ratio\r\n",
							" \t\tfrom \r\n",
							" \t\tstore_sales sts left outer join store_returns sr\r\n",
							" \t\t\ton (sts.ss_ticket_number = sr.sr_ticket_number and sts.ss_item_sk = sr.sr_item_sk)\r\n",
							"                ,date_dim\r\n",
							" \t\twhere \r\n",
							" \t\t\tsr.sr_return_amt > 10000 \r\n",
							" \t\t\tand sts.ss_net_profit > 1\r\n",
							"                         and sts.ss_net_paid > 0 \r\n",
							"                         and sts.ss_quantity > 0\r\n",
							"                         and ss_sold_date_sk = d_date_sk\r\n",
							"                         and d_year = 2001\r\n",
							"                         and d_moy = 12\r\n",
							" \t\tgroup by sts.ss_item_sk\r\n",
							" \t) in_store\r\n",
							" ) store\r\n",
							" where  (\r\n",
							" store.return_rank <= 10\r\n",
							" or \r\n",
							" store.currency_rank <= 10\r\n",
							" )\r\n",
							" order by 1,4,5\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query50\r\n",
							" select  \r\n",
							"   s_store_name\r\n",
							"  ,s_company_id\r\n",
							"  ,s_street_number\r\n",
							"  ,s_street_name\r\n",
							"  ,s_street_type\r\n",
							"  ,s_suite_number\r\n",
							"  ,s_city\r\n",
							"  ,s_county\r\n",
							"  ,s_state\r\n",
							"  ,s_zip\r\n",
							"  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk <= 30 ) then 1 else 0 end)  as 30_days \r\n",
							"  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk > 30) and \r\n",
							"                 (sr_returned_date_sk - ss_sold_date_sk <= 60) then 1 else 0 end )  as 31_60_days \r\n",
							"  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk > 60) and \r\n",
							"                 (sr_returned_date_sk - ss_sold_date_sk <= 90) then 1 else 0 end)  as 61_90_days \r\n",
							"  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk > 90) and\r\n",
							"                 (sr_returned_date_sk - ss_sold_date_sk <= 120) then 1 else 0 end)  as 91_120_days\r\n",
							"  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk  > 120) then 1 else 0 end)  as above120_days\r\n",
							"from\r\n",
							"   store_sales\r\n",
							"  ,store_returns\r\n",
							"  ,store\r\n",
							"  ,date_dim d1\r\n",
							"  ,date_dim d2\r\n",
							"where\r\n",
							"    d2.d_year = 2001\r\n",
							"and d2.d_moy  = 8\r\n",
							"and ss_ticket_number = sr_ticket_number\r\n",
							"and ss_item_sk = sr_item_sk\r\n",
							"and ss_sold_date_sk   = d1.d_date_sk\r\n",
							"and sr_returned_date_sk   = d2.d_date_sk\r\n",
							"and ss_customer_sk = sr_customer_sk\r\n",
							"and ss_store_sk = s_store_sk\r\n",
							"group by\r\n",
							"   s_store_name\r\n",
							"  ,s_company_id\r\n",
							"  ,s_street_number\r\n",
							"  ,s_street_name\r\n",
							"  ,s_street_type\r\n",
							"  ,s_suite_number\r\n",
							"  ,s_city\r\n",
							"  ,s_county\r\n",
							"  ,s_state\r\n",
							"  ,s_zip\r\n",
							"order by s_store_name\r\n",
							"        ,s_company_id\r\n",
							"        ,s_street_number\r\n",
							"        ,s_street_name\r\n",
							"        ,s_street_type\r\n",
							"        ,s_suite_number\r\n",
							"        ,s_city\r\n",
							"        ,s_county\r\n",
							"        ,s_state\r\n",
							"        ,s_zip\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query51\r\n",
							"WITH web_v1 as (\r\n",
							"select\r\n",
							"  ws_item_sk item_sk, d_date,\r\n",
							"  sum(sum(ws_sales_price))\r\n",
							"      over (partition by ws_item_sk order by d_date rows between unbounded preceding and current row) cume_sales\r\n",
							"from web_sales\r\n",
							"    ,date_dim\r\n",
							"where ws_sold_date_sk=d_date_sk\r\n",
							"  and d_month_seq between 1200 and 1200+11\r\n",
							"  and ws_item_sk is not NULL\r\n",
							"group by ws_item_sk, d_date),\r\n",
							"store_v1 as (\r\n",
							"select\r\n",
							"  ss_item_sk item_sk, d_date,\r\n",
							"  sum(sum(ss_sales_price))\r\n",
							"      over (partition by ss_item_sk order by d_date rows between unbounded preceding and current row) cume_sales\r\n",
							"from store_sales\r\n",
							"    ,date_dim\r\n",
							"where ss_sold_date_sk=d_date_sk\r\n",
							"  and d_month_seq between 1200 and 1200+11\r\n",
							"  and ss_item_sk is not NULL\r\n",
							"group by ss_item_sk, d_date)\r\n",
							" select  *\r\n",
							"from (select item_sk\r\n",
							"     ,d_date\r\n",
							"     ,web_sales\r\n",
							"     ,store_sales\r\n",
							"     ,max(web_sales)\r\n",
							"         over (partition by item_sk order by d_date rows between unbounded preceding and current row) web_cumulative\r\n",
							"     ,max(store_sales)\r\n",
							"         over (partition by item_sk order by d_date rows between unbounded preceding and current row) store_cumulative\r\n",
							"     from (select case when web.item_sk is not null then web.item_sk else store.item_sk end item_sk\r\n",
							"                 ,case when web.d_date is not null then web.d_date else store.d_date end d_date\r\n",
							"                 ,web.cume_sales web_sales\r\n",
							"                 ,store.cume_sales store_sales\r\n",
							"           from web_v1 web full outer join store_v1 store on (web.item_sk = store.item_sk\r\n",
							"                                                          and web.d_date = store.d_date)\r\n",
							"          )x )y\r\n",
							"where web_cumulative > store_cumulative\r\n",
							"order by item_sk\r\n",
							"        ,d_date\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query52\r\n",
							"  select  dt.d_year\r\n",
							" \t,item.i_brand_id brand_id\r\n",
							" \t,item.i_brand brand\r\n",
							" \t,sum(ss_ext_sales_price) ext_price\r\n",
							" from date_dim dt\r\n",
							"     ,store_sales\r\n",
							"     ,item\r\n",
							" where dt.d_date_sk = store_sales.ss_sold_date_sk\r\n",
							"    and store_sales.ss_item_sk = item.i_item_sk\r\n",
							"    and item.i_manager_id = 1\r\n",
							"    and dt.d_moy=11\r\n",
							"    and dt.d_year=2000\r\n",
							" group by dt.d_year\r\n",
							" \t,item.i_brand\r\n",
							" \t,item.i_brand_id\r\n",
							" order by dt.d_year\r\n",
							" \t,ext_price desc\r\n",
							" \t,brand_id\r\n",
							" limit 100 ;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query53\r\n",
							" select  * from \r\n",
							"(select i_manufact_id,\r\n",
							"sum(ss_sales_price) sum_sales,\r\n",
							"avg(sum(ss_sales_price)) over (partition by i_manufact_id) avg_quarterly_sales\r\n",
							"from item, store_sales, date_dim, store\r\n",
							"where ss_item_sk = i_item_sk and\r\n",
							"ss_sold_date_sk = d_date_sk and\r\n",
							"ss_store_sk = s_store_sk and\r\n",
							"d_month_seq in (1200,1200+1,1200+2,1200+3,1200+4,1200+5,1200+6,1200+7,1200+8,1200+9,1200+10,1200+11) and\r\n",
							"((i_category in ('Books','Children','Electronics') and\r\n",
							"i_class in ('personal','portable','reference','self-help') and\r\n",
							"i_brand in ('scholaramalgamalg #14','scholaramalgamalg #7',\r\n",
							"\t\t'exportiunivamalg #9','scholaramalgamalg #9'))\r\n",
							"or(i_category in ('Women','Music','Men') and\r\n",
							"i_class in ('accessories','classical','fragrances','pants') and\r\n",
							"i_brand in ('amalgimporto #1','edu packscholar #1','exportiimporto #1',\r\n",
							"\t\t'importoamalg #1')))\r\n",
							"group by i_manufact_id, d_qoy ) tmp1\r\n",
							"where case when avg_quarterly_sales > 0 \r\n",
							"\tthen abs (sum_sales - avg_quarterly_sales)/ avg_quarterly_sales \r\n",
							"\telse null end > 0.1\r\n",
							"order by avg_quarterly_sales,\r\n",
							"\t sum_sales,\r\n",
							"\t i_manufact_id\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query54\r\n",
							" with my_customers as (\r\n",
							" select distinct c_customer_sk\r\n",
							"        , c_current_addr_sk\r\n",
							" from   \r\n",
							"        ( select cs_sold_date_sk sold_date_sk,\r\n",
							"                 cs_bill_customer_sk customer_sk,\r\n",
							"                 cs_item_sk item_sk\r\n",
							"          from   catalog_sales\r\n",
							"          union all\r\n",
							"          select ws_sold_date_sk sold_date_sk,\r\n",
							"                 ws_bill_customer_sk customer_sk,\r\n",
							"                 ws_item_sk item_sk\r\n",
							"          from   web_sales\r\n",
							"         ) cs_or_ws_sales,\r\n",
							"         item,\r\n",
							"         date_dim,\r\n",
							"         customer\r\n",
							" where   sold_date_sk = d_date_sk\r\n",
							"         and item_sk = i_item_sk\r\n",
							"         and i_category = 'Women'\r\n",
							"         and i_class = 'maternity'\r\n",
							"         and c_customer_sk = cs_or_ws_sales.customer_sk\r\n",
							"         and d_moy = 12\r\n",
							"         and d_year = 1998\r\n",
							" )\r\n",
							" , my_revenue as (\r\n",
							" select c_customer_sk,\r\n",
							"        sum(ss_ext_sales_price) as revenue\r\n",
							" from   my_customers,\r\n",
							"        store_sales,\r\n",
							"        customer_address,\r\n",
							"        store,\r\n",
							"        date_dim\r\n",
							" where  c_current_addr_sk = ca_address_sk\r\n",
							"        and ca_county = s_county\r\n",
							"        and ca_state = s_state\r\n",
							"        and ss_sold_date_sk = d_date_sk\r\n",
							"        and c_customer_sk = ss_customer_sk\r\n",
							"        and d_month_seq between (select distinct d_month_seq+1\r\n",
							"                                 from   date_dim where d_year = 1998 and d_moy = 12)\r\n",
							"                           and  (select distinct d_month_seq+3\r\n",
							"                                 from   date_dim where d_year = 1998 and d_moy = 12)\r\n",
							" group by c_customer_sk\r\n",
							" )\r\n",
							" , segments as\r\n",
							" (select cast((revenue/50) as int) as segment\r\n",
							"  from   my_revenue\r\n",
							" )\r\n",
							"  select  segment, count(*) as num_customers, segment*50 as segment_base\r\n",
							" from segments\r\n",
							" group by segment\r\n",
							" order by segment, num_customers\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query55\r\n",
							"  select  i_brand_id brand_id, i_brand brand,\r\n",
							" \tsum(ss_ext_sales_price) ext_price\r\n",
							" from date_dim, store_sales, item\r\n",
							" where d_date_sk = ss_sold_date_sk\r\n",
							" \tand ss_item_sk = i_item_sk\r\n",
							" \tand i_manager_id=28\r\n",
							" \tand d_moy=11\r\n",
							" \tand d_year=1999\r\n",
							" group by i_brand, i_brand_id\r\n",
							" order by ext_price desc, i_brand_id\r\n",
							" limit 100 ;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query56\r\n",
							" with ss as (\r\n",
							" select i_item_id,sum(ss_ext_sales_price) total_sales\r\n",
							" from\r\n",
							" \tstore_sales,\r\n",
							" \tdate_dim,\r\n",
							"         customer_address,\r\n",
							"         item\r\n",
							" where i_item_id in (select\r\n",
							"     i_item_id\r\n",
							"from item\r\n",
							"where i_color in ('slate','blanched','burnished'))\r\n",
							" and     ss_item_sk              = i_item_sk\r\n",
							" and     ss_sold_date_sk         = d_date_sk\r\n",
							" and     d_year                  = 2001\r\n",
							" and     d_moy                   = 2\r\n",
							" and     ss_addr_sk              = ca_address_sk\r\n",
							" and     ca_gmt_offset           = -5 \r\n",
							" group by i_item_id),\r\n",
							" cs as (\r\n",
							" select i_item_id,sum(cs_ext_sales_price) total_sales\r\n",
							" from\r\n",
							" \tcatalog_sales,\r\n",
							" \tdate_dim,\r\n",
							"         customer_address,\r\n",
							"         item\r\n",
							" where\r\n",
							"         i_item_id               in (select\r\n",
							"  i_item_id\r\n",
							"from item\r\n",
							"where i_color in ('slate','blanched','burnished'))\r\n",
							" and     cs_item_sk              = i_item_sk\r\n",
							" and     cs_sold_date_sk         = d_date_sk\r\n",
							" and     d_year                  = 2001\r\n",
							" and     d_moy                   = 2\r\n",
							" and     cs_bill_addr_sk         = ca_address_sk\r\n",
							" and     ca_gmt_offset           = -5 \r\n",
							" group by i_item_id),\r\n",
							" ws as (\r\n",
							" select i_item_id,sum(ws_ext_sales_price) total_sales\r\n",
							" from\r\n",
							" \tweb_sales,\r\n",
							" \tdate_dim,\r\n",
							"         customer_address,\r\n",
							"         item\r\n",
							" where\r\n",
							"         i_item_id               in (select\r\n",
							"  i_item_id\r\n",
							"from item\r\n",
							"where i_color in ('slate','blanched','burnished'))\r\n",
							" and     ws_item_sk              = i_item_sk\r\n",
							" and     ws_sold_date_sk         = d_date_sk\r\n",
							" and     d_year                  = 2001\r\n",
							" and     d_moy                   = 2\r\n",
							" and     ws_bill_addr_sk         = ca_address_sk\r\n",
							" and     ca_gmt_offset           = -5\r\n",
							" group by i_item_id)\r\n",
							"  select  i_item_id ,sum(total_sales) total_sales\r\n",
							" from  (select * from ss \r\n",
							"        union all\r\n",
							"        select * from cs \r\n",
							"        union all\r\n",
							"        select * from ws) tmp1\r\n",
							" group by i_item_id\r\n",
							" order by total_sales\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query57\r\n",
							" with v1 as(\r\n",
							" select i_category, i_brand,\r\n",
							"        cc_name,\r\n",
							"        d_year, d_moy,\r\n",
							"        sum(cs_sales_price) sum_sales,\r\n",
							"        avg(sum(cs_sales_price)) over\r\n",
							"          (partition by i_category, i_brand,\r\n",
							"                     cc_name, d_year)\r\n",
							"          avg_monthly_sales,\r\n",
							"        rank() over\r\n",
							"          (partition by i_category, i_brand,\r\n",
							"                     cc_name\r\n",
							"           order by d_year, d_moy) rn\r\n",
							" from item, catalog_sales, date_dim, call_center\r\n",
							" where cs_item_sk = i_item_sk and\r\n",
							"       cs_sold_date_sk = d_date_sk and\r\n",
							"       cc_call_center_sk= cs_call_center_sk and\r\n",
							"       (\r\n",
							"         d_year = 1999 or\r\n",
							"         ( d_year = 1999-1 and d_moy =12) or\r\n",
							"         ( d_year = 1999+1 and d_moy =1)\r\n",
							"       )\r\n",
							" group by i_category, i_brand,\r\n",
							"          cc_name , d_year, d_moy),\r\n",
							" v2 as(\r\n",
							" select v1.i_category, v1.i_brand, v1.cc_name\r\n",
							"        ,v1.d_year, v1.d_moy\r\n",
							"        ,v1.avg_monthly_sales\r\n",
							"        ,v1.sum_sales, v1_lag.sum_sales psum, v1_lead.sum_sales nsum\r\n",
							" from v1, v1 v1_lag, v1 v1_lead\r\n",
							" where v1.i_category = v1_lag.i_category and\r\n",
							"       v1.i_category = v1_lead.i_category and\r\n",
							"       v1.i_brand = v1_lag.i_brand and\r\n",
							"       v1.i_brand = v1_lead.i_brand and\r\n",
							"       v1. cc_name = v1_lag. cc_name and\r\n",
							"       v1. cc_name = v1_lead. cc_name and\r\n",
							"       v1.rn = v1_lag.rn + 1 and\r\n",
							"       v1.rn = v1_lead.rn - 1)\r\n",
							"  select  *\r\n",
							" from v2\r\n",
							" where  d_year = 1999 and\r\n",
							"        avg_monthly_sales > 0 and\r\n",
							"        case when avg_monthly_sales > 0 then abs(sum_sales - avg_monthly_sales) / avg_monthly_sales else null end > 0.1\r\n",
							" order by sum_sales - avg_monthly_sales, 3\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query58\r\n",
							" with ss_items as\r\n",
							" (select i_item_id item_id\r\n",
							"        ,sum(ss_ext_sales_price) ss_item_rev \r\n",
							" from store_sales\r\n",
							"     ,item\r\n",
							"     ,date_dim\r\n",
							" where ss_item_sk = i_item_sk\r\n",
							"   and d_date in (select d_date\r\n",
							"                  from date_dim\r\n",
							"                  where d_week_seq = (select d_week_seq \r\n",
							"                                      from date_dim\r\n",
							"                                      where d_date = '2000-01-03'))\r\n",
							"   and ss_sold_date_sk   = d_date_sk\r\n",
							" group by i_item_id),\r\n",
							" cs_items as\r\n",
							" (select i_item_id item_id\r\n",
							"        ,sum(cs_ext_sales_price) cs_item_rev\r\n",
							"  from catalog_sales\r\n",
							"      ,item\r\n",
							"      ,date_dim\r\n",
							" where cs_item_sk = i_item_sk\r\n",
							"  and  d_date in (select d_date\r\n",
							"                  from date_dim\r\n",
							"                  where d_week_seq = (select d_week_seq \r\n",
							"                                      from date_dim\r\n",
							"                                      where d_date = '2000-01-03'))\r\n",
							"  and  cs_sold_date_sk = d_date_sk\r\n",
							" group by i_item_id),\r\n",
							" ws_items as\r\n",
							" (select i_item_id item_id\r\n",
							"        ,sum(ws_ext_sales_price) ws_item_rev\r\n",
							"  from web_sales\r\n",
							"      ,item\r\n",
							"      ,date_dim\r\n",
							" where ws_item_sk = i_item_sk\r\n",
							"  and  d_date in (select d_date\r\n",
							"                  from date_dim\r\n",
							"                  where d_week_seq =(select d_week_seq \r\n",
							"                                     from date_dim\r\n",
							"                                     where d_date = '2000-01-03'))\r\n",
							"  and ws_sold_date_sk   = d_date_sk\r\n",
							" group by i_item_id)\r\n",
							"  select  ss_items.item_id\r\n",
							"       ,ss_item_rev\r\n",
							"       ,ss_item_rev/((ss_item_rev+cs_item_rev+ws_item_rev)/3) * 100 ss_dev\r\n",
							"       ,cs_item_rev\r\n",
							"       ,cs_item_rev/((ss_item_rev+cs_item_rev+ws_item_rev)/3) * 100 cs_dev\r\n",
							"       ,ws_item_rev\r\n",
							"       ,ws_item_rev/((ss_item_rev+cs_item_rev+ws_item_rev)/3) * 100 ws_dev\r\n",
							"       ,(ss_item_rev+cs_item_rev+ws_item_rev)/3 average\r\n",
							" from ss_items,cs_items,ws_items\r\n",
							" where ss_items.item_id=cs_items.item_id\r\n",
							"   and ss_items.item_id=ws_items.item_id \r\n",
							"   and ss_item_rev between 0.9 * cs_item_rev and 1.1 * cs_item_rev\r\n",
							"   and ss_item_rev between 0.9 * ws_item_rev and 1.1 * ws_item_rev\r\n",
							"   and cs_item_rev between 0.9 * ss_item_rev and 1.1 * ss_item_rev\r\n",
							"   and cs_item_rev between 0.9 * ws_item_rev and 1.1 * ws_item_rev\r\n",
							"   and ws_item_rev between 0.9 * ss_item_rev and 1.1 * ss_item_rev\r\n",
							"   and ws_item_rev between 0.9 * cs_item_rev and 1.1 * cs_item_rev\r\n",
							" order by item_id\r\n",
							"         ,ss_item_rev\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query59\r\n",
							" with wss as \r\n",
							" (select d_week_seq,\r\n",
							"        ss_store_sk,\r\n",
							"        sum(case when (d_day_name='Sunday') then ss_sales_price else null end) sun_sales,\r\n",
							"        sum(case when (d_day_name='Monday') then ss_sales_price else null end) mon_sales,\r\n",
							"        sum(case when (d_day_name='Tuesday') then ss_sales_price else  null end) tue_sales,\r\n",
							"        sum(case when (d_day_name='Wednesday') then ss_sales_price else null end) wed_sales,\r\n",
							"        sum(case when (d_day_name='Thursday') then ss_sales_price else null end) thu_sales,\r\n",
							"        sum(case when (d_day_name='Friday') then ss_sales_price else null end) fri_sales,\r\n",
							"        sum(case when (d_day_name='Saturday') then ss_sales_price else null end) sat_sales\r\n",
							" from store_sales,date_dim\r\n",
							" where d_date_sk = ss_sold_date_sk\r\n",
							" group by d_week_seq,ss_store_sk\r\n",
							" )\r\n",
							"  select  s_store_name1,s_store_id1,d_week_seq1\r\n",
							"       ,sun_sales1/sun_sales2,mon_sales1/mon_sales2\r\n",
							"       ,tue_sales1/tue_sales2,wed_sales1/wed_sales2,thu_sales1/thu_sales2\r\n",
							"       ,fri_sales1/fri_sales2,sat_sales1/sat_sales2\r\n",
							" from\r\n",
							" (select s_store_name s_store_name1,wss.d_week_seq d_week_seq1\r\n",
							"        ,s_store_id s_store_id1,sun_sales sun_sales1\r\n",
							"        ,mon_sales mon_sales1,tue_sales tue_sales1\r\n",
							"        ,wed_sales wed_sales1,thu_sales thu_sales1\r\n",
							"        ,fri_sales fri_sales1,sat_sales sat_sales1\r\n",
							"  from wss,store,date_dim d\r\n",
							"  where d.d_week_seq = wss.d_week_seq and\r\n",
							"        ss_store_sk = s_store_sk and \r\n",
							"        d_month_seq between 1212 and 1212 + 11) y,\r\n",
							" (select s_store_name s_store_name2,wss.d_week_seq d_week_seq2\r\n",
							"        ,s_store_id s_store_id2,sun_sales sun_sales2\r\n",
							"        ,mon_sales mon_sales2,tue_sales tue_sales2\r\n",
							"        ,wed_sales wed_sales2,thu_sales thu_sales2\r\n",
							"        ,fri_sales fri_sales2,sat_sales sat_sales2\r\n",
							"  from wss,store,date_dim d\r\n",
							"  where d.d_week_seq = wss.d_week_seq and\r\n",
							"        ss_store_sk = s_store_sk and \r\n",
							"        d_month_seq between 1212+ 12 and 1212 + 23) x\r\n",
							" where s_store_id1=s_store_id2\r\n",
							"   and d_week_seq1=d_week_seq2-52\r\n",
							" order by s_store_name1,s_store_id1,d_week_seq1\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query60\r\n",
							" with ss as (\r\n",
							" select\r\n",
							"          i_item_id,sum(ss_ext_sales_price) total_sales\r\n",
							" from\r\n",
							" \tstore_sales,\r\n",
							" \tdate_dim,\r\n",
							"         customer_address,\r\n",
							"         item\r\n",
							" where\r\n",
							"         i_item_id in (select\r\n",
							"  i_item_id\r\n",
							"from\r\n",
							" item\r\n",
							"where i_category in ('Music'))\r\n",
							" and     ss_item_sk              = i_item_sk\r\n",
							" and     ss_sold_date_sk         = d_date_sk\r\n",
							" and     d_year                  = 1998\r\n",
							" and     d_moy                   = 9\r\n",
							" and     ss_addr_sk              = ca_address_sk\r\n",
							" and     ca_gmt_offset           = -5 \r\n",
							" group by i_item_id),\r\n",
							" cs as (\r\n",
							" select\r\n",
							"          i_item_id,sum(cs_ext_sales_price) total_sales\r\n",
							" from\r\n",
							" \tcatalog_sales,\r\n",
							" \tdate_dim,\r\n",
							"         customer_address,\r\n",
							"         item\r\n",
							" where\r\n",
							"         i_item_id               in (select\r\n",
							"  i_item_id\r\n",
							"from\r\n",
							" item\r\n",
							"where i_category in ('Music'))\r\n",
							" and     cs_item_sk              = i_item_sk\r\n",
							" and     cs_sold_date_sk         = d_date_sk\r\n",
							" and     d_year                  = 1998\r\n",
							" and     d_moy                   = 9\r\n",
							" and     cs_bill_addr_sk         = ca_address_sk\r\n",
							" and     ca_gmt_offset           = -5 \r\n",
							" group by i_item_id),\r\n",
							" ws as (\r\n",
							" select\r\n",
							"          i_item_id,sum(ws_ext_sales_price) total_sales\r\n",
							" from\r\n",
							" \tweb_sales,\r\n",
							" \tdate_dim,\r\n",
							"         customer_address,\r\n",
							"         item\r\n",
							" where\r\n",
							"         i_item_id               in (select\r\n",
							"  i_item_id\r\n",
							"from\r\n",
							" item\r\n",
							"where i_category in ('Music'))\r\n",
							" and     ws_item_sk              = i_item_sk\r\n",
							" and     ws_sold_date_sk         = d_date_sk\r\n",
							" and     d_year                  = 1998\r\n",
							" and     d_moy                   = 9\r\n",
							" and     ws_bill_addr_sk         = ca_address_sk\r\n",
							" and     ca_gmt_offset           = -5\r\n",
							" group by i_item_id)\r\n",
							"  select   \r\n",
							"  i_item_id\r\n",
							",sum(total_sales) total_sales\r\n",
							" from  (select * from ss \r\n",
							"        union all\r\n",
							"        select * from cs \r\n",
							"        union all\r\n",
							"        select * from ws) tmp1\r\n",
							" group by i_item_id\r\n",
							" order by i_item_id\r\n",
							"      ,total_sales\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query61\r\n",
							" select  promotions,total,cast(promotions as decimal(15,4))/cast(total as decimal(15,4))*100\r\n",
							"from\r\n",
							"  (select sum(ss_ext_sales_price) promotions\r\n",
							"   from  store_sales\r\n",
							"        ,store\r\n",
							"        ,promotion\r\n",
							"        ,date_dim\r\n",
							"        ,customer\r\n",
							"        ,customer_address \r\n",
							"        ,item\r\n",
							"   where ss_sold_date_sk = d_date_sk\r\n",
							"   and   ss_store_sk = s_store_sk\r\n",
							"   and   ss_promo_sk = p_promo_sk\r\n",
							"   and   ss_customer_sk= c_customer_sk\r\n",
							"   and   ca_address_sk = c_current_addr_sk\r\n",
							"   and   ss_item_sk = i_item_sk \r\n",
							"   and   ca_gmt_offset = -5\r\n",
							"   and   i_category = 'Jewelry'\r\n",
							"   and   (p_channel_dmail = 'Y' or p_channel_email = 'Y' or p_channel_tv = 'Y')\r\n",
							"   and   s_gmt_offset = -5\r\n",
							"   and   d_year = 1998\r\n",
							"   and   d_moy  = 11) promotional_sales,\r\n",
							"  (select sum(ss_ext_sales_price) total\r\n",
							"   from  store_sales\r\n",
							"        ,store\r\n",
							"        ,date_dim\r\n",
							"        ,customer\r\n",
							"        ,customer_address\r\n",
							"        ,item\r\n",
							"   where ss_sold_date_sk = d_date_sk\r\n",
							"   and   ss_store_sk = s_store_sk\r\n",
							"   and   ss_customer_sk= c_customer_sk\r\n",
							"   and   ca_address_sk = c_current_addr_sk\r\n",
							"   and   ss_item_sk = i_item_sk\r\n",
							"   and   ca_gmt_offset = -5\r\n",
							"   and   i_category = 'Jewelry'\r\n",
							"   and   s_gmt_offset = -5\r\n",
							"   and   d_year = 1998\r\n",
							"   and   d_moy  = 11) all_sales\r\n",
							"order by promotions, total\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query62\r\n",
							" select  \r\n",
							"   substr(w_warehouse_name,1,20)\r\n",
							"  ,sm_type\r\n",
							"  ,web_name\r\n",
							"  ,sum(case when (ws_ship_date_sk - ws_sold_date_sk <= 30 ) then 1 else 0 end)  as 30_days \r\n",
							"  ,sum(case when (ws_ship_date_sk - ws_sold_date_sk > 30) and \r\n",
							"                 (ws_ship_date_sk - ws_sold_date_sk <= 60) then 1 else 0 end )  as 31_60_days \r\n",
							"  ,sum(case when (ws_ship_date_sk - ws_sold_date_sk > 60) and \r\n",
							"                 (ws_ship_date_sk - ws_sold_date_sk <= 90) then 1 else 0 end)  as 61_90_days \r\n",
							"  ,sum(case when (ws_ship_date_sk - ws_sold_date_sk > 90) and\r\n",
							"                 (ws_ship_date_sk - ws_sold_date_sk <= 120) then 1 else 0 end)  as 91_120_days\r\n",
							"  ,sum(case when (ws_ship_date_sk - ws_sold_date_sk  > 120) then 1 else 0 end)  as above120_days\r\n",
							"from\r\n",
							"   web_sales\r\n",
							"  ,warehouse\r\n",
							"  ,ship_mode\r\n",
							"  ,web_site\r\n",
							"  ,date_dim\r\n",
							"where\r\n",
							"    d_month_seq between 1200 and 1200 + 11\r\n",
							"and ws_ship_date_sk   = d_date_sk\r\n",
							"and ws_warehouse_sk   = w_warehouse_sk\r\n",
							"and ws_ship_mode_sk   = sm_ship_mode_sk\r\n",
							"and ws_web_site_sk    = web_site_sk\r\n",
							"group by\r\n",
							"   substr(w_warehouse_name,1,20)\r\n",
							"  ,sm_type\r\n",
							"  ,web_name\r\n",
							"order by substr(w_warehouse_name,1,20)\r\n",
							"        ,sm_type\r\n",
							"       ,web_name\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query63\r\n",
							" select  * \r\n",
							"from (select i_manager_id\r\n",
							"             ,sum(ss_sales_price) sum_sales\r\n",
							"             ,avg(sum(ss_sales_price)) over (partition by i_manager_id) avg_monthly_sales\r\n",
							"      from item\r\n",
							"          ,store_sales\r\n",
							"          ,date_dim\r\n",
							"          ,store\r\n",
							"      where ss_item_sk = i_item_sk\r\n",
							"        and ss_sold_date_sk = d_date_sk\r\n",
							"        and ss_store_sk = s_store_sk\r\n",
							"        and d_month_seq in (1200,1200+1,1200+2,1200+3,1200+4,1200+5,1200+6,1200+7,1200+8,1200+9,1200+10,1200+11)\r\n",
							"        and ((    i_category in ('Books','Children','Electronics')\r\n",
							"              and i_class in ('personal','portable','reference','self-help')\r\n",
							"              and i_brand in ('scholaramalgamalg #14','scholaramalgamalg #7',\r\n",
							"\t\t                  'exportiunivamalg #9','scholaramalgamalg #9'))\r\n",
							"           or(    i_category in ('Women','Music','Men')\r\n",
							"              and i_class in ('accessories','classical','fragrances','pants')\r\n",
							"              and i_brand in ('amalgimporto #1','edu packscholar #1','exportiimporto #1',\r\n",
							"\t\t                 'importoamalg #1')))\r\n",
							"group by i_manager_id, d_moy) tmp1\r\n",
							"where case when avg_monthly_sales > 0 then abs (sum_sales - avg_monthly_sales) / avg_monthly_sales else null end > 0.1\r\n",
							"order by i_manager_id\r\n",
							"        ,avg_monthly_sales\r\n",
							"        ,sum_sales\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query64\r\n",
							"with cs_ui as\r\n",
							" (select cs_item_sk\r\n",
							"        ,sum(cs_ext_list_price) as sale,sum(cr_refunded_cash+cr_reversed_charge+cr_store_credit) as refund\r\n",
							"  from catalog_sales\r\n",
							"      ,catalog_returns\r\n",
							"  where cs_item_sk = cr_item_sk\r\n",
							"    and cs_order_number = cr_order_number\r\n",
							"  group by cs_item_sk\r\n",
							"  having sum(cs_ext_list_price)>2*sum(cr_refunded_cash+cr_reversed_charge+cr_store_credit)),\r\n",
							"cross_sales as\r\n",
							" (select i_product_name product_name\r\n",
							"     ,i_item_sk item_sk\r\n",
							"     ,s_store_name store_name\r\n",
							"     ,s_zip store_zip\r\n",
							"     ,ad1.ca_street_number b_street_number\r\n",
							"     ,ad1.ca_street_name b_street_name\r\n",
							"     ,ad1.ca_city b_city\r\n",
							"     ,ad1.ca_zip b_zip\r\n",
							"     ,ad2.ca_street_number c_street_number\r\n",
							"     ,ad2.ca_street_name c_street_name\r\n",
							"     ,ad2.ca_city c_city\r\n",
							"     ,ad2.ca_zip c_zip\r\n",
							"     ,d1.d_year as syear\r\n",
							"     ,d2.d_year as fsyear\r\n",
							"     ,d3.d_year s2year\r\n",
							"     ,count(*) cnt\r\n",
							"     ,sum(ss_wholesale_cost) s1\r\n",
							"     ,sum(ss_list_price) s2\r\n",
							"     ,sum(ss_coupon_amt) s3\r\n",
							"  FROM   store_sales\r\n",
							"        ,store_returns\r\n",
							"        ,cs_ui\r\n",
							"        ,date_dim d1\r\n",
							"        ,date_dim d2\r\n",
							"        ,date_dim d3\r\n",
							"        ,store\r\n",
							"        ,customer\r\n",
							"        ,customer_demographics cd1\r\n",
							"        ,customer_demographics cd2\r\n",
							"        ,promotion\r\n",
							"        ,household_demographics hd1\r\n",
							"        ,household_demographics hd2\r\n",
							"        ,customer_address ad1\r\n",
							"        ,customer_address ad2\r\n",
							"        ,income_band ib1\r\n",
							"        ,income_band ib2\r\n",
							"        ,item\r\n",
							"  WHERE  ss_store_sk = s_store_sk AND\r\n",
							"         ss_sold_date_sk = d1.d_date_sk AND\r\n",
							"         ss_customer_sk = c_customer_sk AND\r\n",
							"         ss_cdemo_sk= cd1.cd_demo_sk AND\r\n",
							"         ss_hdemo_sk = hd1.hd_demo_sk AND\r\n",
							"         ss_addr_sk = ad1.ca_address_sk and\r\n",
							"         ss_item_sk = i_item_sk and\r\n",
							"         ss_item_sk = sr_item_sk and\r\n",
							"         ss_ticket_number = sr_ticket_number and\r\n",
							"         ss_item_sk = cs_ui.cs_item_sk and\r\n",
							"         c_current_cdemo_sk = cd2.cd_demo_sk AND\r\n",
							"         c_current_hdemo_sk = hd2.hd_demo_sk AND\r\n",
							"         c_current_addr_sk = ad2.ca_address_sk and\r\n",
							"         c_first_sales_date_sk = d2.d_date_sk and\r\n",
							"         c_first_shipto_date_sk = d3.d_date_sk and\r\n",
							"         ss_promo_sk = p_promo_sk and\r\n",
							"         hd1.hd_income_band_sk = ib1.ib_income_band_sk and\r\n",
							"         hd2.hd_income_band_sk = ib2.ib_income_band_sk and\r\n",
							"         cd1.cd_marital_status <> cd2.cd_marital_status and\r\n",
							"         i_color in ('purple','burlywood','indian','spring','floral','medium') and\r\n",
							"         i_current_price between 64 and 64 + 10 and\r\n",
							"         i_current_price between 64 + 1 and 64 + 15\r\n",
							"group by i_product_name\r\n",
							"       ,i_item_sk\r\n",
							"       ,s_store_name\r\n",
							"       ,s_zip\r\n",
							"       ,ad1.ca_street_number\r\n",
							"       ,ad1.ca_street_name\r\n",
							"       ,ad1.ca_city\r\n",
							"       ,ad1.ca_zip\r\n",
							"       ,ad2.ca_street_number\r\n",
							"       ,ad2.ca_street_name\r\n",
							"       ,ad2.ca_city\r\n",
							"       ,ad2.ca_zip\r\n",
							"       ,d1.d_year\r\n",
							"       ,d2.d_year\r\n",
							"       ,d3.d_year\r\n",
							")\r\n",
							"select cs1.product_name\r\n",
							"     ,cs1.store_name\r\n",
							"     ,cs1.store_zip\r\n",
							"     ,cs1.b_street_number\r\n",
							"     ,cs1.b_street_name\r\n",
							"     ,cs1.b_city\r\n",
							"     ,cs1.b_zip\r\n",
							"     ,cs1.c_street_number\r\n",
							"     ,cs1.c_street_name\r\n",
							"     ,cs1.c_city\r\n",
							"     ,cs1.c_zip\r\n",
							"     ,cs1.syear\r\n",
							"     ,cs1.cnt\r\n",
							"     ,cs1.s1 as s11\r\n",
							"     ,cs1.s2 as s21\r\n",
							"     ,cs1.s3 as s31\r\n",
							"     ,cs2.s1 as s12\r\n",
							"     ,cs2.s2 as s22\r\n",
							"     ,cs2.s3 as s32\r\n",
							"     ,cs2.syear as syear_2\r\n",
							"     ,cs2.cnt as cnt_2\r\n",
							"from cross_sales cs1,cross_sales cs2\r\n",
							"where cs1.item_sk=cs2.item_sk and\r\n",
							"     cs1.syear = 1999 and\r\n",
							"     cs2.syear = 1999 + 1 and\r\n",
							"     cs2.cnt <= cs1.cnt and\r\n",
							"     cs1.store_name = cs2.store_name and\r\n",
							"     cs1.store_zip = cs2.store_zip\r\n",
							"order by cs1.product_name\r\n",
							"       ,cs1.store_name\r\n",
							"       ,cnt_2;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query65\r\n",
							"  select \r\n",
							"\ts_store_name,\r\n",
							"\ti_item_desc,\r\n",
							"\tsc.revenue,\r\n",
							"\ti_current_price,\r\n",
							"\ti_wholesale_cost,\r\n",
							"\ti_brand\r\n",
							" from store, item,\r\n",
							"     (select ss_store_sk, avg(revenue) as ave\r\n",
							" \tfrom\r\n",
							" \t    (select  ss_store_sk, ss_item_sk, \r\n",
							" \t\t     sum(ss_sales_price) as revenue\r\n",
							" \t\tfrom store_sales, date_dim\r\n",
							" \t\twhere ss_sold_date_sk = d_date_sk and d_month_seq between 1176 and 1176+11\r\n",
							" \t\tgroup by ss_store_sk, ss_item_sk) sa\r\n",
							" \tgroup by ss_store_sk) sb,\r\n",
							"     (select  ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue\r\n",
							" \tfrom store_sales, date_dim\r\n",
							" \twhere ss_sold_date_sk = d_date_sk and d_month_seq between 1176 and 1176+11\r\n",
							" \tgroup by ss_store_sk, ss_item_sk) sc\r\n",
							" where sb.ss_store_sk = sc.ss_store_sk and \r\n",
							"       sc.revenue <= 0.1 * sb.ave and\r\n",
							"       s_store_sk = sc.ss_store_sk and\r\n",
							"       i_item_sk = sc.ss_item_sk\r\n",
							" order by s_store_name, i_item_desc\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query66\r\n",
							"  select   \r\n",
							"         w_warehouse_name\r\n",
							" \t,w_warehouse_sq_ft\r\n",
							" \t,w_city\r\n",
							" \t,w_county\r\n",
							" \t,w_state\r\n",
							" \t,w_country\r\n",
							"        ,ship_carriers\r\n",
							"        ,year\r\n",
							" \t,sum(jan_sales) as jan_sales\r\n",
							" \t,sum(feb_sales) as feb_sales\r\n",
							" \t,sum(mar_sales) as mar_sales\r\n",
							" \t,sum(apr_sales) as apr_sales\r\n",
							" \t,sum(may_sales) as may_sales\r\n",
							" \t,sum(jun_sales) as jun_sales\r\n",
							" \t,sum(jul_sales) as jul_sales\r\n",
							" \t,sum(aug_sales) as aug_sales\r\n",
							" \t,sum(sep_sales) as sep_sales\r\n",
							" \t,sum(oct_sales) as oct_sales\r\n",
							" \t,sum(nov_sales) as nov_sales\r\n",
							" \t,sum(dec_sales) as dec_sales\r\n",
							" \t,sum(jan_sales/w_warehouse_sq_ft) as jan_sales_per_sq_foot\r\n",
							" \t,sum(feb_sales/w_warehouse_sq_ft) as feb_sales_per_sq_foot\r\n",
							" \t,sum(mar_sales/w_warehouse_sq_ft) as mar_sales_per_sq_foot\r\n",
							" \t,sum(apr_sales/w_warehouse_sq_ft) as apr_sales_per_sq_foot\r\n",
							" \t,sum(may_sales/w_warehouse_sq_ft) as may_sales_per_sq_foot\r\n",
							" \t,sum(jun_sales/w_warehouse_sq_ft) as jun_sales_per_sq_foot\r\n",
							" \t,sum(jul_sales/w_warehouse_sq_ft) as jul_sales_per_sq_foot\r\n",
							" \t,sum(aug_sales/w_warehouse_sq_ft) as aug_sales_per_sq_foot\r\n",
							" \t,sum(sep_sales/w_warehouse_sq_ft) as sep_sales_per_sq_foot\r\n",
							" \t,sum(oct_sales/w_warehouse_sq_ft) as oct_sales_per_sq_foot\r\n",
							" \t,sum(nov_sales/w_warehouse_sq_ft) as nov_sales_per_sq_foot\r\n",
							" \t,sum(dec_sales/w_warehouse_sq_ft) as dec_sales_per_sq_foot\r\n",
							" \t,sum(jan_net) as jan_net\r\n",
							" \t,sum(feb_net) as feb_net\r\n",
							" \t,sum(mar_net) as mar_net\r\n",
							" \t,sum(apr_net) as apr_net\r\n",
							" \t,sum(may_net) as may_net\r\n",
							" \t,sum(jun_net) as jun_net\r\n",
							" \t,sum(jul_net) as jul_net\r\n",
							" \t,sum(aug_net) as aug_net\r\n",
							" \t,sum(sep_net) as sep_net\r\n",
							" \t,sum(oct_net) as oct_net\r\n",
							" \t,sum(nov_net) as nov_net\r\n",
							" \t,sum(dec_net) as dec_net\r\n",
							" from (\r\n",
							"     select \r\n",
							" \tw_warehouse_name\r\n",
							" \t,w_warehouse_sq_ft\r\n",
							" \t,w_city\r\n",
							" \t,w_county\r\n",
							" \t,w_state\r\n",
							" \t,w_country\r\n",
							" \t,concat('DHL' , ',' , 'BARIAN') as ship_carriers\r\n",
							"       ,d_year as year\r\n",
							" \t,sum(case when d_moy = 1 \r\n",
							" \t\tthen ws_ext_sales_price* ws_quantity else 0 end) as jan_sales\r\n",
							" \t,sum(case when d_moy = 2 \r\n",
							" \t\tthen ws_ext_sales_price* ws_quantity else 0 end) as feb_sales\r\n",
							" \t,sum(case when d_moy = 3 \r\n",
							" \t\tthen ws_ext_sales_price* ws_quantity else 0 end) as mar_sales\r\n",
							" \t,sum(case when d_moy = 4 \r\n",
							" \t\tthen ws_ext_sales_price* ws_quantity else 0 end) as apr_sales\r\n",
							" \t,sum(case when d_moy = 5 \r\n",
							" \t\tthen ws_ext_sales_price* ws_quantity else 0 end) as may_sales\r\n",
							" \t,sum(case when d_moy = 6 \r\n",
							" \t\tthen ws_ext_sales_price* ws_quantity else 0 end) as jun_sales\r\n",
							" \t,sum(case when d_moy = 7 \r\n",
							" \t\tthen ws_ext_sales_price* ws_quantity else 0 end) as jul_sales\r\n",
							" \t,sum(case when d_moy = 8 \r\n",
							" \t\tthen ws_ext_sales_price* ws_quantity else 0 end) as aug_sales\r\n",
							" \t,sum(case when d_moy = 9 \r\n",
							" \t\tthen ws_ext_sales_price* ws_quantity else 0 end) as sep_sales\r\n",
							" \t,sum(case when d_moy = 10 \r\n",
							" \t\tthen ws_ext_sales_price* ws_quantity else 0 end) as oct_sales\r\n",
							" \t,sum(case when d_moy = 11\r\n",
							" \t\tthen ws_ext_sales_price* ws_quantity else 0 end) as nov_sales\r\n",
							" \t,sum(case when d_moy = 12\r\n",
							" \t\tthen ws_ext_sales_price* ws_quantity else 0 end) as dec_sales\r\n",
							" \t,sum(case when d_moy = 1 \r\n",
							" \t\tthen ws_net_paid * ws_quantity else 0 end) as jan_net\r\n",
							" \t,sum(case when d_moy = 2\r\n",
							" \t\tthen ws_net_paid * ws_quantity else 0 end) as feb_net\r\n",
							" \t,sum(case when d_moy = 3 \r\n",
							" \t\tthen ws_net_paid * ws_quantity else 0 end) as mar_net\r\n",
							" \t,sum(case when d_moy = 4 \r\n",
							" \t\tthen ws_net_paid * ws_quantity else 0 end) as apr_net\r\n",
							" \t,sum(case when d_moy = 5 \r\n",
							" \t\tthen ws_net_paid * ws_quantity else 0 end) as may_net\r\n",
							" \t,sum(case when d_moy = 6 \r\n",
							" \t\tthen ws_net_paid * ws_quantity else 0 end) as jun_net\r\n",
							" \t,sum(case when d_moy = 7 \r\n",
							" \t\tthen ws_net_paid * ws_quantity else 0 end) as jul_net\r\n",
							" \t,sum(case when d_moy = 8 \r\n",
							" \t\tthen ws_net_paid * ws_quantity else 0 end) as aug_net\r\n",
							" \t,sum(case when d_moy = 9 \r\n",
							" \t\tthen ws_net_paid * ws_quantity else 0 end) as sep_net\r\n",
							" \t,sum(case when d_moy = 10 \r\n",
							" \t\tthen ws_net_paid * ws_quantity else 0 end) as oct_net\r\n",
							" \t,sum(case when d_moy = 11\r\n",
							" \t\tthen ws_net_paid * ws_quantity else 0 end) as nov_net\r\n",
							" \t,sum(case when d_moy = 12\r\n",
							" \t\tthen ws_net_paid * ws_quantity else 0 end) as dec_net\r\n",
							"     from\r\n",
							"          web_sales\r\n",
							"         ,warehouse\r\n",
							"         ,date_dim\r\n",
							"         ,time_dim\r\n",
							" \t  ,ship_mode\r\n",
							"     where\r\n",
							"            ws_warehouse_sk =  w_warehouse_sk\r\n",
							"        and ws_sold_date_sk = d_date_sk\r\n",
							"        and ws_sold_time_sk = t_time_sk\r\n",
							" \tand ws_ship_mode_sk = sm_ship_mode_sk\r\n",
							"        and d_year = 2001\r\n",
							" \tand t_time between 30838 and 30838+28800 \r\n",
							" \tand sm_carrier in ('DHL','BARIAN')\r\n",
							"     group by \r\n",
							"        w_warehouse_name\r\n",
							" \t,w_warehouse_sq_ft\r\n",
							" \t,w_city\r\n",
							" \t,w_county\r\n",
							" \t,w_state\r\n",
							" \t,w_country\r\n",
							"       ,d_year\r\n",
							" union all\r\n",
							"     select \r\n",
							" \tw_warehouse_name\r\n",
							" \t,w_warehouse_sq_ft\r\n",
							" \t,w_city\r\n",
							" \t,w_county\r\n",
							" \t,w_state\r\n",
							" \t,w_country\r\n",
							" \t,concat('DHL' , ',' , 'BARIAN') as ship_carriers\r\n",
							"       ,d_year as year\r\n",
							" \t,sum(case when d_moy = 1 \r\n",
							" \t\tthen cs_sales_price* cs_quantity else 0 end) as jan_sales\r\n",
							" \t,sum(case when d_moy = 2 \r\n",
							" \t\tthen cs_sales_price* cs_quantity else 0 end) as feb_sales\r\n",
							" \t,sum(case when d_moy = 3 \r\n",
							" \t\tthen cs_sales_price* cs_quantity else 0 end) as mar_sales\r\n",
							" \t,sum(case when d_moy = 4 \r\n",
							" \t\tthen cs_sales_price* cs_quantity else 0 end) as apr_sales\r\n",
							" \t,sum(case when d_moy = 5 \r\n",
							" \t\tthen cs_sales_price* cs_quantity else 0 end) as may_sales\r\n",
							" \t,sum(case when d_moy = 6 \r\n",
							" \t\tthen cs_sales_price* cs_quantity else 0 end) as jun_sales\r\n",
							" \t,sum(case when d_moy = 7 \r\n",
							" \t\tthen cs_sales_price* cs_quantity else 0 end) as jul_sales\r\n",
							" \t,sum(case when d_moy = 8 \r\n",
							" \t\tthen cs_sales_price* cs_quantity else 0 end) as aug_sales\r\n",
							" \t,sum(case when d_moy = 9 \r\n",
							" \t\tthen cs_sales_price* cs_quantity else 0 end) as sep_sales\r\n",
							" \t,sum(case when d_moy = 10 \r\n",
							" \t\tthen cs_sales_price* cs_quantity else 0 end) as oct_sales\r\n",
							" \t,sum(case when d_moy = 11\r\n",
							" \t\tthen cs_sales_price* cs_quantity else 0 end) as nov_sales\r\n",
							" \t,sum(case when d_moy = 12\r\n",
							" \t\tthen cs_sales_price* cs_quantity else 0 end) as dec_sales\r\n",
							" \t,sum(case when d_moy = 1 \r\n",
							" \t\tthen cs_net_paid_inc_tax * cs_quantity else 0 end) as jan_net\r\n",
							" \t,sum(case when d_moy = 2 \r\n",
							" \t\tthen cs_net_paid_inc_tax * cs_quantity else 0 end) as feb_net\r\n",
							" \t,sum(case when d_moy = 3 \r\n",
							" \t\tthen cs_net_paid_inc_tax * cs_quantity else 0 end) as mar_net\r\n",
							" \t,sum(case when d_moy = 4 \r\n",
							" \t\tthen cs_net_paid_inc_tax * cs_quantity else 0 end) as apr_net\r\n",
							" \t,sum(case when d_moy = 5 \r\n",
							" \t\tthen cs_net_paid_inc_tax * cs_quantity else 0 end) as may_net\r\n",
							" \t,sum(case when d_moy = 6 \r\n",
							" \t\tthen cs_net_paid_inc_tax * cs_quantity else 0 end) as jun_net\r\n",
							" \t,sum(case when d_moy = 7 \r\n",
							" \t\tthen cs_net_paid_inc_tax * cs_quantity else 0 end) as jul_net\r\n",
							" \t,sum(case when d_moy = 8 \r\n",
							" \t\tthen cs_net_paid_inc_tax * cs_quantity else 0 end) as aug_net\r\n",
							" \t,sum(case when d_moy = 9 \r\n",
							" \t\tthen cs_net_paid_inc_tax * cs_quantity else 0 end) as sep_net\r\n",
							" \t,sum(case when d_moy = 10 \r\n",
							" \t\tthen cs_net_paid_inc_tax * cs_quantity else 0 end) as oct_net\r\n",
							" \t,sum(case when d_moy = 11\r\n",
							" \t\tthen cs_net_paid_inc_tax * cs_quantity else 0 end) as nov_net\r\n",
							" \t,sum(case when d_moy = 12\r\n",
							" \t\tthen cs_net_paid_inc_tax * cs_quantity else 0 end) as dec_net\r\n",
							"     from\r\n",
							"          catalog_sales\r\n",
							"         ,warehouse\r\n",
							"         ,date_dim\r\n",
							"         ,time_dim\r\n",
							" \t ,ship_mode\r\n",
							"     where\r\n",
							"            cs_warehouse_sk =  w_warehouse_sk\r\n",
							"        and cs_sold_date_sk = d_date_sk\r\n",
							"        and cs_sold_time_sk = t_time_sk\r\n",
							" \tand cs_ship_mode_sk = sm_ship_mode_sk\r\n",
							"        and d_year = 2001\r\n",
							" \tand t_time between 30838 AND 30838+28800 \r\n",
							" \tand sm_carrier in ('DHL','BARIAN')\r\n",
							"     group by \r\n",
							"        w_warehouse_name\r\n",
							" \t,w_warehouse_sq_ft\r\n",
							" \t,w_city\r\n",
							" \t,w_county\r\n",
							" \t,w_state\r\n",
							" \t,w_country\r\n",
							"       ,d_year\r\n",
							" ) x\r\n",
							" group by \r\n",
							"        w_warehouse_name\r\n",
							" \t,w_warehouse_sq_ft\r\n",
							" \t,w_city\r\n",
							" \t,w_county\r\n",
							" \t,w_state\r\n",
							" \t,w_country\r\n",
							" \t,ship_carriers\r\n",
							"       ,year\r\n",
							" order by w_warehouse_name\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query67\r\n",
							" select  *\r\n",
							"from (select i_category\r\n",
							"            ,i_class\r\n",
							"            ,i_brand\r\n",
							"            ,i_product_name\r\n",
							"            ,d_year\r\n",
							"            ,d_qoy\r\n",
							"            ,d_moy\r\n",
							"            ,s_store_id\r\n",
							"            ,sumsales\r\n",
							"            ,rank() over (partition by i_category order by sumsales desc) rk\r\n",
							"      from (select i_category\r\n",
							"                  ,i_class\r\n",
							"                  ,i_brand\r\n",
							"                  ,i_product_name\r\n",
							"                  ,d_year\r\n",
							"                  ,d_qoy\r\n",
							"                  ,d_moy\r\n",
							"                  ,s_store_id\r\n",
							"                  ,sum(coalesce(ss_sales_price*ss_quantity,0)) sumsales\r\n",
							"            from store_sales\r\n",
							"                ,date_dim\r\n",
							"                ,store\r\n",
							"                ,item\r\n",
							"       where  ss_sold_date_sk=d_date_sk\r\n",
							"          and ss_item_sk=i_item_sk\r\n",
							"          and ss_store_sk = s_store_sk\r\n",
							"          and d_month_seq between 1200 and 1200+11\r\n",
							"       group by  rollup(i_category, i_class, i_brand, i_product_name, d_year, d_qoy, d_moy,s_store_id))dw1) dw2\r\n",
							"where rk <= 100\r\n",
							"order by i_category\r\n",
							"        ,i_class\r\n",
							"        ,i_brand\r\n",
							"        ,i_product_name\r\n",
							"        ,d_year\r\n",
							"        ,d_qoy\r\n",
							"        ,d_moy\r\n",
							"        ,s_store_id\r\n",
							"        ,sumsales\r\n",
							"        ,rk\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query68\r\n",
							"  select  c_last_name\r\n",
							"       ,c_first_name\r\n",
							"       ,ca_city\r\n",
							"       ,bought_city\r\n",
							"       ,ss_ticket_number\r\n",
							"       ,extended_price\r\n",
							"       ,extended_tax\r\n",
							"       ,list_price\r\n",
							" from (select ss_ticket_number\r\n",
							"             ,ss_customer_sk\r\n",
							"             ,ca_city bought_city\r\n",
							"             ,sum(ss_ext_sales_price) extended_price \r\n",
							"             ,sum(ss_ext_list_price) list_price\r\n",
							"             ,sum(ss_ext_tax) extended_tax \r\n",
							"       from store_sales\r\n",
							"           ,date_dim\r\n",
							"           ,store\r\n",
							"           ,household_demographics\r\n",
							"           ,customer_address \r\n",
							"       where store_sales.ss_sold_date_sk = date_dim.d_date_sk\r\n",
							"         and store_sales.ss_store_sk = store.s_store_sk  \r\n",
							"        and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk\r\n",
							"        and store_sales.ss_addr_sk = customer_address.ca_address_sk\r\n",
							"        and date_dim.d_dom between 1 and 2 \r\n",
							"        and (household_demographics.hd_dep_count = 4 or\r\n",
							"             household_demographics.hd_vehicle_count= 3)\r\n",
							"        and date_dim.d_year in (1999,1999+1,1999+2)\r\n",
							"        and store.s_city in ('Fairview','Midway')\r\n",
							"       group by ss_ticket_number\r\n",
							"               ,ss_customer_sk\r\n",
							"               ,ss_addr_sk,ca_city) dn\r\n",
							"      ,customer\r\n",
							"      ,customer_address current_addr\r\n",
							" where ss_customer_sk = c_customer_sk\r\n",
							"   and customer.c_current_addr_sk = current_addr.ca_address_sk\r\n",
							"   and current_addr.ca_city <> bought_city\r\n",
							" order by c_last_name\r\n",
							"         ,ss_ticket_number\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query69\r\n",
							"  select  \r\n",
							"  cd_gender,\r\n",
							"  cd_marital_status,\r\n",
							"  cd_education_status,\r\n",
							"  count(*) cnt1,\r\n",
							"  cd_purchase_estimate,\r\n",
							"  count(*) cnt2,\r\n",
							"  cd_credit_rating,\r\n",
							"  count(*) cnt3\r\n",
							" from\r\n",
							"  customer c,customer_address ca,customer_demographics\r\n",
							" where\r\n",
							"  c.c_current_addr_sk = ca.ca_address_sk and\r\n",
							"  ca_state in ('KY','GA','NM') and\r\n",
							"  cd_demo_sk = c.c_current_cdemo_sk and \r\n",
							"  exists (select *\r\n",
							"          from store_sales,date_dim\r\n",
							"          where c.c_customer_sk = ss_customer_sk and\r\n",
							"                ss_sold_date_sk = d_date_sk and\r\n",
							"                d_year = 2001 and\r\n",
							"                d_moy between 4 and 4+2) and\r\n",
							"   (not exists (select *\r\n",
							"            from web_sales,date_dim\r\n",
							"            where c.c_customer_sk = ws_bill_customer_sk and\r\n",
							"                  ws_sold_date_sk = d_date_sk and\r\n",
							"                  d_year = 2001 and\r\n",
							"                  d_moy between 4 and 4+2) and\r\n",
							"    not exists (select * \r\n",
							"            from catalog_sales,date_dim\r\n",
							"            where c.c_customer_sk = cs_ship_customer_sk and\r\n",
							"                  cs_sold_date_sk = d_date_sk and\r\n",
							"                  d_year = 2001 and\r\n",
							"                  d_moy between 4 and 4+2))\r\n",
							" group by cd_gender,\r\n",
							"          cd_marital_status,\r\n",
							"          cd_education_status,\r\n",
							"          cd_purchase_estimate,\r\n",
							"          cd_credit_rating\r\n",
							" order by cd_gender,\r\n",
							"          cd_marital_status,\r\n",
							"          cd_education_status,\r\n",
							"          cd_purchase_estimate,\r\n",
							"          cd_credit_rating\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query70\r\n",
							"  select  \r\n",
							"    sum(ss_net_profit) as total_sum\r\n",
							"   ,s_state\r\n",
							"   ,s_county\r\n",
							"   ,grouping(s_state)+grouping(s_county) as lochierarchy\r\n",
							"   ,rank() over (\r\n",
							" \tpartition by grouping(s_state)+grouping(s_county),\r\n",
							" \tcase when grouping(s_county) = 0 then s_state end \r\n",
							" \torder by sum(ss_net_profit) desc) as rank_within_parent\r\n",
							" from\r\n",
							"    store_sales\r\n",
							"   ,date_dim       d1\r\n",
							"   ,store\r\n",
							" where\r\n",
							"    d1.d_month_seq between 1200 and 1200+11\r\n",
							" and d1.d_date_sk = ss_sold_date_sk\r\n",
							" and s_store_sk  = ss_store_sk\r\n",
							" and s_state in\r\n",
							"             ( select s_state\r\n",
							"               from  (select s_state as s_state,\r\n",
							" \t\t\t    rank() over ( partition by s_state order by sum(ss_net_profit) desc) as ranking\r\n",
							"                      from   store_sales, store, date_dim\r\n",
							"                      where  d_month_seq between 1200 and 1200+11\r\n",
							" \t\t\t    and d_date_sk = ss_sold_date_sk\r\n",
							" \t\t\t    and s_store_sk  = ss_store_sk\r\n",
							"                      group by s_state\r\n",
							"                     ) tmp1 \r\n",
							"               where ranking <= 5\r\n",
							"             )\r\n",
							" group by rollup(s_state,s_county)\r\n",
							" order by\r\n",
							"   lochierarchy desc\r\n",
							"  ,case when lochierarchy = 0 then s_state end\r\n",
							"  ,rank_within_parent\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query71\r\n",
							" select i_brand_id brand_id, i_brand brand,t_hour,t_minute,\r\n",
							" \tsum(ext_price) ext_price\r\n",
							" from item, (select ws_ext_sales_price as ext_price, \r\n",
							"                        ws_sold_date_sk as sold_date_sk,\r\n",
							"                        ws_item_sk as sold_item_sk,\r\n",
							"                        ws_sold_time_sk as time_sk  \r\n",
							"                 from web_sales,date_dim\r\n",
							"                 where d_date_sk = ws_sold_date_sk\r\n",
							"                   and d_moy=11\r\n",
							"                   and d_year=1999\r\n",
							"                 union all\r\n",
							"                 select cs_ext_sales_price as ext_price,\r\n",
							"                        cs_sold_date_sk as sold_date_sk,\r\n",
							"                        cs_item_sk as sold_item_sk,\r\n",
							"                        cs_sold_time_sk as time_sk\r\n",
							"                 from catalog_sales,date_dim\r\n",
							"                 where d_date_sk = cs_sold_date_sk\r\n",
							"                   and d_moy=11\r\n",
							"                   and d_year=1999\r\n",
							"                 union all\r\n",
							"                 select ss_ext_sales_price as ext_price,\r\n",
							"                        ss_sold_date_sk as sold_date_sk,\r\n",
							"                        ss_item_sk as sold_item_sk,\r\n",
							"                        ss_sold_time_sk as time_sk\r\n",
							"                 from store_sales,date_dim\r\n",
							"                 where d_date_sk = ss_sold_date_sk\r\n",
							"                   and d_moy=11\r\n",
							"                   and d_year=1999\r\n",
							"                 ) tmp,time_dim\r\n",
							" where\r\n",
							"   sold_item_sk = i_item_sk\r\n",
							"   and i_manager_id=1\r\n",
							"   and time_sk = t_time_sk\r\n",
							"   and (t_meal_time = 'breakfast' or t_meal_time = 'dinner')\r\n",
							" group by i_brand, i_brand_id,t_hour,t_minute\r\n",
							" order by ext_price desc, i_brand_id;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query72\r\n",
							" select  i_item_desc\r\n",
							"      ,w_warehouse_name\r\n",
							"      ,d1.d_week_seq\r\n",
							"      ,sum(case when p_promo_sk is null then 1 else 0 end) no_promo\r\n",
							"      ,sum(case when p_promo_sk is not null then 1 else 0 end) promo\r\n",
							"      ,count(*) total_cnt\r\n",
							"from catalog_sales\r\n",
							"join inventory on (cs_item_sk = inv_item_sk)\r\n",
							"join warehouse on (w_warehouse_sk=inv_warehouse_sk)\r\n",
							"join item on (i_item_sk = cs_item_sk)\r\n",
							"join customer_demographics on (cs_bill_cdemo_sk = cd_demo_sk)\r\n",
							"join household_demographics on (cs_bill_hdemo_sk = hd_demo_sk)\r\n",
							"join date_dim d1 on (cs_sold_date_sk = d1.d_date_sk)\r\n",
							"join date_dim d2 on (inv_date_sk = d2.d_date_sk)\r\n",
							"join date_dim d3 on (cs_ship_date_sk = d3.d_date_sk)\r\n",
							"left outer join promotion on (cs_promo_sk=p_promo_sk)\r\n",
							"left outer join catalog_returns on (cr_item_sk = cs_item_sk and cr_order_number = cs_order_number)\r\n",
							"where d1.d_week_seq = d2.d_week_seq\r\n",
							"  and inv_quantity_on_hand < cs_quantity \r\n",
							"  and d3.d_date > date_add(cast(d1.d_date as date),5)\r\n",
							"  and hd_buy_potential = '>10000'\r\n",
							"  and d1.d_year = 1999\r\n",
							"  and cd_marital_status = 'D'\r\n",
							"group by i_item_desc,w_warehouse_name,d1.d_week_seq\r\n",
							"order by total_cnt desc, i_item_desc, w_warehouse_name, d_week_seq\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query73\r\n",
							" select c_last_name\r\n",
							"       ,c_first_name\r\n",
							"       ,c_salutation\r\n",
							"       ,c_preferred_cust_flag \r\n",
							"       ,ss_ticket_number\r\n",
							"       ,cnt from\r\n",
							"   (select ss_ticket_number\r\n",
							"          ,ss_customer_sk\r\n",
							"          ,count(*) cnt\r\n",
							"    from store_sales,date_dim,store,household_demographics\r\n",
							"    where store_sales.ss_sold_date_sk = date_dim.d_date_sk\r\n",
							"    and store_sales.ss_store_sk = store.s_store_sk  \r\n",
							"    and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk\r\n",
							"    and date_dim.d_dom between 1 and 2 \r\n",
							"    and (household_demographics.hd_buy_potential = '>10000' or\r\n",
							"         household_demographics.hd_buy_potential = 'Unknown')\r\n",
							"    and household_demographics.hd_vehicle_count > 0\r\n",
							"    and case when household_demographics.hd_vehicle_count > 0 then \r\n",
							"             household_demographics.hd_dep_count/ household_demographics.hd_vehicle_count else null end > 1\r\n",
							"    and date_dim.d_year in (1999,1999+1,1999+2)\r\n",
							"    and store.s_county in ('Williamson County','Franklin Parish','Bronx County','Orange County')\r\n",
							"    group by ss_ticket_number,ss_customer_sk) dj,customer\r\n",
							"    where ss_customer_sk = c_customer_sk\r\n",
							"      and cnt between 1 and 5\r\n",
							"    order by cnt desc, c_last_name asc;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query74\r\n",
							" with year_total as (\r\n",
							" select c_customer_id customer_id\r\n",
							"       ,c_first_name customer_first_name\r\n",
							"       ,c_last_name customer_last_name\r\n",
							"       ,d_year as year\r\n",
							"       ,sum(ss_net_paid) year_total\r\n",
							"       ,'s' sale_type\r\n",
							" from customer\r\n",
							"     ,store_sales\r\n",
							"     ,date_dim\r\n",
							" where c_customer_sk = ss_customer_sk\r\n",
							"   and ss_sold_date_sk = d_date_sk\r\n",
							"   and d_year in (2001,2001+1)\r\n",
							" group by c_customer_id\r\n",
							"         ,c_first_name\r\n",
							"         ,c_last_name\r\n",
							"         ,d_year\r\n",
							" union all\r\n",
							" select c_customer_id customer_id\r\n",
							"       ,c_first_name customer_first_name\r\n",
							"       ,c_last_name customer_last_name\r\n",
							"       ,d_year as year\r\n",
							"       ,sum(ws_net_paid) year_total\r\n",
							"       ,'w' sale_type\r\n",
							" from customer\r\n",
							"     ,web_sales\r\n",
							"     ,date_dim\r\n",
							" where c_customer_sk = ws_bill_customer_sk\r\n",
							"   and ws_sold_date_sk = d_date_sk\r\n",
							"   and d_year in (2001,2001+1)\r\n",
							" group by c_customer_id\r\n",
							"         ,c_first_name\r\n",
							"         ,c_last_name\r\n",
							"         ,d_year\r\n",
							"         )\r\n",
							"  select \r\n",
							"        t_s_secyear.customer_id, t_s_secyear.customer_first_name, t_s_secyear.customer_last_name\r\n",
							" from year_total t_s_firstyear\r\n",
							"     ,year_total t_s_secyear\r\n",
							"     ,year_total t_w_firstyear\r\n",
							"     ,year_total t_w_secyear\r\n",
							" where t_s_secyear.customer_id = t_s_firstyear.customer_id\r\n",
							"         and t_s_firstyear.customer_id = t_w_secyear.customer_id\r\n",
							"         and t_s_firstyear.customer_id = t_w_firstyear.customer_id\r\n",
							"         and t_s_firstyear.sale_type = 's'\r\n",
							"         and t_w_firstyear.sale_type = 'w'\r\n",
							"         and t_s_secyear.sale_type = 's'\r\n",
							"         and t_w_secyear.sale_type = 'w'\r\n",
							"         and t_s_firstyear.year = 2001\r\n",
							"         and t_s_secyear.year = 2001+1\r\n",
							"         and t_w_firstyear.year = 2001\r\n",
							"         and t_w_secyear.year = 2001+1\r\n",
							"         and t_s_firstyear.year_total > 0\r\n",
							"         and t_w_firstyear.year_total > 0\r\n",
							"         and case when t_w_firstyear.year_total > 0 then t_w_secyear.year_total / t_w_firstyear.year_total else null end\r\n",
							"           > case when t_s_firstyear.year_total > 0 then t_s_secyear.year_total / t_s_firstyear.year_total else null end\r\n",
							" order by 1,1,1\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query75\r\n",
							"WITH all_sales AS (\r\n",
							" SELECT d_year\r\n",
							"       ,i_brand_id\r\n",
							"       ,i_class_id\r\n",
							"       ,i_category_id\r\n",
							"       ,i_manufact_id\r\n",
							"       ,SUM(sales_cnt) AS sales_cnt\r\n",
							"       ,SUM(sales_amt) AS sales_amt\r\n",
							" FROM (SELECT d_year\r\n",
							"             ,i_brand_id\r\n",
							"             ,i_class_id\r\n",
							"             ,i_category_id\r\n",
							"             ,i_manufact_id\r\n",
							"             ,cs_quantity - COALESCE(cr_return_quantity,0) AS sales_cnt\r\n",
							"             ,cs_ext_sales_price - COALESCE(cr_return_amount,0.0) AS sales_amt\r\n",
							"       FROM catalog_sales JOIN item ON i_item_sk=cs_item_sk\r\n",
							"                          JOIN date_dim ON d_date_sk=cs_sold_date_sk\r\n",
							"                          LEFT JOIN catalog_returns ON (cs_order_number=cr_order_number \r\n",
							"                                                    AND cs_item_sk=cr_item_sk)\r\n",
							"       WHERE i_category='Books'\r\n",
							"       UNION\r\n",
							"       SELECT d_year\r\n",
							"             ,i_brand_id\r\n",
							"             ,i_class_id\r\n",
							"             ,i_category_id\r\n",
							"             ,i_manufact_id\r\n",
							"             ,ss_quantity - COALESCE(sr_return_quantity,0) AS sales_cnt\r\n",
							"             ,ss_ext_sales_price - COALESCE(sr_return_amt,0.0) AS sales_amt\r\n",
							"       FROM store_sales JOIN item ON i_item_sk=ss_item_sk\r\n",
							"                        JOIN date_dim ON d_date_sk=ss_sold_date_sk\r\n",
							"                        LEFT JOIN store_returns ON (ss_ticket_number=sr_ticket_number \r\n",
							"                                                AND ss_item_sk=sr_item_sk)\r\n",
							"       WHERE i_category='Books'\r\n",
							"       UNION\r\n",
							"       SELECT d_year\r\n",
							"             ,i_brand_id\r\n",
							"             ,i_class_id\r\n",
							"             ,i_category_id\r\n",
							"             ,i_manufact_id\r\n",
							"             ,ws_quantity - COALESCE(wr_return_quantity,0) AS sales_cnt\r\n",
							"             ,ws_ext_sales_price - COALESCE(wr_return_amt,0.0) AS sales_amt\r\n",
							"       FROM web_sales JOIN item ON i_item_sk=ws_item_sk\r\n",
							"                      JOIN date_dim ON d_date_sk=ws_sold_date_sk\r\n",
							"                      LEFT JOIN web_returns ON (ws_order_number=wr_order_number \r\n",
							"                                            AND ws_item_sk=wr_item_sk)\r\n",
							"       WHERE i_category='Books') sales_detail\r\n",
							" GROUP BY d_year, i_brand_id, i_class_id, i_category_id, i_manufact_id)\r\n",
							" SELECT  prev_yr.d_year AS prev_year\r\n",
							"                          ,curr_yr.d_year AS year\r\n",
							"                          ,curr_yr.i_brand_id\r\n",
							"                          ,curr_yr.i_class_id\r\n",
							"                          ,curr_yr.i_category_id\r\n",
							"                          ,curr_yr.i_manufact_id\r\n",
							"                          ,prev_yr.sales_cnt AS prev_yr_cnt\r\n",
							"                          ,curr_yr.sales_cnt AS curr_yr_cnt\r\n",
							"                          ,curr_yr.sales_cnt-prev_yr.sales_cnt AS sales_cnt_diff\r\n",
							"                          ,curr_yr.sales_amt-prev_yr.sales_amt AS sales_amt_diff\r\n",
							" FROM all_sales curr_yr, all_sales prev_yr\r\n",
							" WHERE curr_yr.i_brand_id=prev_yr.i_brand_id\r\n",
							"   AND curr_yr.i_class_id=prev_yr.i_class_id\r\n",
							"   AND curr_yr.i_category_id=prev_yr.i_category_id\r\n",
							"   AND curr_yr.i_manufact_id=prev_yr.i_manufact_id\r\n",
							"   AND curr_yr.d_year=2002\r\n",
							"   AND prev_yr.d_year=2002-1\r\n",
							"   AND CAST(curr_yr.sales_cnt AS DECIMAL(17,2))/CAST(prev_yr.sales_cnt AS DECIMAL(17,2))<0.9\r\n",
							" ORDER BY sales_cnt_diff\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query76\r\n",
							" select  channel, col_name, d_year, d_qoy, i_category, COUNT(*) sales_cnt, SUM(ext_sales_price) sales_amt FROM (\r\n",
							"        SELECT 'store' as channel, 'ss_store_sk' col_name, d_year, d_qoy, i_category, ss_ext_sales_price ext_sales_price\r\n",
							"         FROM store_sales, item, date_dim\r\n",
							"         WHERE ss_store_sk IS NULL\r\n",
							"           AND ss_sold_date_sk=d_date_sk\r\n",
							"           AND ss_item_sk=i_item_sk\r\n",
							"        UNION ALL\r\n",
							"        SELECT 'web' as channel, 'ws_ship_customer_sk' col_name, d_year, d_qoy, i_category, ws_ext_sales_price ext_sales_price\r\n",
							"         FROM web_sales, item, date_dim\r\n",
							"         WHERE ws_ship_customer_sk IS NULL\r\n",
							"           AND ws_sold_date_sk=d_date_sk\r\n",
							"           AND ws_item_sk=i_item_sk\r\n",
							"        UNION ALL\r\n",
							"        SELECT 'catalog' as channel, 'cs_ship_addr_sk' col_name, d_year, d_qoy, i_category, cs_ext_sales_price ext_sales_price\r\n",
							"         FROM catalog_sales, item, date_dim\r\n",
							"         WHERE cs_ship_addr_sk IS NULL\r\n",
							"           AND cs_sold_date_sk=d_date_sk\r\n",
							"           AND cs_item_sk=i_item_sk) foo\r\n",
							"GROUP BY channel, col_name, d_year, d_qoy, i_category\r\n",
							"ORDER BY channel, col_name, d_year, d_qoy, i_category\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query77\r\n",
							" with ss as\r\n",
							" (select s_store_sk,\r\n",
							"         sum(ss_ext_sales_price) as sales,\r\n",
							"         sum(ss_net_profit) as profit\r\n",
							" from store_sales,\r\n",
							"      date_dim,\r\n",
							"      store\r\n",
							" where ss_sold_date_sk = d_date_sk\r\n",
							"       and d_date between cast('2000-08-23' as date) \r\n",
							"                  and date_add(cast('2000-08-23' as date), 30 ) \r\n",
							"       and ss_store_sk = s_store_sk\r\n",
							" group by s_store_sk)\r\n",
							" ,\r\n",
							" sr as\r\n",
							" (select s_store_sk,\r\n",
							"         sum(sr_return_amt) as returns,\r\n",
							"         sum(sr_net_loss) as profit_loss\r\n",
							" from store_returns,\r\n",
							"      date_dim,\r\n",
							"      store\r\n",
							" where sr_returned_date_sk = d_date_sk\r\n",
							"       and d_date between cast('2000-08-23' as date)\r\n",
							"                  and date_add(cast('2000-08-23' as date),  30 )\r\n",
							"       and sr_store_sk = s_store_sk\r\n",
							" group by s_store_sk), \r\n",
							" cs as\r\n",
							" (select cs_call_center_sk,\r\n",
							"        sum(cs_ext_sales_price) as sales,\r\n",
							"        sum(cs_net_profit) as profit\r\n",
							" from catalog_sales,\r\n",
							"      date_dim\r\n",
							" where cs_sold_date_sk = d_date_sk\r\n",
							"       and d_date between cast('2000-08-23' as date)\r\n",
							"                  and date_add(cast('2000-08-23' as date), 30 )\r\n",
							" group by cs_call_center_sk \r\n",
							" ), \r\n",
							" cr as\r\n",
							" (select cr_call_center_sk,\r\n",
							"         sum(cr_return_amount) as returns,\r\n",
							"         sum(cr_net_loss) as profit_loss\r\n",
							" from catalog_returns,\r\n",
							"      date_dim\r\n",
							" where cr_returned_date_sk = d_date_sk\r\n",
							"       and d_date between cast('2000-08-23' as date)\r\n",
							"                  and date_add(cast('2000-08-23' as date),  30 )\r\n",
							" group by cr_call_center_sk\r\n",
							" ), \r\n",
							" ws as\r\n",
							" ( select wp_web_page_sk,\r\n",
							"        sum(ws_ext_sales_price) as sales,\r\n",
							"        sum(ws_net_profit) as profit\r\n",
							" from web_sales,\r\n",
							"      date_dim,\r\n",
							"      web_page\r\n",
							" where ws_sold_date_sk = d_date_sk\r\n",
							"       and d_date between cast('2000-08-23' as date)\r\n",
							"                  and date_add(cast('2000-08-23' as date), 30 )\r\n",
							"       and ws_web_page_sk = wp_web_page_sk\r\n",
							" group by wp_web_page_sk), \r\n",
							" wr as\r\n",
							" (select wp_web_page_sk,\r\n",
							"        sum(wr_return_amt) as returns,\r\n",
							"        sum(wr_net_loss) as profit_loss\r\n",
							" from web_returns,\r\n",
							"      date_dim,\r\n",
							"      web_page\r\n",
							" where wr_returned_date_sk = d_date_sk\r\n",
							"       and d_date between cast('2000-08-23' as date)\r\n",
							"                  and date_add(cast('2000-08-23' as date), 30 )\r\n",
							"       and wr_web_page_sk = wp_web_page_sk\r\n",
							" group by wp_web_page_sk)\r\n",
							"  select  channel\r\n",
							"        , id\r\n",
							"        , sum(sales) as sales\r\n",
							"        , sum(returns) as returns\r\n",
							"        , sum(profit) as profit\r\n",
							" from \r\n",
							" (select 'store channel' as channel\r\n",
							"        , ss.s_store_sk as id\r\n",
							"        , sales\r\n",
							"        , coalesce(returns, 0) as returns\r\n",
							"        , (profit - coalesce(profit_loss,0)) as profit\r\n",
							" from   ss left join sr\r\n",
							"        on  ss.s_store_sk = sr.s_store_sk\r\n",
							" union all\r\n",
							" select 'catalog channel' as channel\r\n",
							"        , cs_call_center_sk as id\r\n",
							"        , sales\r\n",
							"        , returns\r\n",
							"        , (profit - profit_loss) as profit\r\n",
							" from  cs\r\n",
							"       , cr\r\n",
							" union all\r\n",
							" select 'web channel' as channel\r\n",
							"        , ws.wp_web_page_sk as id\r\n",
							"        , sales\r\n",
							"        , coalesce(returns, 0) returns\r\n",
							"        , (profit - coalesce(profit_loss,0)) as profit\r\n",
							" from   ws left join wr\r\n",
							"        on  ws.wp_web_page_sk = wr.wp_web_page_sk\r\n",
							" ) x\r\n",
							" group by rollup (channel, id)\r\n",
							" order by channel\r\n",
							"         ,id\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query78\r\n",
							"with ws as\r\n",
							"  (select d_year AS ws_sold_year, ws_item_sk,\r\n",
							"    ws_bill_customer_sk ws_customer_sk,\r\n",
							"    sum(ws_quantity) ws_qty,\r\n",
							"    sum(ws_wholesale_cost) ws_wc,\r\n",
							"    sum(ws_sales_price) ws_sp\r\n",
							"   from web_sales\r\n",
							"   left join web_returns on wr_order_number=ws_order_number and ws_item_sk=wr_item_sk\r\n",
							"   join date_dim on ws_sold_date_sk = d_date_sk\r\n",
							"   where wr_order_number is null\r\n",
							"   group by d_year, ws_item_sk, ws_bill_customer_sk\r\n",
							"   ),\r\n",
							"cs as\r\n",
							"  (select d_year AS cs_sold_year, cs_item_sk,\r\n",
							"    cs_bill_customer_sk cs_customer_sk,\r\n",
							"    sum(cs_quantity) cs_qty,\r\n",
							"    sum(cs_wholesale_cost) cs_wc,\r\n",
							"    sum(cs_sales_price) cs_sp\r\n",
							"   from catalog_sales\r\n",
							"   left join catalog_returns on cr_order_number=cs_order_number and cs_item_sk=cr_item_sk\r\n",
							"   join date_dim on cs_sold_date_sk = d_date_sk\r\n",
							"   where cr_order_number is null\r\n",
							"   group by d_year, cs_item_sk, cs_bill_customer_sk\r\n",
							"   ),\r\n",
							"ss as\r\n",
							"  (select d_year AS ss_sold_year, ss_item_sk,\r\n",
							"    ss_customer_sk,\r\n",
							"    sum(ss_quantity) ss_qty,\r\n",
							"    sum(ss_wholesale_cost) ss_wc,\r\n",
							"    sum(ss_sales_price) ss_sp\r\n",
							"   from store_sales\r\n",
							"   left join store_returns on sr_ticket_number=ss_ticket_number and ss_item_sk=sr_item_sk\r\n",
							"   join date_dim on ss_sold_date_sk = d_date_sk\r\n",
							"   where sr_ticket_number is null\r\n",
							"   group by d_year, ss_item_sk, ss_customer_sk\r\n",
							"   )\r\n",
							" select \r\n",
							"ss_sold_year, ss_item_sk, ss_customer_sk,\r\n",
							"round(ss_qty/(coalesce(ws_qty,0)+coalesce(cs_qty,0)),2) ratio,\r\n",
							"ss_qty store_qty, ss_wc store_wholesale_cost, ss_sp store_sales_price,\r\n",
							"coalesce(ws_qty,0)+coalesce(cs_qty,0) other_chan_qty,\r\n",
							"coalesce(ws_wc,0)+coalesce(cs_wc,0) other_chan_wholesale_cost,\r\n",
							"coalesce(ws_sp,0)+coalesce(cs_sp,0) other_chan_sales_price\r\n",
							"from ss\r\n",
							"left join ws on (ws_sold_year=ss_sold_year and ws_item_sk=ss_item_sk and ws_customer_sk=ss_customer_sk)\r\n",
							"left join cs on (cs_sold_year=ss_sold_year and cs_item_sk=ss_item_sk and cs_customer_sk=ss_customer_sk)\r\n",
							"where (coalesce(ws_qty,0)>0 or coalesce(cs_qty, 0)>0) and ss_sold_year=2000\r\n",
							"order by \r\n",
							"  ss_sold_year, ss_item_sk, ss_customer_sk,\r\n",
							"  ss_qty desc, ss_wc desc, ss_sp desc,\r\n",
							"  other_chan_qty,\r\n",
							"  other_chan_wholesale_cost,\r\n",
							"  other_chan_sales_price,\r\n",
							"  round(ss_qty/(coalesce(ws_qty+cs_qty,1)),2)\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query79\r\n",
							"  select \r\n",
							"  c_last_name,c_first_name,substr(s_city,1,30),ss_ticket_number,amt,profit\r\n",
							"  from\r\n",
							"   (select ss_ticket_number\r\n",
							"          ,ss_customer_sk\r\n",
							"          ,store.s_city\r\n",
							"          ,sum(ss_coupon_amt) amt\r\n",
							"          ,sum(ss_net_profit) profit\r\n",
							"    from store_sales,date_dim,store,household_demographics\r\n",
							"    where store_sales.ss_sold_date_sk = date_dim.d_date_sk\r\n",
							"    and store_sales.ss_store_sk = store.s_store_sk  \r\n",
							"    and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk\r\n",
							"    and (household_demographics.hd_dep_count = 6 or household_demographics.hd_vehicle_count > 2)\r\n",
							"    and date_dim.d_dow = 1\r\n",
							"    and date_dim.d_year in (1999,1999+1,1999+2) \r\n",
							"    and store.s_number_employees between 200 and 295\r\n",
							"    group by ss_ticket_number,ss_customer_sk,ss_addr_sk,store.s_city) ms,customer\r\n",
							"    where ss_customer_sk = c_customer_sk\r\n",
							" order by c_last_name,c_first_name,substr(s_city,1,30), profit\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query80\r\n",
							" with ssr as\r\n",
							" (select  s_store_id as store_id,\r\n",
							"          sum(ss_ext_sales_price) as sales,\r\n",
							"          sum(coalesce(sr_return_amt, 0)) as returns,\r\n",
							"          sum(ss_net_profit - coalesce(sr_net_loss, 0)) as profit\r\n",
							"  from store_sales left outer join store_returns on\r\n",
							"         (ss_item_sk = sr_item_sk and ss_ticket_number = sr_ticket_number),\r\n",
							"     date_dim,\r\n",
							"     store,\r\n",
							"     item,\r\n",
							"     promotion\r\n",
							" where ss_sold_date_sk = d_date_sk\r\n",
							"       and d_date between cast('2000-08-23' as date) \r\n",
							"                  and date_add(cast('2000-08-23' as date), 30 )\r\n",
							"       and ss_store_sk = s_store_sk\r\n",
							"       and ss_item_sk = i_item_sk\r\n",
							"       and i_current_price > 50\r\n",
							"       and ss_promo_sk = p_promo_sk\r\n",
							"       and p_channel_tv = 'N'\r\n",
							" group by s_store_id)\r\n",
							" ,\r\n",
							" csr as\r\n",
							" (select  cp_catalog_page_id as catalog_page_id,\r\n",
							"          sum(cs_ext_sales_price) as sales,\r\n",
							"          sum(coalesce(cr_return_amount, 0)) as returns,\r\n",
							"          sum(cs_net_profit - coalesce(cr_net_loss, 0)) as profit\r\n",
							"  from catalog_sales left outer join catalog_returns on\r\n",
							"         (cs_item_sk = cr_item_sk and cs_order_number = cr_order_number),\r\n",
							"     date_dim,\r\n",
							"     catalog_page,\r\n",
							"     item,\r\n",
							"     promotion\r\n",
							" where cs_sold_date_sk = d_date_sk\r\n",
							"       and d_date between cast('2000-08-23' as date)\r\n",
							"                  and date_add(cast('2000-08-23' as date), 30 )\r\n",
							"        and cs_catalog_page_sk = cp_catalog_page_sk\r\n",
							"       and cs_item_sk = i_item_sk\r\n",
							"       and i_current_price > 50\r\n",
							"       and cs_promo_sk = p_promo_sk\r\n",
							"       and p_channel_tv = 'N'\r\n",
							"group by cp_catalog_page_id)\r\n",
							" ,\r\n",
							" wsr as\r\n",
							" (select  web_site_id,\r\n",
							"          sum(ws_ext_sales_price) as sales,\r\n",
							"          sum(coalesce(wr_return_amt, 0)) as returns,\r\n",
							"          sum(ws_net_profit - coalesce(wr_net_loss, 0)) as profit\r\n",
							"  from web_sales left outer join web_returns on\r\n",
							"         (ws_item_sk = wr_item_sk and ws_order_number = wr_order_number),\r\n",
							"     date_dim,\r\n",
							"     web_site,\r\n",
							"     item,\r\n",
							"     promotion\r\n",
							" where ws_sold_date_sk = d_date_sk\r\n",
							"       and d_date between cast('2000-08-23' as date)\r\n",
							"                  and date_add(cast('2000-08-23' as date),  30 )\r\n",
							"        and ws_web_site_sk = web_site_sk\r\n",
							"       and ws_item_sk = i_item_sk\r\n",
							"       and i_current_price > 50\r\n",
							"       and ws_promo_sk = p_promo_sk\r\n",
							"       and p_channel_tv = 'N'\r\n",
							"group by web_site_id)\r\n",
							"  select  channel\r\n",
							"        , id\r\n",
							"        , sum(sales) as sales\r\n",
							"        , sum(returns) as returns\r\n",
							"        , sum(profit) as profit\r\n",
							" from \r\n",
							" (select 'store channel' as channel\r\n",
							"        , concat( 'store' , store_id )  as id\r\n",
							"        , sales\r\n",
							"        , returns\r\n",
							"        , profit\r\n",
							" from   ssr\r\n",
							" union all\r\n",
							" select 'catalog channel' as channel\r\n",
							"        , concat( 'catalog_page' , catalog_page_id ) as id\r\n",
							"        , sales\r\n",
							"        , returns\r\n",
							"        , profit\r\n",
							" from  csr\r\n",
							" union all\r\n",
							" select 'web channel' as channel\r\n",
							"        , concat( 'web_site' , web_site_id )  as id\r\n",
							"        , sales\r\n",
							"        , returns\r\n",
							"        , profit\r\n",
							" from   wsr\r\n",
							" ) x\r\n",
							" group by rollup (channel, id)\r\n",
							" order by channel\r\n",
							"         ,id\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query81\r\n",
							" with customer_total_return as\r\n",
							" (select cr_returning_customer_sk as ctr_customer_sk\r\n",
							"        ,ca_state as ctr_state, \r\n",
							" \tsum(cr_return_amt_inc_tax) as ctr_total_return\r\n",
							" from catalog_returns\r\n",
							"     ,date_dim\r\n",
							"     ,customer_address\r\n",
							" where cr_returned_date_sk = d_date_sk \r\n",
							"   and d_year =2000\r\n",
							"   and cr_returning_addr_sk = ca_address_sk \r\n",
							" group by cr_returning_customer_sk\r\n",
							"         ,ca_state )\r\n",
							"  select  c_customer_id,c_salutation,c_first_name,c_last_name,ca_street_number,ca_street_name\r\n",
							"                   ,ca_street_type,ca_suite_number,ca_city,ca_county,ca_state,ca_zip,ca_country,ca_gmt_offset\r\n",
							"                  ,ca_location_type,ctr_total_return\r\n",
							" from customer_total_return ctr1\r\n",
							"     ,customer_address\r\n",
							"     ,customer\r\n",
							" where ctr1.ctr_total_return > (select avg(ctr_total_return)*1.2\r\n",
							" \t\t\t  from customer_total_return ctr2 \r\n",
							"                  \t  where ctr1.ctr_state = ctr2.ctr_state)\r\n",
							"       and ca_address_sk = c_current_addr_sk\r\n",
							"       and ca_state = 'GA'\r\n",
							"       and ctr1.ctr_customer_sk = c_customer_sk\r\n",
							" order by c_customer_id,c_salutation,c_first_name,c_last_name,ca_street_number,ca_street_name\r\n",
							"                   ,ca_street_type,ca_suite_number,ca_city,ca_county,ca_state,ca_zip,ca_country,ca_gmt_offset\r\n",
							"                  ,ca_location_type,ctr_total_return\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query82\r\n",
							"  select  i_item_id\r\n",
							"       ,i_item_desc\r\n",
							"       ,i_current_price\r\n",
							" from item, inventory, date_dim, store_sales\r\n",
							" where i_current_price between 62 and 62+30\r\n",
							" and inv_item_sk = i_item_sk\r\n",
							" and d_date_sk=inv_date_sk\r\n",
							" and d_date between cast('2000-05-25' as date) and date_add(cast('2000-05-25' as date), 60 )\r\n",
							" and i_manufact_id in (129,270,821,423)\r\n",
							" and inv_quantity_on_hand between 100 and 500\r\n",
							" and ss_item_sk = i_item_sk\r\n",
							" group by i_item_id,i_item_desc,i_current_price\r\n",
							" order by i_item_id\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query83\r\n",
							" with sr_items as\r\n",
							" (select i_item_id item_id,\r\n",
							"        sum(sr_return_quantity) sr_item_qty\r\n",
							" from store_returns,\r\n",
							"      item,\r\n",
							"      date_dim\r\n",
							" where sr_item_sk = i_item_sk\r\n",
							" and   d_date    in \r\n",
							"\t(select d_date\r\n",
							"\tfrom date_dim\r\n",
							"\twhere d_week_seq in \r\n",
							"\t\t(select d_week_seq\r\n",
							"\t\tfrom date_dim\r\n",
							"\t  where d_date in ('2000-06-30','2000-09-27','2000-11-17')))\r\n",
							" and   sr_returned_date_sk   = d_date_sk\r\n",
							" group by i_item_id),\r\n",
							" cr_items as\r\n",
							" (select i_item_id item_id,\r\n",
							"        sum(cr_return_quantity) cr_item_qty\r\n",
							" from catalog_returns,\r\n",
							"      item,\r\n",
							"      date_dim\r\n",
							" where cr_item_sk = i_item_sk\r\n",
							" and   d_date    in \r\n",
							"\t(select d_date\r\n",
							"\tfrom date_dim\r\n",
							"\twhere d_week_seq in \r\n",
							"\t\t(select d_week_seq\r\n",
							"\t\tfrom date_dim\r\n",
							"\t  where d_date in ('2000-06-30','2000-09-27','2000-11-17')))\r\n",
							" and   cr_returned_date_sk   = d_date_sk\r\n",
							" group by i_item_id),\r\n",
							" wr_items as\r\n",
							" (select i_item_id item_id,\r\n",
							"        sum(wr_return_quantity) wr_item_qty\r\n",
							" from web_returns,\r\n",
							"      item,\r\n",
							"      date_dim\r\n",
							" where wr_item_sk = i_item_sk\r\n",
							" and   d_date    in \r\n",
							"\t(select d_date\r\n",
							"\tfrom date_dim\r\n",
							"\twhere d_week_seq in \r\n",
							"\t\t(select d_week_seq\r\n",
							"\t\tfrom date_dim\r\n",
							"\t\twhere d_date in ('2000-06-30','2000-09-27','2000-11-17')))\r\n",
							" and   wr_returned_date_sk   = d_date_sk\r\n",
							" group by i_item_id)\r\n",
							"  select  sr_items.item_id\r\n",
							"       ,sr_item_qty\r\n",
							"       ,sr_item_qty/(sr_item_qty+cr_item_qty+wr_item_qty)/3.0 * 100 sr_dev\r\n",
							"       ,cr_item_qty\r\n",
							"       ,cr_item_qty/(sr_item_qty+cr_item_qty+wr_item_qty)/3.0 * 100 cr_dev\r\n",
							"       ,wr_item_qty\r\n",
							"       ,wr_item_qty/(sr_item_qty+cr_item_qty+wr_item_qty)/3.0 * 100 wr_dev\r\n",
							"       ,(sr_item_qty+cr_item_qty+wr_item_qty)/3.0 average\r\n",
							" from sr_items\r\n",
							"     ,cr_items\r\n",
							"     ,wr_items\r\n",
							" where sr_items.item_id=cr_items.item_id\r\n",
							"   and sr_items.item_id=wr_items.item_id \r\n",
							" order by sr_items.item_id\r\n",
							"         ,sr_item_qty\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query84\r\n",
							"  select  c_customer_id as customer_id\r\n",
							"       ,concat(c_last_name , ', ' , coalesce(c_first_name,'')) as customername\r\n",
							" from customer\r\n",
							"     ,customer_address\r\n",
							"     ,customer_demographics\r\n",
							"     ,household_demographics\r\n",
							"     ,income_band\r\n",
							"     ,store_returns\r\n",
							" where ca_city\t        =  'Edgewood'\r\n",
							"   and c_current_addr_sk = ca_address_sk\r\n",
							"   and ib_lower_bound   >=  38128\r\n",
							"   and ib_upper_bound   <=  38128 + 50000\r\n",
							"   and ib_income_band_sk = hd_income_band_sk\r\n",
							"   and cd_demo_sk = c_current_cdemo_sk\r\n",
							"   and hd_demo_sk = c_current_hdemo_sk\r\n",
							"   and sr_cdemo_sk = cd_demo_sk\r\n",
							" order by c_customer_id\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query85\r\n",
							"  select  substr(r_reason_desc,1,20)\r\n",
							"       ,avg(ws_quantity)\r\n",
							"       ,avg(wr_refunded_cash)\r\n",
							"       ,avg(wr_fee)\r\n",
							" from web_sales, web_returns, web_page, customer_demographics cd1,\r\n",
							"      customer_demographics cd2, customer_address, date_dim, reason \r\n",
							" where ws_web_page_sk = wp_web_page_sk\r\n",
							"   and ws_item_sk = wr_item_sk\r\n",
							"   and ws_order_number = wr_order_number\r\n",
							"   and ws_sold_date_sk = d_date_sk and d_year = 2000\r\n",
							"   and cd1.cd_demo_sk = wr_refunded_cdemo_sk \r\n",
							"   and cd2.cd_demo_sk = wr_returning_cdemo_sk\r\n",
							"   and ca_address_sk = wr_refunded_addr_sk\r\n",
							"   and r_reason_sk = wr_reason_sk\r\n",
							"   and\r\n",
							"   (\r\n",
							"    (\r\n",
							"     cd1.cd_marital_status = 'M'\r\n",
							"     and\r\n",
							"     cd1.cd_marital_status = cd2.cd_marital_status\r\n",
							"     and\r\n",
							"     cd1.cd_education_status = 'Advanced Degree'\r\n",
							"     and \r\n",
							"     cd1.cd_education_status = cd2.cd_education_status\r\n",
							"     and\r\n",
							"     ws_sales_price between 100.00 and 150.00\r\n",
							"    )\r\n",
							"   or\r\n",
							"    (\r\n",
							"     cd1.cd_marital_status = 'S'\r\n",
							"     and\r\n",
							"     cd1.cd_marital_status = cd2.cd_marital_status\r\n",
							"     and\r\n",
							"     cd1.cd_education_status = 'College' \r\n",
							"     and\r\n",
							"     cd1.cd_education_status = cd2.cd_education_status\r\n",
							"     and\r\n",
							"     ws_sales_price between 50.00 and 100.00\r\n",
							"    )\r\n",
							"   or\r\n",
							"    (\r\n",
							"     cd1.cd_marital_status = 'W'\r\n",
							"     and\r\n",
							"     cd1.cd_marital_status = cd2.cd_marital_status\r\n",
							"     and\r\n",
							"     cd1.cd_education_status = '2 yr Degree'\r\n",
							"     and\r\n",
							"     cd1.cd_education_status = cd2.cd_education_status\r\n",
							"     and\r\n",
							"     ws_sales_price between 150.00 and 200.00\r\n",
							"    )\r\n",
							"   )\r\n",
							"   and\r\n",
							"   (\r\n",
							"    (\r\n",
							"     ca_country = 'United States'\r\n",
							"     and\r\n",
							"     ca_state in ('IN', 'OH', 'NJ')\r\n",
							"     and ws_net_profit between 100 and 200  \r\n",
							"    )\r\n",
							"    or\r\n",
							"    (\r\n",
							"     ca_country = 'United States'\r\n",
							"     and\r\n",
							"     ca_state in ('WI', 'CT', 'KY')\r\n",
							"     and ws_net_profit between 150 and 300  \r\n",
							"    )\r\n",
							"    or\r\n",
							"    (\r\n",
							"     ca_country = 'United States'\r\n",
							"     and\r\n",
							"     ca_state in ('LA', 'IA', 'AR')\r\n",
							"     and ws_net_profit between 50 and 250  \r\n",
							"    )\r\n",
							"   )\r\n",
							"group by r_reason_desc\r\n",
							"order by substr(r_reason_desc,1,20)\r\n",
							"        ,avg(ws_quantity)\r\n",
							"        ,avg(wr_refunded_cash)\r\n",
							"        ,avg(wr_fee)\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query86\r\n",
							"  select   \r\n",
							"    sum(ws_net_paid) as total_sum\r\n",
							"   ,i_category\r\n",
							"   ,i_class\r\n",
							"   ,grouping(i_category)+grouping(i_class) as lochierarchy\r\n",
							"   ,rank() over (\r\n",
							" \tpartition by grouping(i_category)+grouping(i_class),\r\n",
							" \tcase when grouping(i_class) = 0 then i_category end \r\n",
							" \torder by sum(ws_net_paid) desc) as rank_within_parent\r\n",
							" from\r\n",
							"    web_sales\r\n",
							"   ,date_dim       d1\r\n",
							"   ,item\r\n",
							" where\r\n",
							"    d1.d_month_seq between 1200 and 1200+11\r\n",
							" and d1.d_date_sk = ws_sold_date_sk\r\n",
							" and i_item_sk  = ws_item_sk\r\n",
							" group by rollup(i_category,i_class)\r\n",
							" order by\r\n",
							"   lochierarchy desc,\r\n",
							"   case when lochierarchy = 0 then i_category end,\r\n",
							"   rank_within_parent\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query87\r\n",
							"select count(*) \r\n",
							"from ((select distinct c_last_name, c_first_name, d_date\r\n",
							"       from store_sales, date_dim, customer\r\n",
							"       where store_sales.ss_sold_date_sk = date_dim.d_date_sk\r\n",
							"         and store_sales.ss_customer_sk = customer.c_customer_sk\r\n",
							"         and d_month_seq between 1200 and 1200+11)\r\n",
							"       except\r\n",
							"      (select distinct c_last_name, c_first_name, d_date\r\n",
							"       from catalog_sales, date_dim, customer\r\n",
							"       where catalog_sales.cs_sold_date_sk = date_dim.d_date_sk\r\n",
							"         and catalog_sales.cs_bill_customer_sk = customer.c_customer_sk\r\n",
							"         and d_month_seq between 1200 and 1200+11)\r\n",
							"       except\r\n",
							"      (select distinct c_last_name, c_first_name, d_date\r\n",
							"       from web_sales, date_dim, customer\r\n",
							"       where web_sales.ws_sold_date_sk = date_dim.d_date_sk\r\n",
							"         and web_sales.ws_bill_customer_sk = customer.c_customer_sk\r\n",
							"         and d_month_seq between 1200 and 1200+11)\r\n",
							") cool_cust;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query88\r\n",
							"select  *\r\n",
							"from\r\n",
							" (select count(*) h8_30_to_9\r\n",
							" from store_sales, household_demographics , time_dim, store\r\n",
							" where ss_sold_time_sk = time_dim.t_time_sk   \r\n",
							"     and ss_hdemo_sk = household_demographics.hd_demo_sk \r\n",
							"     and ss_store_sk = s_store_sk\r\n",
							"     and time_dim.t_hour = 8\r\n",
							"     and time_dim.t_minute >= 30\r\n",
							"     and ((household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or\r\n",
							"          (household_demographics.hd_dep_count = 2 and household_demographics.hd_vehicle_count<=2+2) or\r\n",
							"          (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2)) \r\n",
							"     and store.s_store_name = 'ese') s1,\r\n",
							" (select count(*) h9_to_9_30 \r\n",
							" from store_sales, household_demographics , time_dim, store\r\n",
							" where ss_sold_time_sk = time_dim.t_time_sk\r\n",
							"     and ss_hdemo_sk = household_demographics.hd_demo_sk\r\n",
							"     and ss_store_sk = s_store_sk \r\n",
							"     and time_dim.t_hour = 9 \r\n",
							"     and time_dim.t_minute < 30\r\n",
							"     and ((household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or\r\n",
							"          (household_demographics.hd_dep_count = 2 and household_demographics.hd_vehicle_count<=2+2) or\r\n",
							"          (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2))\r\n",
							"     and store.s_store_name = 'ese') s2,\r\n",
							" (select count(*) h9_30_to_10 \r\n",
							" from store_sales, household_demographics , time_dim, store\r\n",
							" where ss_sold_time_sk = time_dim.t_time_sk\r\n",
							"     and ss_hdemo_sk = household_demographics.hd_demo_sk\r\n",
							"     and ss_store_sk = s_store_sk\r\n",
							"     and time_dim.t_hour = 9\r\n",
							"     and time_dim.t_minute >= 30\r\n",
							"     and ((household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or\r\n",
							"          (household_demographics.hd_dep_count = 2 and household_demographics.hd_vehicle_count<=2+2) or\r\n",
							"          (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2))\r\n",
							"     and store.s_store_name = 'ese') s3,\r\n",
							" (select count(*) h10_to_10_30\r\n",
							" from store_sales, household_demographics , time_dim, store\r\n",
							" where ss_sold_time_sk = time_dim.t_time_sk\r\n",
							"     and ss_hdemo_sk = household_demographics.hd_demo_sk\r\n",
							"     and ss_store_sk = s_store_sk\r\n",
							"     and time_dim.t_hour = 10 \r\n",
							"     and time_dim.t_minute < 30\r\n",
							"     and ((household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or\r\n",
							"          (household_demographics.hd_dep_count = 2 and household_demographics.hd_vehicle_count<=2+2) or\r\n",
							"          (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2))\r\n",
							"     and store.s_store_name = 'ese') s4,\r\n",
							" (select count(*) h10_30_to_11\r\n",
							" from store_sales, household_demographics , time_dim, store\r\n",
							" where ss_sold_time_sk = time_dim.t_time_sk\r\n",
							"     and ss_hdemo_sk = household_demographics.hd_demo_sk\r\n",
							"     and ss_store_sk = s_store_sk\r\n",
							"     and time_dim.t_hour = 10 \r\n",
							"     and time_dim.t_minute >= 30\r\n",
							"     and ((household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or\r\n",
							"          (household_demographics.hd_dep_count = 2 and household_demographics.hd_vehicle_count<=2+2) or\r\n",
							"          (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2))\r\n",
							"     and store.s_store_name = 'ese') s5,\r\n",
							" (select count(*) h11_to_11_30\r\n",
							" from store_sales, household_demographics , time_dim, store\r\n",
							" where ss_sold_time_sk = time_dim.t_time_sk\r\n",
							"     and ss_hdemo_sk = household_demographics.hd_demo_sk\r\n",
							"     and ss_store_sk = s_store_sk \r\n",
							"     and time_dim.t_hour = 11\r\n",
							"     and time_dim.t_minute < 30\r\n",
							"     and ((household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or\r\n",
							"          (household_demographics.hd_dep_count = 2 and household_demographics.hd_vehicle_count<=2+2) or\r\n",
							"          (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2))\r\n",
							"     and store.s_store_name = 'ese') s6,\r\n",
							" (select count(*) h11_30_to_12\r\n",
							" from store_sales, household_demographics , time_dim, store\r\n",
							" where ss_sold_time_sk = time_dim.t_time_sk\r\n",
							"     and ss_hdemo_sk = household_demographics.hd_demo_sk\r\n",
							"     and ss_store_sk = s_store_sk\r\n",
							"     and time_dim.t_hour = 11\r\n",
							"     and time_dim.t_minute >= 30\r\n",
							"     and ((household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or\r\n",
							"          (household_demographics.hd_dep_count = 2 and household_demographics.hd_vehicle_count<=2+2) or\r\n",
							"          (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2))\r\n",
							"     and store.s_store_name = 'ese') s7,\r\n",
							" (select count(*) h12_to_12_30\r\n",
							" from store_sales, household_demographics , time_dim, store\r\n",
							" where ss_sold_time_sk = time_dim.t_time_sk\r\n",
							"     and ss_hdemo_sk = household_demographics.hd_demo_sk\r\n",
							"     and ss_store_sk = s_store_sk\r\n",
							"     and time_dim.t_hour = 12\r\n",
							"     and time_dim.t_minute < 30\r\n",
							"     and ((household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or\r\n",
							"          (household_demographics.hd_dep_count = 2 and household_demographics.hd_vehicle_count<=2+2) or\r\n",
							"          (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2))\r\n",
							"     and store.s_store_name = 'ese') s8;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query89\r\n",
							" select  *\r\n",
							"from(\r\n",
							"select i_category, i_class, i_brand,\r\n",
							"       s_store_name, s_company_name,\r\n",
							"       d_moy,\r\n",
							"       sum(ss_sales_price) sum_sales,\r\n",
							"       avg(sum(ss_sales_price)) over\r\n",
							"         (partition by i_category, i_brand, s_store_name, s_company_name)\r\n",
							"         avg_monthly_sales\r\n",
							"from item, store_sales, date_dim, store\r\n",
							"where ss_item_sk = i_item_sk and\r\n",
							"      ss_sold_date_sk = d_date_sk and\r\n",
							"      ss_store_sk = s_store_sk and\r\n",
							"      d_year in (1999) and\r\n",
							"        ((i_category in ('Books','Electronics','Sports') and\r\n",
							"          i_class in ('computers','stereo','football')\r\n",
							"         )\r\n",
							"      or (i_category in ('Men','Jewelry','Women') and\r\n",
							"          i_class in ('shirts','birdal','dresses') \r\n",
							"        ))\r\n",
							"group by i_category, i_class, i_brand,\r\n",
							"         s_store_name, s_company_name, d_moy) tmp1\r\n",
							"where case when (avg_monthly_sales <> 0) then (abs(sum_sales - avg_monthly_sales) / avg_monthly_sales) else null end > 0.1\r\n",
							"order by sum_sales - avg_monthly_sales, s_store_name\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query90\r\n",
							"  select  cast(amc as decimal(15,4))/cast(pmc as decimal(15,4)) am_pm_ratio\r\n",
							" from ( select count(*) amc\r\n",
							"       from web_sales, household_demographics , time_dim, web_page\r\n",
							"       where ws_sold_time_sk = time_dim.t_time_sk\r\n",
							"         and ws_ship_hdemo_sk = household_demographics.hd_demo_sk\r\n",
							"         and ws_web_page_sk = web_page.wp_web_page_sk\r\n",
							"         and time_dim.t_hour between 8 and 8+1\r\n",
							"         and household_demographics.hd_dep_count = 6\r\n",
							"         and web_page.wp_char_count between 5000 and 5200) at1,\r\n",
							"      ( select count(*) pmc\r\n",
							"       from web_sales, household_demographics , time_dim, web_page\r\n",
							"       where ws_sold_time_sk = time_dim.t_time_sk\r\n",
							"         and ws_ship_hdemo_sk = household_demographics.hd_demo_sk\r\n",
							"         and ws_web_page_sk = web_page.wp_web_page_sk\r\n",
							"         and time_dim.t_hour between 19 and 19+1\r\n",
							"         and household_demographics.hd_dep_count = 6\r\n",
							"         and web_page.wp_char_count between 5000 and 5200) pt\r\n",
							" order by am_pm_ratio\r\n",
							"  limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query91\r\n",
							"select  \r\n",
							"        cc_call_center_id Call_Center,\r\n",
							"        cc_name Call_Center_Name,\r\n",
							"        cc_manager Manager,\r\n",
							"        sum(cr_net_loss) Returns_Loss\r\n",
							"from\r\n",
							"        call_center,\r\n",
							"        catalog_returns,\r\n",
							"        date_dim,\r\n",
							"        customer,\r\n",
							"        customer_address,\r\n",
							"        customer_demographics,\r\n",
							"        household_demographics\r\n",
							"where\r\n",
							"        cr_call_center_sk       = cc_call_center_sk\r\n",
							"and     cr_returned_date_sk     = d_date_sk\r\n",
							"and     cr_returning_customer_sk= c_customer_sk\r\n",
							"and     cd_demo_sk              = c_current_cdemo_sk\r\n",
							"and     hd_demo_sk              = c_current_hdemo_sk\r\n",
							"and     ca_address_sk           = c_current_addr_sk\r\n",
							"and     d_year                  = 1998 \r\n",
							"and     d_moy                   = 11\r\n",
							"and     ( (cd_marital_status       = 'M' and cd_education_status     = 'Unknown')\r\n",
							"        or(cd_marital_status       = 'W' and cd_education_status     = 'Advanced Degree'))\r\n",
							"and     hd_buy_potential like 'Unknown%'\r\n",
							"and     ca_gmt_offset           = -7\r\n",
							"group by cc_call_center_id,cc_name,cc_manager,cd_marital_status,cd_education_status\r\n",
							"order by sum(cr_net_loss) desc;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query92\r\n",
							" select  \r\n",
							"   sum(ws_ext_discount_amt)  as Excess_Discount_Amount \r\n",
							"from \r\n",
							"    web_sales \r\n",
							"   ,item \r\n",
							"   ,date_dim\r\n",
							"where\r\n",
							"i_manufact_id = 350\r\n",
							"and i_item_sk = ws_item_sk \r\n",
							"and d_date between '2000-01-27' and \r\n",
							"        date_add(cast('2000-01-27' as date), 90 )\r\n",
							"and d_date_sk = ws_sold_date_sk \r\n",
							"and ws_ext_discount_amt  \r\n",
							"     > ( \r\n",
							"         SELECT \r\n",
							"            1.3 * avg(ws_ext_discount_amt) \r\n",
							"         FROM \r\n",
							"            web_sales \r\n",
							"           ,date_dim\r\n",
							"         WHERE \r\n",
							"              ws_item_sk = i_item_sk \r\n",
							"          and d_date between '2000-01-27' and\r\n",
							"                             date_add(cast('2000-01-27' as date), 90 )\r\n",
							"          and d_date_sk = ws_sold_date_sk \r\n",
							"      ) \r\n",
							"order by sum(ws_ext_discount_amt)\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query93\r\n",
							" select  ss_customer_sk\r\n",
							"            ,sum(act_sales) sumsales\r\n",
							"      from (select ss_item_sk\r\n",
							"                  ,ss_ticket_number\r\n",
							"                  ,ss_customer_sk\r\n",
							"                  ,case when sr_return_quantity is not null then (ss_quantity-sr_return_quantity)*ss_sales_price\r\n",
							"                                                            else (ss_quantity*ss_sales_price) end act_sales\r\n",
							"            from store_sales left outer join store_returns on (sr_item_sk = ss_item_sk\r\n",
							"                                                               and sr_ticket_number = ss_ticket_number)\r\n",
							"                ,reason\r\n",
							"            where sr_reason_sk = r_reason_sk\r\n",
							"              and r_reason_desc = 'reason 28') t\r\n",
							"      group by ss_customer_sk\r\n",
							"      order by sumsales, ss_customer_sk\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query94\r\n",
							" select  \r\n",
							"   count(distinct ws_order_number) as order_count\r\n",
							"  ,sum(ws_ext_ship_cost) as total_shipping_cost\r\n",
							"  ,sum(ws_net_profit) as total_net_profit\r\n",
							"from\r\n",
							"   web_sales ws1\r\n",
							"  ,date_dim\r\n",
							"  ,customer_address\r\n",
							"  ,web_site\r\n",
							"where\r\n",
							"    d_date between cast('1999-2-01' as date) and \r\n",
							"           date_add(cast('1999-2-01' as date), 60 )\r\n",
							"and ws1.ws_ship_date_sk = d_date_sk\r\n",
							"and ws1.ws_ship_addr_sk = ca_address_sk\r\n",
							"and ca_state = 'IL'\r\n",
							"and ws1.ws_web_site_sk = web_site_sk\r\n",
							"and web_company_name = 'pri'\r\n",
							"and exists (select *\r\n",
							"            from web_sales ws2\r\n",
							"            where ws1.ws_order_number = ws2.ws_order_number\r\n",
							"              and ws1.ws_warehouse_sk <> ws2.ws_warehouse_sk)\r\n",
							"and not exists(select *\r\n",
							"               from web_returns wr1\r\n",
							"               where ws1.ws_order_number = wr1.wr_order_number)\r\n",
							"order by count(distinct ws_order_number)\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query95\r\n",
							"with ws_wh as\r\n",
							"(select ws1.ws_order_number,ws1.ws_warehouse_sk wh1,ws2.ws_warehouse_sk wh2\r\n",
							" from web_sales ws1,web_sales ws2\r\n",
							" where ws1.ws_order_number = ws2.ws_order_number\r\n",
							"   and ws1.ws_warehouse_sk <> ws2.ws_warehouse_sk)\r\n",
							" select  \r\n",
							"   count(distinct ws_order_number) as order_count\r\n",
							"  ,sum(ws_ext_ship_cost) as total_shipping_cost\r\n",
							"  ,sum(ws_net_profit) as total_net_profit\r\n",
							"from\r\n",
							"   web_sales ws1\r\n",
							"  ,date_dim\r\n",
							"  ,customer_address\r\n",
							"  ,web_site\r\n",
							"where\r\n",
							"    d_date between '1999-2-01' and \r\n",
							"           date_add(cast('1999-2-01' as date), 60 )\r\n",
							"and ws1.ws_ship_date_sk = d_date_sk\r\n",
							"and ws1.ws_ship_addr_sk = ca_address_sk\r\n",
							"and ca_state = 'IL'\r\n",
							"and ws1.ws_web_site_sk = web_site_sk\r\n",
							"and web_company_name = 'pri'\r\n",
							"and ws1.ws_order_number in (select ws_order_number\r\n",
							"                            from ws_wh)\r\n",
							"and ws1.ws_order_number in (select wr_order_number\r\n",
							"                            from web_returns,ws_wh\r\n",
							"                            where wr_order_number = ws_wh.ws_order_number)\r\n",
							"order by count(distinct ws_order_number)\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query96\r\n",
							" select  count(*) \r\n",
							"from store_sales\r\n",
							"    ,household_demographics \r\n",
							"    ,time_dim, store\r\n",
							"where ss_sold_time_sk = time_dim.t_time_sk   \r\n",
							"    and ss_hdemo_sk = household_demographics.hd_demo_sk \r\n",
							"    and ss_store_sk = s_store_sk\r\n",
							"    and time_dim.t_hour = 20\r\n",
							"    and time_dim.t_minute >= 30\r\n",
							"    and household_demographics.hd_dep_count = 7\r\n",
							"    and store.s_store_name = 'ese'\r\n",
							"order by count(*)\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query97\r\n",
							"with ssci as (\r\n",
							"select ss_customer_sk customer_sk\r\n",
							"      ,ss_item_sk item_sk\r\n",
							"from store_sales,date_dim\r\n",
							"where ss_sold_date_sk = d_date_sk\r\n",
							"  and d_month_seq between 1200 and 1200 + 11\r\n",
							"group by ss_customer_sk\r\n",
							"        ,ss_item_sk),\r\n",
							"csci as(\r\n",
							" select cs_bill_customer_sk customer_sk\r\n",
							"      ,cs_item_sk item_sk\r\n",
							"from catalog_sales,date_dim\r\n",
							"where cs_sold_date_sk = d_date_sk\r\n",
							"  and d_month_seq between 1200 and 1200 + 11\r\n",
							"group by cs_bill_customer_sk\r\n",
							"        ,cs_item_sk)\r\n",
							" select  sum(case when ssci.customer_sk is not null and csci.customer_sk is null then 1 else 0 end) store_only\r\n",
							"      ,sum(case when ssci.customer_sk is null and csci.customer_sk is not null then 1 else 0 end) catalog_only\r\n",
							"      ,sum(case when ssci.customer_sk is not null and csci.customer_sk is not null then 1 else 0 end) store_and_catalog\r\n",
							"from ssci full outer join csci on (ssci.customer_sk=csci.customer_sk\r\n",
							"                               and ssci.item_sk = csci.item_sk)\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query98\r\n",
							"select i_item_id\r\n",
							"      ,i_item_desc \r\n",
							"      ,i_category \r\n",
							"      ,i_class \r\n",
							"      ,i_current_price\r\n",
							"      ,sum(ss_ext_sales_price) as itemrevenue \r\n",
							"      ,sum(ss_ext_sales_price)*100/sum(sum(ss_ext_sales_price)) over\r\n",
							"          (partition by i_class) as revenueratio\r\n",
							"from\t\r\n",
							"\tstore_sales\r\n",
							"    \t,item \r\n",
							"    \t,date_dim\r\n",
							"where \r\n",
							"\tss_item_sk = i_item_sk \r\n",
							"  \tand i_category in ('Sports', 'Books', 'Home')\r\n",
							"  \tand ss_sold_date_sk = d_date_sk\r\n",
							"\tand d_date between cast('1999-02-22' as date) \r\n",
							"\t\t\t\tand date_add(cast('1999-02-22' as date), 30 )\r\n",
							"group by \r\n",
							"\ti_item_id\r\n",
							"        ,i_item_desc \r\n",
							"        ,i_category\r\n",
							"        ,i_class\r\n",
							"        ,i_current_price\r\n",
							"order by \r\n",
							"\ti_category\r\n",
							"        ,i_class\r\n",
							"        ,i_item_id\r\n",
							"        ,i_item_desc\r\n",
							"        ,revenueratio;"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"--query99\r\n",
							" select  \r\n",
							"   substr(w_warehouse_name,1,20)\r\n",
							"  ,sm_type\r\n",
							"  ,cc_name\r\n",
							"  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk <= 30 ) then 1 else 0 end)  as 30_days \r\n",
							"  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 30) and \r\n",
							"                 (cs_ship_date_sk - cs_sold_date_sk <= 60) then 1 else 0 end )  as 31_60_days\r\n",
							"  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 60) and \r\n",
							"                 (cs_ship_date_sk - cs_sold_date_sk <= 90) then 1 else 0 end)  as 61_90_days\r\n",
							"  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 90) and\r\n",
							"                 (cs_ship_date_sk - cs_sold_date_sk <= 120) then 1 else 0 end)  as 91_120_days\r\n",
							"  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk  > 120) then 1 else 0 end)  as above120_days\r\n",
							"from\r\n",
							"   catalog_sales\r\n",
							"  ,warehouse\r\n",
							"  ,ship_mode\r\n",
							"  ,call_center\r\n",
							"  ,date_dim\r\n",
							"where\r\n",
							"    d_month_seq between 1200 and 1200 + 11\r\n",
							"and cs_ship_date_sk   = d_date_sk\r\n",
							"and cs_warehouse_sk   = w_warehouse_sk\r\n",
							"and cs_ship_mode_sk   = sm_ship_mode_sk\r\n",
							"and cs_call_center_sk = cc_call_center_sk\r\n",
							"group by\r\n",
							"   substr(w_warehouse_name,1,20)\r\n",
							"  ,sm_type\r\n",
							"  ,cc_name\r\n",
							"order by substr(w_warehouse_name,1,20)\r\n",
							"        ,sm_type\r\n",
							"        ,cc_name\r\n",
							" limit 100;"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SynapseSpark')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 30
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 5,
					"minNodeCount": 3
				},
				"nodeCount": 3,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.1",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "westeurope"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tpcdsSmall')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": false,
					"maxNodeCount": 10,
					"minNodeCount": 3
				},
				"nodeCount": 3,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "westeurope"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tpcdsMedium')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": false,
					"maxNodeCount": 10,
					"minNodeCount": 3
				},
				"nodeCount": 3,
				"nodeSize": "Medium",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "westeurope"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tpcdsLarge')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": false,
					"maxNodeCount": 10,
					"minNodeCount": 3
				},
				"nodeCount": 3,
				"nodeSize": "Large",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "westeurope"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tpcdsXLarge')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": false,
					"maxNodeCount": 10,
					"minNodeCount": 3
				},
				"nodeCount": 3,
				"nodeSize": "XLarge",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "westeurope"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SynapseSQLDedicated')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"collation": "SQL_Latin1_General_CP1_CI_AS",
				"maxSizeBytes": 263882790666240,
				"annotations": []
			},
			"dependsOn": [],
			"location": "westeurope"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ScaleSQLDBforSynapseLink2SQLDB')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Scale to S3-DTU100",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[dbo].[spScaleDB_S3]"
						},
						"linkedServiceName": {
							"referenceName": "brandybuck_primula",
							"type": "LinkedServiceReference"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "Examples"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/brandybuck_primula')]"
			]
		}
	]
}